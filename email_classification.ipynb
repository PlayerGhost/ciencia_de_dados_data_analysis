{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "import math\n",
    "#from langdetect import detect,detect_langs\n",
    "import validators\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "#import en_core_web_sm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import email\n",
    "import email.policy\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer,word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from string import punctuation\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re\n",
    "import heapq\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CARREGANDO BASE DE DADOS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "'''teste = pd.read_csv(\"spam_ham_dataset.csv\").sample(frac=1)\n",
    "teste2 =pd.read_csv(\"emails.csv\").sample(frac=1)\n",
    "targetTest2 = teste2[\"spam\"]\n",
    "teste = teste.drop(columns=[\"Unnamed: 0\",\"label_num\"])\n",
    "teste = teste.replace({\"ham\":0,\"spam\":1})\n",
    "targetTest = teste[\"label\"]'''\n",
    "\n",
    "database = pd.read_csv(\"Database/enron_spam_data.csv\")\n",
    "database = database.drop(columns=[\"Message ID\",\"Date\"])\n",
    "database = database.replace({\"ham\":0,\"spam\":1})\n",
    "database = database.drop(columns=[\"Subject\"])\n",
    "database = database.dropna()\n",
    "database = database.sample(frac=1)\n",
    "target = database[\"Spam/Ham\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def removePunctuation(text):\n",
    "    ponctuation = list(punctuation)\n",
    "\n",
    "    for i in ponctuation:\n",
    "        text = text.replace(i, \"\")\n",
    "\n",
    "    return text\n",
    "\n",
    "stopWords = set(stopwords.words('english')  + list(punctuation) + list(STOPWORDS))\n",
    "stopWords.add(\"subject\")\n",
    "stem = PorterStemmer()\n",
    "\n",
    "regex = re.compile(r'[\\w\\.-]+@[\\w\\.-]+(\\.[\\w]+)+')\n",
    "\n",
    "def wordsPreProcessing(email):\n",
    "    if email is None:\n",
    "        return 'empty'\n",
    "\n",
    "    newText = email\n",
    "\n",
    "    spacy.prefer_gpu()\n",
    "    NER = spacy.load(\"E:\\Anaconda3\\Lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.2.0\")\n",
    "\n",
    "    nerResult = NER(newText)\n",
    "\n",
    "    for text in nerResult.ents:\n",
    "        newText = newText.replace(text.text, text.label_+text.label_[-1])\n",
    "\n",
    "    e = newText.split()\n",
    "\n",
    "    for i in range(0,len(e)):\n",
    "        if validators.url(e[i]):\n",
    "            e[i] = \"URLLL\"\n",
    "\n",
    "        if re.fullmatch(regex,e[i]):\n",
    "            e[i] = \"EMAILLL\"\n",
    "\n",
    "\n",
    "    for text in word_tokenize(\"\".join(e).lower()):\n",
    "        text = removePunctuation(text)\n",
    "\n",
    "        if text not in stopWords and not text.isdigit():\n",
    "            newText = newText.replace(text, stem.stem(text))\n",
    "\n",
    "    return newText"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def bagOfWord(emails):\n",
    "    wordCount = {}\n",
    "\n",
    "    for email in emails:\n",
    "        for i in email.split():\n",
    "            if i not in wordCount.keys():\n",
    "                wordCount[i] = 1\n",
    "            else:\n",
    "                wordCount[i] += 1\n",
    "\n",
    "    return wordCount"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m emailsTest \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m email \u001B[38;5;129;01min\u001B[39;00m database[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMessage\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m----> 4\u001B[0m     emailsTest\u001B[38;5;241m.\u001B[39mappend(\u001B[43mwordsPreProcessing\u001B[49m\u001B[43m(\u001B[49m\u001B[43memail\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m#emailsTest.append(email)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \n\u001B[0;32m      7\u001B[0m \n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m#emailsTest\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mok\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36mwordsPreProcessing\u001B[1;34m(email)\u001B[0m\n\u001B[0;32m     21\u001B[0m spacy\u001B[38;5;241m.\u001B[39mprefer_gpu()\n\u001B[0;32m     22\u001B[0m NER \u001B[38;5;241m=\u001B[39m spacy\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mE:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mAnaconda3\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mLib\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124msite-packages\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124men_core_web_sm\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124men_core_web_sm-3.2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 24\u001B[0m nerResult \u001B[38;5;241m=\u001B[39m \u001B[43mNER\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnewText\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m nerResult\u001B[38;5;241m.\u001B[39ments:\n\u001B[0;32m     27\u001B[0m     newText \u001B[38;5;241m=\u001B[39m newText\u001B[38;5;241m.\u001B[39mreplace(text\u001B[38;5;241m.\u001B[39mtext, text\u001B[38;5;241m.\u001B[39mlabel_\u001B[38;5;241m+\u001B[39mtext\u001B[38;5;241m.\u001B[39mlabel_[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n",
      "File \u001B[1;32mE:\\Anaconda3\\envs\\ciencia_de_dados_data_analysis\\lib\\site-packages\\spacy\\language.py:1014\u001B[0m, in \u001B[0;36mLanguage.__call__\u001B[1;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[0;32m   1012\u001B[0m     error_handler \u001B[38;5;241m=\u001B[39m proc\u001B[38;5;241m.\u001B[39mget_error_handler()\n\u001B[0;32m   1013\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1014\u001B[0m     doc \u001B[38;5;241m=\u001B[39m proc(doc, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcomponent_cfg\u001B[38;5;241m.\u001B[39mget(name, {}))  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m   1015\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1016\u001B[0m     \u001B[38;5;66;03m# This typically happens if a component is not initialized\u001B[39;00m\n\u001B[0;32m   1017\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE109\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Anaconda3\\envs\\ciencia_de_dados_data_analysis\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py:143\u001B[0m, in \u001B[0;36mAttributeRuler.__call__\u001B[1;34m(self, doc)\u001B[0m\n\u001B[0;32m    141\u001B[0m error_handler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_error_handler()\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 143\u001B[0m     matches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_annotations(doc, matches)\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m doc\n",
      "File \u001B[1;32mE:\\Anaconda3\\envs\\ciencia_de_dados_data_analysis\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py:152\u001B[0m, in \u001B[0;36mAttributeRuler.match\u001B[1;34m(self, doc)\u001B[0m\n\u001B[0;32m    150\u001B[0m matches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmatcher(doc, allow_missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, as_spans\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;66;03m# Sort by the attribute ID, so that later rules have precedence\u001B[39;00m\n\u001B[1;32m--> 152\u001B[0m matches \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    153\u001B[0m     (\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab\u001B[38;5;241m.\u001B[39mstrings[m_id]), m_id, s, e) \u001B[38;5;28;01mfor\u001B[39;00m m_id, s, e \u001B[38;5;129;01min\u001B[39;00m matches  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m    154\u001B[0m ]\n\u001B[0;32m    155\u001B[0m matches\u001B[38;5;241m.\u001B[39msort()\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m matches\n",
      "File \u001B[1;32mE:\\Anaconda3\\envs\\ciencia_de_dados_data_analysis\\lib\\site-packages\\spacy\\pipeline\\attributeruler.py:152\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    150\u001B[0m matches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmatcher(doc, allow_missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, as_spans\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;66;03m# Sort by the attribute ID, so that later rules have precedence\u001B[39;00m\n\u001B[1;32m--> 152\u001B[0m matches \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    153\u001B[0m     (\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab\u001B[38;5;241m.\u001B[39mstrings[m_id]), m_id, s, e) \u001B[38;5;28;01mfor\u001B[39;00m m_id, s, e \u001B[38;5;129;01min\u001B[39;00m matches  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m    154\u001B[0m ]\n\u001B[0;32m    155\u001B[0m matches\u001B[38;5;241m.\u001B[39msort()\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m matches\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "emailsTest = []\n",
    "\n",
    "for email in database[\"Message\"]:\n",
    "    emailsTest.append(wordsPreProcessing(email))\n",
    "    #emailsTest.append(email)\n",
    "\n",
    "\n",
    "#emailsTest\n",
    "print(\"ok\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#nlp = en_core_web_sm.load()\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy.prefer_gpu()\n",
    "NER = spacy.load(\"E:\\Anaconda3\\Lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.2.0\")\n",
    "\n",
    "print(wordsPreProcessing(emailsTest[45]))\n",
    "\n",
    "#displacy.render(text1,style=\"ent\",jupyter=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emailsTest[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#wordCount = bagOfWord(emailsText)\n",
    "\n",
    "#wordFrequency = heapq.nlargest(100, wordCount, wordCount.get)\n",
    "\n",
    "#print(wordFrequency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidfVectorizer = TfidfVectorizer(analyzer=\"word\",max_features=2100)\n",
    "#tfidfVectorizer = TfidfVectorizer(analyzer=\"word\")\n",
    "\n",
    "tfidfTransform = tfidfVectorizer.fit_transform(emailsText)\n",
    "\n",
    "print(tfidfTransform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidfLabels = tfidfVectorizer.get_feature_names()\n",
    "tfidfLabels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfTfidfArray = pd.DataFrame(data=tfidfTransform.toarray(), index=emailsNome, columns=tfidfLabels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfTfidfArray"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfTfidfArray.insert(len(dfTfidfArray.columns), \"Target\", targetsArray, True)\n",
    "dfTfidfArray = dfTfidfArray.sample(frac=1)\n",
    "dfTfidfArray\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dfTfidfArray.to_csv(\"dataset.csv\", sep='\\t', encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2, random_state=0)\n",
    "#model = PCA(n_components=50, svd_solver='full')\n",
    "array_red = model.fit_transform(dfTfidfArray)\n",
    "\n",
    "df_tsne = pd.DataFrame(array_red)\n",
    "\n",
    "target = dfTfidfArray[\"Target\"].array\n",
    "\n",
    "df_tsne['Target'] = target\n",
    "print(df_tsne)\n",
    "df_tsne_c1 = df_tsne[df_tsne['Target'] == 0]\n",
    "\n",
    "df_tsne_c2 = df_tsne[df_tsne['Target'] == 1]\n",
    "\n",
    "plt.scatter(df_tsne_c1[0].array,df_tsne_c1[1].array,marker='o',color='blue')\n",
    "\n",
    "plt.scatter(df_tsne_c2[0].array,df_tsne_c2[1].array,marker='o',color='red')\n",
    "\n",
    "plt.title('Dados')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_features = dfTfidfArray.drop(columns=['Target'])\n",
    "#df_tsneTarget = df_tsne[\"Target\"].array\n",
    "#df_tsneFeatures = df_tsne.drop(columns=['Target'])\n",
    "\n",
    "\n",
    "df_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def getModel():\n",
    "      return LogisticRegression(max_iter=200)\n",
    "#     return DecisionTreeClassifier()\n",
    "#     return RandomForestClassifier()\n",
    "#     return LinearSVC()\n",
    "#     return MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(df_features.values,target,test_size=0.2)\n",
    "modelo = getModel().fit(X_treino,y_treino)\n",
    "score = modelo.score(X_teste,y_teste)\n",
    "#score = modelo.score([\"alo\"],[1])\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = cross_val_score(getModel(),df_features.values,target,cv=10)\n",
    "\n",
    "scores.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicoes = cross_val_predict(getModel(), df_features.values, target, cv=10)\n",
    "\n",
    "cm = confusion_matrix(target,predicoes,labels=[0, 1])\n",
    "\n",
    "cm_df = pd.DataFrame(cm, columns=[0, 1])\n",
    "\n",
    "cm_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emailsTest2 = []\n",
    "\n",
    "for email in teste2[\"text\"]:\n",
    "    emailsTest2.append(wordsPreProcessing(email))\n",
    "    \n",
    "print(\"ok\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emailsTest3 = []\n",
    "\n",
    "for email in teste[\"text\"]:\n",
    "    emailsTest3.append(wordsPreProcessing(email))\n",
    "    \n",
    "print(\"ok\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#APAGAR DEPOIS\n",
    "\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_counts = count_vect.fit_transform(emailsTest)\n",
    "# X_train_counts.shape\n",
    "#\n",
    "# tf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ##APAGAR DEPOIS\n",
    "# clf = getModel().fit(X_train_tfidf,target)\n",
    "#\n",
    "# X_new_counts = count_vect.transform(emailsTest2)\n",
    "#\n",
    "# X_new_tfidf = tf_transformer.transform(X_new_counts)\n",
    "#\n",
    "# predict = clf.predict(X_new_tfidf)\n",
    "# print(len(emailsTest2))\n",
    "# print(predict)\n",
    "# print(targetTest2)\n",
    "# print(teste2)\n",
    "# print(clf.score(X_new_tfidf,targetTest2))\n",
    "#\n",
    "# #predicoesTest = cross_val_predict(modelo2, dfTfidfArrayFeaturesTest.values, dfTfidfArrayTargetTest, cv=10)\n",
    "#\n",
    "# cmTest = confusion_matrix(targetTest2,predict,labels=[0, 1])\n",
    "#\n",
    "# cm_dfTest = pd.DataFrame(cmTest, columns=[0, 1])\n",
    "#\n",
    "# cm_dfTest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dfTfidfArrayTest = pd.DataFrame(data=tfidfTransformTest.toarray(), columns=tfidfVectorizerTest.get_feature_names_out())\n",
    "# dfTfidfArrayTest.insert(len(dfTfidfArrayTest.columns), \"Target\", target.array, True)\n",
    "# dfTfidfArrayTest = dfTfidfArrayTest.sample(frac=1)\n",
    "# dfTfidfArrayTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# modelTest = TSNE(n_components=2, random_state=0)\n",
    "# #modelTest = PCA(n_components=50)\n",
    "# array_redTest = modelTest.fit_transform(dfTfidfArrayTest)\n",
    "#\n",
    "# df_tsneTest = pd.DataFrame(array_redTest)\n",
    "# df_tsneTest['Target'] = target.array\n",
    "#\n",
    "# df_tsne_c1Test = df_tsneTest[df_tsneTest['Target'] == 0]\n",
    "#\n",
    "# df_tsne_c2Test  = df_tsneTest[df_tsneTest['Target'] == 1]\n",
    "#\n",
    "# plt.scatter(df_tsne_c1Test[0].array,df_tsne_c1Test[1].array,marker='o',color='blue')\n",
    "#\n",
    "# plt.scatter(df_tsne_c2Test[0].array,df_tsne_c2Test[1].array,marker='o',color='red')\n",
    "#\n",
    "# plt.title('Dados')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "#\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dfTfidfArrayTarget = dfTfidfArray[\"Target\"].array\n",
    "# dfTfidfArrayFeatures = dfTfidfArray.drop(columns=['Target'])\n",
    "#\n",
    "# print(dfTfidfArrayFeatures)\n",
    "#\n",
    "# dfTfidfArrayTargetTest = dfTfidfArrayTest[\"Target\"].array\n",
    "# dfTfidfArrayFeaturesTest = dfTfidfArrayTest.drop(columns=['Target'])\n",
    "#\n",
    "#\n",
    "#\n",
    "# print(dfTfidfArrayFeaturesTest)\n",
    "# dfTfidfArrayTargetTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dfTfidfArrayTargetTest2 = dfTfidfArrayTest2[\"Target\"].array\n",
    "# dfTfidfArrayFeaturesTest2 = dfTfidfArrayTest2.drop(columns=['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #from sklearn.svm import LinearSVC\n",
    "#\n",
    "# X_treino, X_teste, y_treino, y_teste = train_test_split(dfTfidfArrayFeaturesTest2.values,dfTfidfArrayTargetTest2,test_size=0.2)\n",
    "# X_treinoTest, X_testeTest, y_treinoTest, y_testeTest = train_test_split(dfTfidfArrayFeaturesTest.values,dfTfidfArrayTargetTest,test_size=0.01)\n",
    "# modelo = getModel().fit(X_treino,y_treino)\n",
    "# modelo2 = getModel().fit(X_treinoTest,y_treinoTest)\n",
    "# predict = modelo.predict(X_teste)\n",
    "# #score = modelo.score(X_treinoTest,y_treinoTest)\n",
    "# #score2 = modelo2.score(X_treino,y_treino)\n",
    "#\n",
    "# cmTest = confusion_matrix(y_teste,predict)\n",
    "# cm_dfTest = pd.DataFrame(cmTest, columns=[0, 1])\n",
    "#\n",
    "# cm_dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#predicoesTest = cross_val_predict(modelo2, dfTfidfArrayFeaturesTest.values, dfTfidfArrayTargetTest, cv=10)\n",
    "\n",
    "#cmTest = confusion_matrix(dfTfidfArrayTargetTest,predicoesTest,labels=[0, 1])\n",
    "\n",
    "#cm_dfTest = pd.DataFrame(cmTest, columns=[0, 1])\n",
    "\n",
    "#cm_dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}