{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T07:48:04.385408Z",
     "start_time": "2022-05-05T07:48:03.008408Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Carregando base de dados  pré-processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T07:48:52.249148Z",
     "start_time": "2022-05-05T07:48:51.958148Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   email  target\n0      start date     hourahead timee  cardinall  hou...       0\n1      service long desk  price structure deal quote ...       0\n2      start date  cardinall    hourahead timee  card...       0\n3      start date     hourahead timee  cardinall  anc...       0\n4      cardinall deliverable revenue management marke...       0\n...                                                  ...     ...\n33340  bio  matrix scientific group   symbo   bmxg  p...       1\n33341   cardinall step away hot naked webcam girl liv...       1\n33342  need pill increase performance click  seroius ...       1\n33343  datee final nom       inlet hpl  eastrans  car...       0\n33344  ordinall time  offering male enhancement perfo...       1\n\n[33341 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>start date     hourahead timee  cardinall  hou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>service long desk  price structure deal quote ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>start date  cardinall    hourahead timee  card...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>start date     hourahead timee  cardinall  anc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cardinall deliverable revenue management marke...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33340</th>\n      <td>bio  matrix scientific group   symbo   bmxg  p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33341</th>\n      <td>cardinall step away hot naked webcam girl liv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33342</th>\n      <td>need pill increase performance click  seroius ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33343</th>\n      <td>datee final nom       inlet hpl  eastrans  car...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33344</th>\n      <td>ordinall time  offering male enhancement perfo...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>33341 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = pd.read_csv(\"../../Database/dataBaseWithNER.csv\")\n",
    "\n",
    "database = database.drop(columns=[\"Unnamed: 0\"])\n",
    "database = database.dropna()\n",
    "target = database[\"target\"].array\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emailsText = []\n",
    "for email in database[\"email\"]:\n",
    "    emailsText.append(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33341\n"
     ]
    }
   ],
   "source": [
    "print(len(emailsText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Representação vetorial TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1593)\t0.26470874972054786\n",
      "  (0, 1098)\t0.35510965844285625\n",
      "  (0, 671)\t0.34195431682743727\n",
      "  (0, 535)\t0.3142974755284843\n",
      "  (0, 1663)\t0.2523502664970415\n",
      "  (0, 249)\t0.0882891907360702\n",
      "  (0, 1904)\t0.14585506953003874\n",
      "  (0, 861)\t0.6284245513555586\n",
      "  (0, 440)\t0.21615559903629922\n",
      "  (0, 1796)\t0.23177737406989862\n",
      "  (1, 1893)\t0.12322552160237797\n",
      "  (1, 432)\t0.16667910623163265\n",
      "  (1, 1405)\t0.2023515027069684\n",
      "  (1, 1910)\t0.21821281232441633\n",
      "  (1, 773)\t0.252147976524646\n",
      "  (1, 1814)\t0.24651126769711865\n",
      "  (1, 2073)\t0.1442701571707954\n",
      "  (1, 1342)\t0.19540664510107641\n",
      "  (1, 1962)\t0.21745283397516152\n",
      "  (1, 809)\t0.3089620245082559\n",
      "  (1, 1457)\t0.1585651873255142\n",
      "  (1, 297)\t0.26945510026530634\n",
      "  (1, 1102)\t0.268483606738479\n",
      "  (1, 105)\t0.2304674552193428\n",
      "  (1, 1514)\t0.2375975711797802\n",
      "  :\t:\n",
      "  (33340, 734)\t0.1499328111246709\n",
      "  (33340, 1274)\t0.08454655116352783\n",
      "  (33340, 1509)\t0.09899129231263658\n",
      "  (33340, 637)\t0.15067486614547307\n",
      "  (33340, 1426)\t0.1353816153153684\n",
      "  (33340, 1339)\t0.22427638740937866\n",
      "  (33340, 754)\t0.09188746055078964\n",
      "  (33340, 559)\t0.11491980925916795\n",
      "  (33340, 1769)\t0.10510884292075533\n",
      "  (33340, 1986)\t0.08636565336679641\n",
      "  (33340, 1031)\t0.10274780227612142\n",
      "  (33340, 922)\t0.1335163841406214\n",
      "  (33340, 2031)\t0.08105791498966726\n",
      "  (33340, 741)\t0.08739011828455572\n",
      "  (33340, 283)\t0.10256819866807917\n",
      "  (33340, 936)\t0.10740062813394481\n",
      "  (33340, 897)\t0.10944071839628189\n",
      "  (33340, 1336)\t0.15206155743866692\n",
      "  (33340, 1903)\t0.06622826958556323\n",
      "  (33340, 931)\t0.10240347739304079\n",
      "  (33340, 1892)\t0.1796402828958075\n",
      "  (33340, 982)\t0.07011904757700844\n",
      "  (33340, 1018)\t0.07853769601332126\n",
      "  (33340, 1433)\t0.07688428329132653\n",
      "  (33340, 249)\t0.035685123980728164\n"
     ]
    }
   ],
   "source": [
    "tfidfVectorizer = TfidfVectorizer(analyzer=\"word\",max_features=2100)\n",
    "\n",
    "tfidfTransform = tfidfVectorizer.fit_transform(emailsText)\n",
    "\n",
    "print(tfidfTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['aa',\n 'ability',\n 'able',\n 'absolutely',\n 'abuse',\n 'accept',\n 'acceptance',\n 'accepted',\n 'access',\n 'according',\n 'account',\n 'accounting',\n 'accuracy',\n 'achieve',\n 'acquire',\n 'acquired',\n 'acquisition',\n 'acrobat',\n 'act',\n 'action',\n 'active',\n 'activity',\n 'actual',\n 'actually',\n 'acy',\n 'ad',\n 'add',\n 'added',\n 'adding',\n 'addition',\n 'additional',\n 'additionally',\n 'address',\n 'administration',\n 'adobe',\n 'adult',\n 'advance',\n 'advanced',\n 'advantage',\n 'advertisement',\n 'advertising',\n 'advice',\n 'advise',\n 'advised',\n 'advises',\n 'advisor',\n 'aep',\n 'affair',\n 'affect',\n 'affiliate',\n 'affiliated',\n 'affordable',\n 'age',\n 'agency',\n 'agenda',\n 'agent',\n 'aggressive',\n 'agree',\n 'agreed',\n 'agreement',\n 'ahead',\n 'aid',\n 'ail',\n 'aimee',\n 'air',\n 'al',\n 'alert',\n 'alias',\n 'align',\n 'allen',\n 'allocated',\n 'allocation',\n 'allow',\n 'allowed',\n 'allows',\n 'alternative',\n 'america',\n 'amid',\n 'amount',\n 'amy',\n 'analysis',\n 'analyst',\n 'ancillary',\n 'andmanyother',\n 'andrew',\n 'anita',\n 'anjam',\n 'announce',\n 'announced',\n 'announcement',\n 'announces',\n 'answer',\n 'anti',\n 'anticipated',\n 'anticipates',\n 'anybody',\n 'aol',\n 'appear',\n 'appears',\n 'application',\n 'applied',\n 'apply',\n 'appointment',\n 'appreciate',\n 'approach',\n 'appropriate',\n 'approval',\n 'approved',\n 'ar',\n 'area',\n 'arm',\n 'arrange',\n 'arrangement',\n 'art',\n 'article',\n 'asap',\n 'ask',\n 'asked',\n 'asking',\n 'asset',\n 'assist',\n 'assistance',\n 'assistant',\n 'associate',\n 'associated',\n 'assume',\n 'assumption',\n 'assurance',\n 'attached',\n 'attachment',\n 'attack',\n 'attempt',\n 'attend',\n 'attention',\n 'attorney',\n 'auction',\n 'audit',\n 'authority',\n 'automatically',\n 'availability',\n 'available',\n 'average',\n 'avoid',\n 'award',\n 'awarded',\n 'aware',\n 'away',\n 'background',\n 'bad',\n 'balance',\n 'ballot',\n 'bandwidth',\n 'bank',\n 'banker',\n 'banking',\n 'bankruptcy',\n 'barry',\n 'base',\n 'based',\n 'basic',\n 'basin',\n 'basis',\n 'batch',\n 'baylor',\n 'bbb',\n 'bcf',\n 'bed',\n 'began',\n 'begin',\n 'beginning',\n 'behalf',\n 'belief',\n 'believe',\n 'beneficiary',\n 'benefit',\n 'best',\n 'beth',\n 'better',\n 'bid',\n 'big',\n 'biggest',\n 'bill',\n 'billing',\n 'billion',\n 'bit',\n 'biz',\n 'black',\n 'blank',\n 'block',\n 'bloomberg',\n 'blue',\n 'bn',\n 'board',\n 'bob',\n 'body',\n 'bond',\n 'bonus',\n 'book',\n 'boost',\n 'border',\n 'bought',\n 'box',\n 'boy',\n 'br',\n 'bra',\n 'brand',\n 'break',\n 'breaking',\n 'brent',\n 'brian',\n 'bridge',\n 'brief',\n 'bring',\n 'broadband',\n 'broadcast',\n 'broker',\n 'brought',\n 'brown',\n 'browser',\n 'budget',\n 'build',\n 'building',\n 'built',\n 'bulk',\n 'business',\n 'button',\n 'buy',\n 'buyer',\n 'buying',\n 'ca',\n 'cable',\n 'cal',\n 'calendar',\n 'calger',\n 'california',\n 'call',\n 'called',\n 'calling',\n 'calpine',\n 'came',\n 'campaign',\n 'candidate',\n 'cap',\n 'capability',\n 'capacity',\n 'capital',\n 'capture',\n 'car',\n 'card',\n 'cardinall',\n 'care',\n 'career',\n 'carefully',\n 'carol',\n 'carry',\n 'case',\n 'cash',\n 'category',\n 'cause',\n 'caused',\n 'cc',\n 'cd',\n 'ce',\n 'cell',\n 'cent',\n 'center',\n 'central',\n 'ceo',\n 'cera',\n 'certain',\n 'certainly',\n 'cfo',\n 'chair',\n 'chairman',\n 'challenge',\n 'chance',\n 'change',\n 'changed',\n 'changing',\n 'channel',\n 'charge',\n 'chart',\n 'cheap',\n 'check',\n 'chief',\n 'child',\n 'choice',\n 'choose',\n 'christie',\n 'city',\n 'cl',\n 'claim',\n 'claimed',\n 'claiming',\n 'class',\n 'clean',\n 'clear',\n 'clearly',\n 'click',\n 'client',\n 'close',\n 'closed',\n 'closely',\n 'closing',\n 'club',\n 'coal',\n 'code',\n 'collapse',\n 'collateral',\n 'colleague',\n 'college',\n 'color',\n 'column',\n 'com',\n 'combination',\n 'combined',\n 'come',\n 'coming',\n 'comment',\n 'commerce',\n 'commercial',\n 'commission',\n 'commitment',\n 'committed',\n 'committee',\n 'commodity',\n 'common',\n 'communication',\n 'community',\n 'company',\n 'compare',\n 'compared',\n 'compensated',\n 'compensation',\n 'competition',\n 'competitive',\n 'competitor',\n 'complaint',\n 'complete',\n 'completed',\n 'completely',\n 'completion',\n 'complex',\n 'compliance',\n 'component',\n 'computron',\n 'concept',\n 'concern',\n 'concerned',\n 'concerning',\n 'conclusion',\n 'condition',\n 'conduct',\n 'conference',\n 'confidence',\n 'confidential',\n 'confidentiality',\n 'confirm',\n 'confirmation',\n 'confirmed',\n 'conflict',\n 'congratulation',\n 'connection',\n 'consequently',\n 'consider',\n 'consideration',\n 'considered',\n 'consistent',\n 'constitutes',\n 'construction',\n 'construed',\n 'consultant',\n 'consultation',\n 'consulting',\n 'consumer',\n 'contact',\n 'contacted',\n 'contacting',\n 'contain',\n 'contained',\n 'contains',\n 'content',\n 'continue',\n 'continued',\n 'continues',\n 'continuing',\n 'contract',\n 'contractor',\n 'contribution',\n 'control',\n 'convenience',\n 'convenient',\n 'conversation',\n 'cooperation',\n 'coordinate',\n 'coordinator',\n 'copy',\n 'copyright',\n 'core',\n 'corel',\n 'corp',\n 'corporate',\n 'corporation',\n 'correct',\n 'correspondence',\n 'cost',\n 'couid',\n 'count',\n 'counterparties',\n 'counterparty',\n 'country',\n 'couple',\n 'coupon',\n 'course',\n 'court',\n 'cover',\n 'coverage',\n 'create',\n 'created',\n 'creating',\n 'creative',\n 'credit',\n 'creditor',\n 'crenshaw',\n 'crisis',\n 'critical',\n 'cross',\n 'crude',\n 'current',\n 'currently',\n 'curve',\n 'custom',\n 'customer',\n 'cut',\n 'da',\n 'dabhol',\n 'daily',\n 'daren',\n 'data',\n 'database',\n 'date',\n 'datee',\n 'david',\n 'davis',\n 'day',\n 'dbcaps',\n 'de',\n 'deadline',\n 'deal',\n 'dealer',\n 'dealing',\n 'dear',\n 'death',\n 'debt',\n 'dec',\n 'decide',\n 'decided',\n 'deciding',\n 'decision',\n 'decline',\n 'declined',\n 'default',\n 'degree',\n 'del',\n 'delay',\n 'delete',\n 'deliver',\n 'delivered',\n 'delivery',\n 'demand',\n 'department',\n 'deposit',\n 'deposited',\n 'dept',\n 'der',\n 'derivative',\n 'described',\n 'description',\n 'design',\n 'designated',\n 'designed',\n 'desire',\n 'desk',\n 'despite',\n 'detail',\n 'detailed',\n 'detected',\n 'determine',\n 'develop',\n 'developed',\n 'developing',\n 'development',\n 'device',\n 'dia',\n 'dial',\n 'die',\n 'died',\n 'differ',\n 'difference',\n 'different',\n 'difficult',\n 'difficulty',\n 'digital',\n 'diligence',\n 'dinner',\n 'direct',\n 'direction',\n 'directly',\n 'director',\n 'directory',\n 'disclose',\n 'disclosed',\n 'disclosure',\n 'discount',\n 'discovered',\n 'discreet',\n 'discus',\n 'discussed',\n 'discussion',\n 'distribute',\n 'distribution',\n 'division',\n 'doc',\n 'doctor',\n 'document',\n 'documentation',\n 'dollar',\n 'domain',\n 'domestic',\n 'door',\n 'dose',\n 'double',\n 'doubt',\n 'dow',\n 'downgrade',\n 'download',\n 'dpc',\n 'dr',\n 'draft',\n 'draw',\n 'drawn',\n 'drew',\n 'drink',\n 'drive',\n 'drop',\n 'dropped',\n 'drug',\n 'duke',\n 'duty',\n 'dvd',\n 'dynamic',\n 'dynegy',\n 'earlier',\n 'early',\n 'earn',\n 'earnings',\n 'easier',\n 'easily',\n 'east',\n 'easy',\n 'eb',\n 'economic',\n 'economy',\n 'ect',\n 'ed',\n 'edge',\n 'edison',\n 'edition',\n 'edu',\n 'education',\n 'ee',\n 'eff',\n 'effect',\n 'effective',\n 'effort',\n 'el',\n 'electric',\n 'electricity',\n 'electronic',\n 'element',\n 'em',\n 'emai',\n 'email',\n 'emerging',\n 'emerson',\n 'employee',\n 'en',\n 'ena',\n 'enable',\n 'end',\n 'ene',\n 'energy',\n 'engine',\n 'engineering',\n 'enjoy',\n 'enron',\n 'enrononline',\n 'enronxgate',\n 'ensure',\n 'enter',\n 'entered',\n 'enterprise',\n 'entertainment',\n 'entire',\n 'entity',\n 'entry',\n 'environment',\n 'enw',\n 'eol',\n 'epmi',\n 'equipment',\n 'equity',\n 'erection',\n 'error',\n 'especially',\n 'est',\n 'established',\n 'estate',\n 'estimate',\n 'estimated',\n 'et',\n 'ets',\n 'euro',\n 'evaluation',\n 'event',\n 'eventt',\n 'ew',\n 'ex',\n 'exactly',\n 'example',\n 'excellent',\n 'excess',\n 'exchange',\n 'exciting',\n 'exclusive',\n 'executed',\n 'executive',\n 'exercise',\n 'existing',\n 'expand',\n 'expansion',\n 'expect',\n 'expectation',\n 'expected',\n 'expects',\n 'expense',\n 'expensive',\n 'experience',\n 'experienced',\n 'expert',\n 'explain',\n 'exploration',\n 'export',\n 'exposure',\n 'express',\n 'expressed',\n 'ext',\n 'extend',\n 'extended',\n 'extension',\n 'extensive',\n 'external',\n 'extra',\n 'extremely',\n 'eye',\n 'facc',\n 'face',\n 'facilitate',\n 'facility',\n 'fact',\n 'factor',\n 'failed',\n 'failure',\n 'faith',\n 'fall',\n 'fallen',\n 'familiar',\n 'family',\n 'far',\n 'farmer',\n 'fast',\n 'faster',\n 'fastow',\n 'fat',\n 'father',\n 'favor',\n 'fax',\n 'fear',\n 'feature',\n 'featured',\n 'feb',\n 'federal',\n 'fee',\n 'feedback',\n 'feel',\n 'fell',\n 'field',\n 'figure',\n 'file',\n 'filed',\n 'filing',\n 'final',\n 'finally',\n 'finance',\n 'financial',\n 'financing',\n 'finding',\n 'fine',\n 'firm',\n 'fit',\n 'fixed',\n 'fl',\n 'flash',\n 'flight',\n 'floor',\n 'flow',\n 'focus',\n 'focused',\n 'follow',\n 'followed',\n 'following',\n 'follows',\n 'font',\n 'food',\n 'foot',\n 'force',\n 'forced',\n 'forecast',\n 'foreign',\n 'foreigner',\n 'foresee',\n 'form',\n 'formal',\n 'format',\n 'formula',\n 'forth',\n 'fortune',\n 'forward',\n 'forwarded',\n 'frank',\n 'fred',\n 'free',\n 'fresh',\n 'fri',\n 'friend',\n 'ft',\n 'fuel',\n 'fully',\n 'fun',\n 'function',\n 'fund',\n 'fundamental',\n 'funding',\n 'furthermore',\n 'future',\n 'fw',\n 'fyi',\n 'gain',\n 'game',\n 'gap',\n 'gas',\n 'gathered',\n 'gathering',\n 'gave',\n 'geec',\n 'general',\n 'generate',\n 'generated',\n 'generating',\n 'generation',\n 'generator',\n 'generic',\n 'george',\n 'get',\n 'getting',\n 'giant',\n 'gibner',\n 'gift',\n 'girl',\n 'give',\n 'given',\n 'giving',\n 'glad',\n 'global',\n 'go',\n 'goal',\n 'god',\n 'going',\n 'gold',\n 'gone',\n 'good',\n 'got',\n 'gotten',\n 'gov',\n 'government',\n 'governor',\n 'gpee',\n 'gr',\n 'grade',\n 'graduate',\n 'grand',\n 'grant',\n 'graphic',\n 'great',\n 'greater',\n 'green',\n 'greg',\n 'grid',\n 'ground',\n 'group',\n 'grow',\n 'growing',\n 'growth',\n 'guarantee',\n 'guaranteed',\n 'guide',\n 'guy',\n 'hall',\n 'hand',\n 'handle',\n 'handling',\n 'happen',\n 'happening',\n 'happy',\n 'hard',\n 'head',\n 'health',\n 'hear',\n 'heard',\n 'hearing',\n 'heart',\n 'heavy',\n 'hedge',\n 'height',\n 'held',\n 'hello',\n 'help',\n 'helped',\n 'helping',\n 'hesitate',\n 'hey',\n 'hi',\n 'high',\n 'higher',\n 'highest',\n 'highly',\n 'hin',\n 'historical',\n 'history',\n 'hit',\n 'hold',\n 'holding',\n 'holiday',\n 'home',\n 'hope',\n 'host',\n 'hot',\n 'hotel',\n 'hotmail',\n 'hou',\n 'hour',\n 'hourahead',\n 'house',\n 'houston',\n 'hpl',\n 'hr',\n 'href',\n 'hsc',\n 'html',\n 'http',\n 'hub',\n 'huge',\n 'human',\n 'husband',\n 'idea',\n 'identified',\n 'identify',\n 'identity',\n 'ii',\n 'iii',\n 'image',\n 'imagine',\n 'immediate',\n 'immediately',\n 'impact',\n 'implementation',\n 'importance',\n 'important',\n 'improve',\n 'improved',\n 'improvement',\n 'inciude',\n 'include',\n 'included',\n 'includes',\n 'including',\n 'income',\n 'increase',\n 'increased',\n 'increasing',\n 'independent',\n 'index',\n 'indicate',\n 'indicated',\n 'indicating',\n 'indicative',\n 'individual',\n 'industrial',\n 'industry',\n 'info',\n 'inform',\n 'information',\n 'informed',\n 'infrastructure',\n 'inherent',\n 'initial',\n 'initiative',\n 'innovative',\n 'input',\n 'inquiry',\n 'inside',\n 'instant',\n 'instead',\n 'institution',\n 'instruction',\n 'insurance',\n 'integration',\n 'intend',\n 'intended',\n 'intent',\n 'interest',\n 'interested',\n 'interesting',\n 'interface',\n 'internal',\n 'international',\n 'internet',\n 'interview',\n 'introduce',\n 'inventory',\n 'invest',\n 'invested',\n 'investigation',\n 'investing',\n 'investment',\n 'investor',\n 'invitation',\n 'invite',\n 'invoice',\n 'involve',\n 'involved',\n 'involving',\n 'ion',\n 'ire',\n 'iso',\n 'issue',\n 'issued',\n 'item',\n 'iv',\n 'jan',\n 'jeff',\n 'jim',\n 'job',\n 'john',\n 'join',\n 'joint',\n 'jones',\n 'judge',\n 'jul',\n 'jump',\n 'junk',\n 'kaminski',\n 'keeping',\n 'ken',\n 'kept',\n 'key',\n 'kimberly',\n 'kin',\n 'kind',\n 'kitchen',\n 'knew',\n 'kno',\n 'know',\n 'knowledge',\n 'known',\n 'la',\n 'lack',\n 'land',\n 'language',\n 'large',\n 'larger',\n 'largest',\n 'late',\n 'later',\n 'latest',\n 'launch',\n 'lauraan',\n 'law',\n 'lawsuit',\n 'laww',\n ...]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfLabels = tfidfVectorizer.get_feature_names()\n",
    "tfidfLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfTfidf = pd.DataFrame(data=tfidfTransform.toarray(), columns=tfidfLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        aa  ability  able  absolutely  abuse  accept  acceptance  accepted  \\\n0      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n1      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n2      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n3      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n4      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n...    ...      ...   ...         ...    ...     ...         ...       ...   \n33336  0.0      0.0   0.0         0.0    0.0     0.0    0.015667       0.0   \n33337  0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n33338  0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n33339  0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n33340  0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n\n         access  according  ...  xanax   xl   xp     yahoo  year  yes  yield  \\\n0      0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n1      0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n2      0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n3      0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n4      0.143700        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n...         ...        ...  ...    ...  ...  ...       ...   ...  ...    ...   \n33336  0.000000        0.0  ...    0.0  0.0  0.0  0.013857   0.0  0.0    0.0   \n33337  0.207355        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n33338  0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n33339  0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n33340  0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n\n        yo  young  zone  \n0      0.0    0.0   0.0  \n1      0.0    0.0   0.0  \n2      0.0    0.0   0.0  \n3      0.0    0.0   0.0  \n4      0.0    0.0   0.0  \n...    ...    ...   ...  \n33336  0.0    0.0   0.0  \n33337  0.0    0.0   0.0  \n33338  0.0    0.0   0.0  \n33339  0.0    0.0   0.0  \n33340  0.0    0.0   0.0  \n\n[33341 rows x 2100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aa</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>absolutely</th>\n      <th>abuse</th>\n      <th>accept</th>\n      <th>acceptance</th>\n      <th>accepted</th>\n      <th>access</th>\n      <th>according</th>\n      <th>...</th>\n      <th>xanax</th>\n      <th>xl</th>\n      <th>xp</th>\n      <th>yahoo</th>\n      <th>year</th>\n      <th>yes</th>\n      <th>yield</th>\n      <th>yo</th>\n      <th>young</th>\n      <th>zone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.143700</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33336</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.015667</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.013857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33337</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.207355</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33338</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33339</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33340</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>33341 rows × 2100 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualização de dados com TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "E:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.00 GiB for an array with shape (4025, 33341) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m TSNE(n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m array_red \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdfTfidf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m df_tsne \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(array_red)\n\u001B[0;32m      6\u001B[0m df_tsne[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTarget\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m target\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1108\u001B[0m, in \u001B[0;36mTSNE.fit_transform\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m   1088\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1089\u001B[0m     \u001B[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001B[39;00m\n\u001B[0;32m   1090\u001B[0m \n\u001B[0;32m   1091\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1108\u001B[0m     embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1109\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_ \u001B[38;5;241m=\u001B[39m embedding\n\u001B[0;32m   1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:947\u001B[0m, in \u001B[0;36mTSNE._fit\u001B[1;34m(self, X, skip_num_points)\u001B[0m\n\u001B[0;32m    940\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    941\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[t-SNE] Indexed \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m samples in \u001B[39m\u001B[38;5;132;01m{:.3f}\u001B[39;00m\u001B[38;5;124ms...\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    942\u001B[0m             n_samples, duration\n\u001B[0;32m    943\u001B[0m         )\n\u001B[0;32m    944\u001B[0m     )\n\u001B[0;32m    946\u001B[0m t0 \u001B[38;5;241m=\u001B[39m time()\n\u001B[1;32m--> 947\u001B[0m distances_nn \u001B[38;5;241m=\u001B[39m \u001B[43mknn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkneighbors_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdistance\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    948\u001B[0m duration \u001B[38;5;241m=\u001B[39m time() \u001B[38;5;241m-\u001B[39m t0\n\u001B[0;32m    949\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\neighbors\\_base.py:886\u001B[0m, in \u001B[0;36mKNeighborsMixin.kneighbors_graph\u001B[1;34m(self, X, n_neighbors, mode)\u001B[0m\n\u001B[0;32m    883\u001B[0m     A_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mones(n_queries \u001B[38;5;241m*\u001B[39m n_neighbors)\n\u001B[0;32m    885\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistance\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 886\u001B[0m     A_data, A_ind \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkneighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_neighbors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    887\u001B[0m     A_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mravel(A_data)\n\u001B[0;32m    889\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\neighbors\\_base.py:752\u001B[0m, in \u001B[0;36mKNeighborsMixin.kneighbors\u001B[1;34m(self, X, n_neighbors, return_distance)\u001B[0m\n\u001B[0;32m    749\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    750\u001B[0m         kwds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meffective_metric_params_\n\u001B[1;32m--> 752\u001B[0m     chunked_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    753\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpairwise_distances_chunked\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    754\u001B[0m \u001B[43m            \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    755\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_X\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    756\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreduce_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreduce_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    757\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meffective_metric_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    758\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    759\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    760\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    761\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    763\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_method \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mball_tree\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkd_tree\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    764\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m issparse(X):\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1717\u001B[0m, in \u001B[0;36mpairwise_distances_chunked\u001B[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001B[0m\n\u001B[0;32m   1715\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1716\u001B[0m     X_chunk \u001B[38;5;241m=\u001B[39m X[sl]\n\u001B[1;32m-> 1717\u001B[0m D_chunk \u001B[38;5;241m=\u001B[39m pairwise_distances(X_chunk, Y, metric\u001B[38;5;241m=\u001B[39mmetric, n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m   1718\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (X \u001B[38;5;129;01mis\u001B[39;00m Y \u001B[38;5;129;01mor\u001B[39;00m Y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001B[38;5;241m.\u001B[39mget(\n\u001B[0;32m   1719\u001B[0m     metric, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1720\u001B[0m ) \u001B[38;5;129;01mis\u001B[39;00m euclidean_distances:\n\u001B[0;32m   1721\u001B[0m     \u001B[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001B[39;00m\n\u001B[0;32m   1722\u001B[0m     \u001B[38;5;66;03m# i.e. \"l2\"\u001B[39;00m\n\u001B[0;32m   1723\u001B[0m     D_chunk\u001B[38;5;241m.\u001B[39mflat[sl\u001B[38;5;241m.\u001B[39mstart :: _num_samples(X) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1889\u001B[0m, in \u001B[0;36mpairwise_distances\u001B[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001B[0m\n\u001B[0;32m   1886\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m distance\u001B[38;5;241m.\u001B[39msquareform(distance\u001B[38;5;241m.\u001B[39mpdist(X, metric\u001B[38;5;241m=\u001B[39mmetric, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds))\n\u001B[0;32m   1887\u001B[0m     func \u001B[38;5;241m=\u001B[39m partial(distance\u001B[38;5;241m.\u001B[39mcdist, metric\u001B[38;5;241m=\u001B[39mmetric, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m-> 1889\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1430\u001B[0m, in \u001B[0;36m_parallel_pairwise\u001B[1;34m(X, Y, func, n_jobs, **kwds)\u001B[0m\n\u001B[0;32m   1427\u001B[0m X, Y, dtype \u001B[38;5;241m=\u001B[39m _return_float_dtype(X, Y)\n\u001B[0;32m   1429\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m effective_n_jobs(n_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m-> 1430\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(X, Y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m   1432\u001B[0m \u001B[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001B[39;00m\n\u001B[0;32m   1433\u001B[0m fd \u001B[38;5;241m=\u001B[39m delayed(_dist_wrapper)\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:330\u001B[0m, in \u001B[0;36meuclidean_distances\u001B[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001B[0m\n\u001B[0;32m    324\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m Y_norm_squared\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (\u001B[38;5;241m1\u001B[39m, Y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m    325\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    326\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncompatible dimensions for Y of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mY\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    327\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mY_norm_squared of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moriginal_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    328\u001B[0m         )\n\u001B[1;32m--> 330\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_euclidean_distances\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_norm_squared\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_norm_squared\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msquared\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:371\u001B[0m, in \u001B[0;36m_euclidean_distances\u001B[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001B[0m\n\u001B[0;32m    368\u001B[0m     distances \u001B[38;5;241m=\u001B[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    370\u001B[0m     \u001B[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001B[39;00m\n\u001B[1;32m--> 371\u001B[0m     distances \u001B[38;5;241m=\u001B[39m \u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43msafe_sparse_dot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdense_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    372\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m XX\n\u001B[0;32m    373\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m YY\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 1.00 GiB for an array with shape (4025, 33341) and data type float64"
     ]
    }
   ],
   "source": [
    "model = TSNE(n_components=2, random_state=0)\n",
    "array_red = model.fit_transform(dfTfidf)\n",
    "\n",
    "df_tsne = pd.DataFrame(array_red)\n",
    "\n",
    "df_tsne['Target'] = target\n",
    "df_tsne_c1 = df_tsne[df_tsne['Target'] == 0]\n",
    "\n",
    "df_tsne_c2 = df_tsne[df_tsne['Target'] == 1]\n",
    "\n",
    "plt.scatter(df_tsne_c1[0].array,df_tsne_c1[1].array,marker='o',color='blue')\n",
    "\n",
    "plt.scatter(df_tsne_c2[0].array,df_tsne_c2[1].array,marker='o',color='red')\n",
    "\n",
    "plt.title('Dados')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    return DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(dfTfidf.values,target,test_size=0.2)\n",
    "modelo = getModel().fit(X_treino,y_treino)\n",
    "score = modelo.score(X_teste,y_teste)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(getModel(),dfTfidf.values,target,cv=10)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicoes = cross_val_predict(getModel(), dfTfidf.values, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report : \")\n",
    "print(classification_report(target, predicoes, target_names=[\"Ham\", \"Spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories = [\"Ham\", \"Spam\"]\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(\n",
    "    [categories[i] for i in target], [categories[i] for i in predicoes.tolist()],\n",
    "    title=\"Confusion Matrix\",\n",
    "    cmap=\"Purples\",\n",
    "    hide_zeros=True,\n",
    "    figsize=(5,5)\n",
    ")\n",
    "\n",
    "plt.xticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(\n",
    "    [categories[i] for i in target], [categories[i] for i in predicoes.tolist()],\n",
    "    normalize=True,\n",
    "    title=\"Confusion Matrix\",\n",
    "    cmap=\"Purples\",\n",
    "    hide_zeros=True,\n",
    "    figsize=(5,5)\n",
    ")\n",
    "\n",
    "plt.xticks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}