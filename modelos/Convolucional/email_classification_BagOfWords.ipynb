{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Carregando base de dados  pré-processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>start date     hourahead timee  cardinall  hou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service long desk  price structure deal quote ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>start date  cardinall    hourahead timee  card...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>start date     hourahead timee  cardinall  anc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cardinall deliverable revenue management marke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33340</th>\n",
       "      <td>bio  matrix scientific group   symbo   bmxg  p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33341</th>\n",
       "      <td>cardinall step away hot naked webcam girl liv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33342</th>\n",
       "      <td>need pill increase performance click  seroius ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33343</th>\n",
       "      <td>datee final nom       inlet hpl  eastrans  car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33344</th>\n",
       "      <td>ordinall time  offering male enhancement perfo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33341 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   email  target\n",
       "0      start date     hourahead timee  cardinall  hou...       0\n",
       "1      service long desk  price structure deal quote ...       0\n",
       "2      start date  cardinall    hourahead timee  card...       0\n",
       "3      start date     hourahead timee  cardinall  anc...       0\n",
       "4      cardinall deliverable revenue management marke...       0\n",
       "...                                                  ...     ...\n",
       "33340  bio  matrix scientific group   symbo   bmxg  p...       1\n",
       "33341   cardinall step away hot naked webcam girl liv...       1\n",
       "33342  need pill increase performance click  seroius ...       1\n",
       "33343  datee final nom       inlet hpl  eastrans  car...       0\n",
       "33344  ordinall time  offering male enhancement perfo...       1\n",
       "\n",
       "[33341 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../../Database/dataBaseWithNER.csv\")\n",
    "dataset = dataset.drop(columns=[\"Unnamed: 0\"])\n",
    "dataset = dataset.dropna()\n",
    "targets = np.array(dataset[\"target\"].array)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emailsText = []\n",
    "for email in dataset[\"email\"]:\n",
    "    emailsText.append(email)\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33341\n"
     ]
    }
   ],
   "source": [
    "print(len(emailsText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Representação vetorial Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>accepted</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>...</th>\n",
       "      <th>xanax</th>\n",
       "      <th>xl</th>\n",
       "      <th>xp</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yield</th>\n",
       "      <th>yo</th>\n",
       "      <th>young</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33338</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33339</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33340</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33341 rows × 2100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  ability  able  absolutely  abuse  accept  acceptance  accepted  \\\n",
       "0       0        0     0           0      0       0           0         0   \n",
       "1       0        0     0           0      0       0           0         0   \n",
       "2       0        0     0           0      0       0           0         0   \n",
       "3       0        0     0           0      0       0           0         0   \n",
       "4       0        0     0           0      0       0           0         0   \n",
       "...    ..      ...   ...         ...    ...     ...         ...       ...   \n",
       "33336   0        0     0           0      0       0           1         0   \n",
       "33337   0        0     0           0      0       0           0         0   \n",
       "33338   0        0     0           0      0       0           0         0   \n",
       "33339   0        0     0           0      0       0           0         0   \n",
       "33340   0        0     0           0      0       0           0         0   \n",
       "\n",
       "       access  according  ...  xanax  xl  xp  yahoo  year  yes  yield  yo  \\\n",
       "0           0          0  ...      0   0   0      0     0    0      0   0   \n",
       "1           0          0  ...      0   0   0      0     0    0      0   0   \n",
       "2           0          0  ...      0   0   0      0     0    0      0   0   \n",
       "3           0          0  ...      0   0   0      0     0    0      0   0   \n",
       "4           1          0  ...      0   0   0      0     0    0      0   0   \n",
       "...       ...        ...  ...    ...  ..  ..    ...   ...  ...    ...  ..   \n",
       "33336       0          0  ...      0   0   0      1     0    0      0   0   \n",
       "33337       1          0  ...      0   0   0      0     0    0      0   0   \n",
       "33338       0          0  ...      0   0   0      0     0    0      0   0   \n",
       "33339       0          0  ...      0   0   0      0     0    0      0   0   \n",
       "33340       0          0  ...      0   0   0      0     0    0      0   0   \n",
       "\n",
       "       young  zone  \n",
       "0          0     0  \n",
       "1          0     0  \n",
       "2          0     0  \n",
       "3          0     0  \n",
       "4          0     0  \n",
       "...      ...   ...  \n",
       "33336      0     0  \n",
       "33337      0     0  \n",
       "33338      0     0  \n",
       "33339      0     0  \n",
       "33340      0     0  \n",
       "\n",
       "[33341 rows x 2100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=2100)\n",
    "X = vectorizer.fit_transform(emailsText)\n",
    "\n",
    "bag = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "del emailsText\n",
    "del X\n",
    "\n",
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bag = np.array(bag)\n",
    "bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualização de dados com TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#model = TSNE(n_components=2, random_state=0)\n",
    "##model = PCA(n_components=50, svd_solver='full')\n",
    "#array_red = model.fit_transform(bag)\n",
    "#\n",
    "#df_tsne = pd.DataFrame(array_red)\n",
    "#\n",
    "#df_tsne['Target'] = target\n",
    "#df_tsne_c1 = df_tsne[df_tsne['Target'] == 0]\n",
    "#\n",
    "#df_tsne_c2 = df_tsne[df_tsne['Target'] == 1]\n",
    "#\n",
    "#plt.scatter(df_tsne_c1[0].array,df_tsne_c1[1].array,marker='o',color='blue')\n",
    "#\n",
    "#plt.scatter(df_tsne_c2[0].array,df_tsne_c2[1].array,marker='o',color='red')\n",
    "#\n",
    "#plt.title('Dados')\n",
    "#plt.xlabel('x')\n",
    "#plt.ylabel('y')\n",
    "#\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26672, 1, 2100)\n"
     ]
    }
   ],
   "source": [
    "X_treino = np.array(X_treino)\n",
    "\n",
    "X_treino = X_treino.reshape((X_treino.shape[0],1,X_treino.shape[1]))\n",
    "print(X_treino.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "foldsAccuracy = []\n",
    "foldLosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Iniciando treinamento da fold: 1.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 4s 3ms/step - loss: 0.3499 - accuracy: 0.8889 - val_loss: 0.1727 - val_accuracy: 0.9440 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.2207 - accuracy: 0.9410 - val_loss: 0.1448 - val_accuracy: 0.9528 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1933 - accuracy: 0.9501 - val_loss: 0.1184 - val_accuracy: 0.9600 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1385 - accuracy: 0.9627 - val_loss: 0.0856 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1287 - accuracy: 0.9648 - val_loss: 0.1275 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.9768 - val_loss: 0.0639 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0893 - accuracy: 0.9764 - val_loss: 0.0666 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.0559 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0609 - accuracy: 0.9839 - val_loss: 0.0539 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.9827 - val_loss: 0.0682 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0445 - accuracy: 0.9865 - val_loss: 0.0527 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.0443 - val_accuracy: 0.9864 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0449 - accuracy: 0.9882 - val_loss: 0.0532 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 0.0550 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.0423 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.0417 - val_accuracy: 0.9864 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.0495 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.0448 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.0426 - val_accuracy: 0.9856 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.0431 - val_accuracy: 0.9856 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0254 - accuracy: 0.9946 - val_loss: 0.0464 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.0476 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "742/743 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9961\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.0538 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0147 - accuracy: 0.9963 - val_loss: 0.0478 - val_accuracy: 0.9872 - lr: 1.0000e-03\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.0466 - val_accuracy: 0.9864 - lr: 1.0000e-03\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.0462 - val_accuracy: 0.9864 - lr: 1.0000e-03\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.0456 - val_accuracy: 0.9864 - lr: 1.0000e-03\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 0.0448 - val_accuracy: 0.9880 - lr: 1.0000e-03\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0452 - val_accuracy: 0.9864 - lr: 1.0000e-03\n",
      "Epoch 30/200\n",
      "743/743 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9971\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0453 - val_accuracy: 0.9864 - lr: 1.0000e-03\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0453 - val_accuracy: 0.9864 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0453 - val_accuracy: 0.9864 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0452 - val_accuracy: 0.9864 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0452 - val_accuracy: 0.9864 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0452 - val_accuracy: 0.9864 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0453 - val_accuracy: 0.9864 - lr: 1.0000e-04\n",
      "Score fold 1: loss de 0.09102164953947067; accuracy de 97.5287914276123%\n",
      "****************************************************\n",
      "Iniciando treinamento da fold: 2.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.3240 - accuracy: 0.8913 - val_loss: 0.1648 - val_accuracy: 0.9472 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1536 - accuracy: 0.9546 - val_loss: 0.1026 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1171 - accuracy: 0.9664 - val_loss: 0.0876 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1908 - accuracy: 0.9588 - val_loss: 0.2787 - val_accuracy: 0.8857 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.2247 - accuracy: 0.9499 - val_loss: 0.7121 - val_accuracy: 0.7066 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.2149 - accuracy: 0.9278 - val_loss: 0.1107 - val_accuracy: 0.9560 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1031 - accuracy: 0.9687 - val_loss: 0.0864 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0813 - accuracy: 0.9749 - val_loss: 0.0697 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0574 - accuracy: 0.9812 - val_loss: 0.0616 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0571 - accuracy: 0.9828 - val_loss: 0.0590 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.0565 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0400 - accuracy: 0.9888 - val_loss: 0.0586 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.9845 - val_loss: 0.0612 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0520 - accuracy: 0.9876 - val_loss: 0.0577 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.0558 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0267 - accuracy: 0.9929 - val_loss: 0.0529 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0285 - accuracy: 0.9924 - val_loss: 0.0543 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0551 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0538 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0242 - accuracy: 0.9939 - val_loss: 0.0588 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.0556 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.0555 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "723/743 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9959\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0590 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 0.0571 - val_accuracy: 0.9800 - lr: 1.0000e-03\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0572 - val_accuracy: 0.9792 - lr: 1.0000e-03\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0574 - val_accuracy: 0.9792 - lr: 1.0000e-03\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0574 - val_accuracy: 0.9800 - lr: 1.0000e-03\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0573 - val_accuracy: 0.9800 - lr: 1.0000e-03\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 0.0575 - val_accuracy: 0.9800 - lr: 1.0000e-03\n",
      "Epoch 30/200\n",
      "727/743 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9972\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0576 - val_accuracy: 0.9800 - lr: 1.0000e-03\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0576 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0576 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0576 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0577 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0576 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0576 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Score fold 2: loss de 0.07085882872343063; accuracy de 97.69645929336548%\n",
      "****************************************************\n",
      "Iniciando treinamento da fold: 3.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.3803 - accuracy: 0.8760 - val_loss: 0.2134 - val_accuracy: 0.9289 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1821 - accuracy: 0.9490 - val_loss: 0.1158 - val_accuracy: 0.9544 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1020 - accuracy: 0.9676 - val_loss: 0.0948 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1083 - accuracy: 0.9695 - val_loss: 0.0758 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0898 - accuracy: 0.9764 - val_loss: 0.0679 - val_accuracy: 0.9704 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0528 - accuracy: 0.9830 - val_loss: 0.0603 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0965 - accuracy: 0.9750 - val_loss: 0.0856 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1049 - accuracy: 0.9779 - val_loss: 0.2473 - val_accuracy: 0.8753 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.1069 - accuracy: 0.9722 - val_loss: 0.0636 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0587 - accuracy: 0.9830 - val_loss: 0.0533 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0661 - accuracy: 0.9831 - val_loss: 0.0547 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.0523 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0927 - accuracy: 0.9835 - val_loss: 0.0602 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.9795 - val_loss: 0.0544 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0449 - accuracy: 0.9874 - val_loss: 0.0558 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0450 - accuracy: 0.9873 - val_loss: 0.0497 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 0.0532 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 0.0515 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0463 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0453 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0457 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.0481 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0502 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0512 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0589 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 2ms/step - loss: 0.0404 - accuracy: 0.9922 - val_loss: 0.0557 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "  1/743 [..............................] - ETA: 1s - loss: 0.0097 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "foldCount = 1\n",
    "for train, test in kfold.split(bag, targets):\n",
    "    model = keras.models.Sequential([\n",
    "        ########## MLP\n",
    "        keras.layers.Flatten(input_shape=(bag.shape[1],)),\n",
    "        #keras.layers.Dense(300, activation=\"relu\"),\n",
    "        keras.layers.Dense(1000, activation=\"relu\"),\n",
    "        keras.layers.Dense(300, activation=\"relu\"),\n",
    "        keras.layers.Dense(100, activation=\"relu\"),\n",
    "\n",
    "        keras.layers.Dense(len(set(targets)), activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=['accuracy'])\n",
    "\n",
    "    print('****************************************************')\n",
    "    print(f'Iniciando treinamento da fold: {foldCount}.')\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4,mode='min'), tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0, restore_best_weights=True)]\n",
    "\n",
    "    history = model.fit(bag[train], targets[train], epochs=200, callbacks=callbacks, validation_split=0.05)\n",
    "\n",
    "    scores = model.evaluate(bag[test], targets[test], verbose=0)\n",
    "    print(f'Score fold {foldCount}: {model.metrics_names[0]} de {scores[0]}; {model.metrics_names[1]} de {scores[1]*100}%')\n",
    "\n",
    "    foldsAccuracy.append(scores[1] * 100)\n",
    "    foldLosses.append(scores[0])\n",
    "\n",
    "    foldCount = foldCount + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('****************************************************')\n",
    "print('Score de cada fold:')\n",
    "for i in range(0, len(foldsAccuracy)):\n",
    "    print('****************************************************')\n",
    "    print(f'--> Fold {i+1}: Loss: {foldLosses[i]} ; Accuracy: {foldsAccuracy[i]}%')\n",
    "\n",
    "print('****************************************************')\n",
    "print('Média de accuracy das folds:')\n",
    "print(f'--> Accuracy: {np.mean(foldsAccuracy)} (+- {np.std(foldsAccuracy)})')\n",
    "print(f'--> Loss: {np.mean(foldLosses)}')\n",
    "print('****************************************************')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}