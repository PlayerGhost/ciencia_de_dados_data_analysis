{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from simpletransformers.language_representation import RepresentationModel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Carregando base de dados  pré-processada"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   email  target\n0      start date     hourahead timee  cardinall  hou...       0\n1      service long desk  price structure deal quote ...       0\n2      start date  cardinall    hourahead timee  card...       0\n3      start date     hourahead timee  cardinall  anc...       0\n4      cardinall deliverable revenue management marke...       0\n...                                                  ...     ...\n33340  bio  matrix scientific group   symbo   bmxg  p...       1\n33341   cardinall step away hot naked webcam girl liv...       1\n33342  need pill increase performance click  seroius ...       1\n33343  datee final nom       inlet hpl  eastrans  car...       0\n33344  ordinall time  offering male enhancement perfo...       1\n\n[33341 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>start date     hourahead timee  cardinall  hou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>service long desk  price structure deal quote ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>start date  cardinall    hourahead timee  card...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>start date     hourahead timee  cardinall  anc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cardinall deliverable revenue management marke...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33340</th>\n      <td>bio  matrix scientific group   symbo   bmxg  p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33341</th>\n      <td>cardinall step away hot naked webcam girl liv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33342</th>\n      <td>need pill increase performance click  seroius ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33343</th>\n      <td>datee final nom       inlet hpl  eastrans  car...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33344</th>\n      <td>ordinall time  offering male enhancement perfo...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>33341 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = pd.read_csv(\"../../Database/dataBaseWithNER.csv\")\n",
    "\n",
    "database = database.drop(columns=[\"Unnamed: 0\"])\n",
    "database = database.dropna()\n",
    "target = database[\"target\"].values.tolist()\n",
    "database"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "emailsText = []\n",
    "for email in database[\"email\"]:\n",
    "    emailsText.append(email)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33341\n"
     ]
    }
   ],
   "source": [
    "print(len(emailsText))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Representação vetorial GPT2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at gpt2 were not used when initializing GPT2ForTextRepresentation: ['h.9.mlp.c_fc.bias', 'h.2.ln_1.bias', 'h.9.attn.c_attn.bias', 'h.3.attn.bias', 'h.11.ln_1.weight', 'h.3.ln_2.weight', 'h.3.mlp.c_fc.bias', 'h.2.ln_2.bias', 'h.1.ln_1.weight', 'h.1.ln_2.weight', 'h.9.mlp.c_fc.weight', 'h.8.attn.c_proj.bias', 'h.2.mlp.c_proj.bias', 'h.4.ln_1.bias', 'h.8.attn.c_attn.bias', 'h.10.attn.bias', 'h.9.ln_2.weight', 'h.9.mlp.c_proj.weight', 'h.6.mlp.c_fc.bias', 'h.4.mlp.c_proj.weight', 'h.2.attn.c_attn.bias', 'h.11.ln_2.bias', 'h.5.attn.c_proj.bias', 'h.1.mlp.c_proj.weight', 'h.1.mlp.c_fc.bias', 'h.0.mlp.c_proj.weight', 'h.6.attn.c_proj.weight', 'h.3.ln_1.weight', 'h.10.mlp.c_proj.bias', 'h.0.ln_1.bias', 'h.9.ln_1.bias', 'h.10.ln_2.bias', 'h.8.mlp.c_proj.weight', 'h.9.attn.c_proj.bias', 'h.1.attn.bias', 'h.4.attn.c_proj.bias', 'h.8.ln_1.bias', 'h.7.mlp.c_proj.bias', 'h.9.attn.c_attn.weight', 'h.6.ln_1.weight', 'h.5.attn.c_proj.weight', 'h.4.ln_1.weight', 'h.6.ln_1.bias', 'h.6.mlp.c_fc.weight', 'h.8.ln_2.bias', 'h.1.attn.c_attn.bias', 'ln_f.bias', 'h.5.ln_2.bias', 'h.1.attn.c_attn.weight', 'h.3.ln_2.bias', 'h.7.mlp.c_fc.weight', 'h.2.mlp.c_fc.weight', 'h.5.ln_1.bias', 'h.7.ln_1.weight', 'h.8.mlp.c_fc.weight', 'h.10.attn.c_attn.bias', 'wte.weight', 'h.4.attn.c_attn.bias', 'h.6.ln_2.weight', 'h.3.attn.c_proj.bias', 'h.7.ln_2.weight', 'h.9.attn.bias', 'h.1.mlp.c_proj.bias', 'h.3.ln_1.bias', 'h.3.mlp.c_proj.weight', 'h.6.ln_2.bias', 'h.7.attn.c_attn.weight', 'h.10.mlp.c_proj.weight', 'h.11.mlp.c_proj.weight', 'h.11.attn.c_proj.weight', 'h.0.mlp.c_fc.weight', 'h.5.mlp.c_proj.bias', 'h.9.ln_2.bias', 'h.8.attn.c_attn.weight', 'h.2.mlp.c_proj.weight', 'h.10.ln_2.weight', 'h.7.ln_1.bias', 'h.4.attn.c_attn.weight', 'h.6.mlp.c_proj.weight', 'h.7.ln_2.bias', 'h.8.ln_2.weight', 'h.1.ln_2.bias', 'h.10.attn.c_proj.bias', 'h.7.attn.c_proj.weight', 'h.7.mlp.c_fc.bias', 'h.3.attn.c_attn.bias', 'h.4.ln_2.bias', 'h.0.attn.c_attn.weight', 'h.11.ln_2.weight', 'h.3.attn.c_attn.weight', 'h.6.attn.bias', 'h.10.attn.c_proj.weight', 'h.5.mlp.c_proj.weight', 'h.9.ln_1.weight', 'h.8.mlp.c_proj.bias', 'h.3.mlp.c_fc.weight', 'h.6.mlp.c_proj.bias', 'h.5.ln_1.weight', 'h.10.mlp.c_fc.bias', 'h.0.ln_1.weight', 'h.2.mlp.c_fc.bias', 'h.2.attn.c_attn.weight', 'h.11.mlp.c_fc.weight', 'h.0.attn.c_proj.bias', 'h.2.ln_1.weight', 'h.0.mlp.c_fc.bias', 'h.0.attn.c_proj.weight', 'wpe.weight', 'h.7.attn.c_attn.bias', 'h.5.attn.c_attn.weight', 'h.6.attn.c_attn.weight', 'h.8.ln_1.weight', 'h.11.mlp.c_fc.bias', 'h.5.attn.bias', 'h.11.attn.c_proj.bias', 'h.4.mlp.c_fc.weight', 'h.10.attn.c_attn.weight', 'h.0.attn.c_attn.bias', 'h.2.attn.bias', 'h.8.attn.c_proj.weight', 'h.10.ln_1.bias', 'ln_f.weight', 'h.4.attn.bias', 'h.0.attn.bias', 'h.5.ln_2.weight', 'h.6.attn.c_attn.bias', 'h.7.attn.bias', 'h.11.ln_1.bias', 'h.11.attn.c_attn.bias', 'h.4.ln_2.weight', 'h.1.attn.c_proj.weight', 'h.3.attn.c_proj.weight', 'h.6.attn.c_proj.bias', 'h.10.ln_1.weight', 'h.7.mlp.c_proj.weight', 'h.8.attn.bias', 'h.1.mlp.c_fc.weight', 'h.5.attn.c_attn.bias', 'h.11.attn.bias', 'h.9.mlp.c_proj.bias', 'h.0.ln_2.bias', 'h.5.mlp.c_fc.bias', 'h.4.mlp.c_fc.bias', 'h.9.attn.c_proj.weight', 'h.5.mlp.c_fc.weight', 'h.2.ln_2.weight', 'h.4.mlp.c_proj.bias', 'h.0.mlp.c_proj.bias', 'h.1.attn.c_proj.bias', 'h.11.mlp.c_proj.bias', 'h.2.attn.c_proj.weight', 'h.2.attn.c_proj.bias', 'h.7.attn.c_proj.bias', 'h.11.attn.c_attn.weight', 'h.4.attn.c_proj.weight', 'h.10.mlp.c_fc.weight', 'h.8.mlp.c_fc.bias', 'h.1.ln_1.bias', 'h.3.mlp.c_proj.bias', 'h.0.ln_2.weight']\n",
      "- This IS expected if you are initializing GPT2ForTextRepresentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForTextRepresentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForTextRepresentation were not initialized from the model checkpoint at gpt2 and are newly initialized: ['gpt2.h.9.mlp.c_proj.weight', 'gpt2.h.7.mlp.c_proj.bias', 'gpt2.h.0.attn.c_attn.weight', 'gpt2.h.6.mlp.c_fc.bias', 'gpt2.h.5.mlp.c_fc.weight', 'gpt2.h.0.ln_1.weight', 'gpt2.h.10.attn.c_proj.bias', 'gpt2.h.9.attn.c_proj.weight', 'gpt2.h.8.attn.c_attn.weight', 'gpt2.h.2.ln_2.bias', 'gpt2.h.8.attn.masked_bias', 'gpt2.h.8.attn.bias', 'gpt2.ln_f.weight', 'gpt2.h.2.ln_2.weight', 'gpt2.h.2.attn.c_attn.bias', 'gpt2.h.2.attn.c_proj.weight', 'gpt2.h.1.attn.c_proj.bias', 'gpt2.h.1.attn.c_attn.bias', 'gpt2.h.4.ln_1.weight', 'gpt2.h.4.attn.c_attn.bias', 'gpt2.h.0.ln_1.bias', 'gpt2.h.0.ln_2.weight', 'gpt2.wte.weight', 'gpt2.h.4.attn.c_proj.weight', 'gpt2.h.4.mlp.c_fc.bias', 'gpt2.h.0.attn.masked_bias', 'gpt2.h.3.mlp.c_proj.bias', 'gpt2.h.11.attn.masked_bias', 'gpt2.h.8.mlp.c_proj.bias', 'gpt2.h.9.attn.c_attn.weight', 'gpt2.h.9.mlp.c_fc.bias', 'gpt2.h.0.attn.c_proj.bias', 'gpt2.h.9.attn.masked_bias', 'gpt2.h.10.mlp.c_fc.weight', 'gpt2.h.9.mlp.c_fc.weight', 'gpt2.h.7.attn.c_proj.bias', 'gpt2.h.7.attn.c_attn.bias', 'gpt2.h.9.ln_1.weight', 'gpt2.h.1.attn.masked_bias', 'gpt2.h.2.attn.c_proj.bias', 'gpt2.h.3.mlp.c_fc.weight', 'gpt2.h.1.mlp.c_proj.weight', 'gpt2.h.4.ln_2.weight', 'gpt2.h.2.ln_1.weight', 'gpt2.h.0.attn.c_attn.bias', 'gpt2.h.5.attn.c_proj.weight', 'gpt2.h.3.attn.c_attn.bias', 'gpt2.h.7.attn.masked_bias', 'gpt2.h.0.mlp.c_proj.bias', 'gpt2.h.5.attn.c_proj.bias', 'gpt2.h.7.attn.bias', 'gpt2.h.2.mlp.c_fc.weight', 'gpt2.h.1.mlp.c_proj.bias', 'gpt2.h.4.attn.c_proj.bias', 'gpt2.h.6.ln_2.bias', 'gpt2.h.7.attn.c_attn.weight', 'gpt2.h.5.mlp.c_fc.bias', 'gpt2.h.5.mlp.c_proj.weight', 'gpt2.h.10.attn.c_attn.bias', 'gpt2.h.10.attn.bias', 'gpt2.h.8.attn.c_attn.bias', 'gpt2.wpe.weight', 'gpt2.h.2.mlp.c_proj.weight', 'gpt2.h.6.attn.c_proj.bias', 'gpt2.h.0.mlp.c_fc.bias', 'gpt2.h.7.ln_2.weight', 'gpt2.h.6.ln_1.weight', 'gpt2.h.4.attn.masked_bias', 'gpt2.h.0.mlp.c_fc.weight', 'gpt2.h.6.ln_2.weight', 'gpt2.h.6.attn.c_proj.weight', 'gpt2.h.7.mlp.c_fc.bias', 'gpt2.h.8.mlp.c_proj.weight', 'gpt2.h.11.mlp.c_proj.weight', 'gpt2.h.1.attn.c_proj.weight', 'gpt2.h.10.ln_2.bias', 'gpt2.h.3.ln_1.bias', 'gpt2.h.0.attn.bias', 'gpt2.h.8.ln_2.weight', 'gpt2.h.8.attn.c_proj.bias', 'gpt2.h.11.ln_2.weight', 'gpt2.h.4.attn.c_attn.weight', 'gpt2.h.7.mlp.c_proj.weight', 'gpt2.h.3.attn.c_proj.weight', 'gpt2.h.10.mlp.c_proj.bias', 'gpt2.h.3.mlp.c_proj.weight', 'gpt2.h.1.mlp.c_fc.bias', 'gpt2.h.9.ln_2.bias', 'gpt2.h.11.attn.bias', 'gpt2.h.8.attn.c_proj.weight', 'gpt2.h.3.ln_2.weight', 'gpt2.h.6.attn.c_attn.bias', 'gpt2.h.1.ln_2.weight', 'gpt2.h.3.attn.c_attn.weight', 'gpt2.h.5.ln_2.bias', 'gpt2.h.6.mlp.c_proj.bias', 'gpt2.h.2.attn.bias', 'gpt2.h.6.mlp.c_proj.weight', 'gpt2.h.9.ln_1.bias', 'gpt2.h.3.ln_1.weight', 'gpt2.h.6.attn.masked_bias', 'gpt2.ln_f.bias', 'gpt2.h.7.ln_1.weight', 'gpt2.h.5.ln_1.bias', 'gpt2.h.10.ln_1.weight', 'gpt2.h.1.ln_1.weight', 'gpt2.h.1.ln_2.bias', 'gpt2.h.7.attn.c_proj.weight', 'gpt2.h.3.ln_2.bias', 'gpt2.h.4.mlp.c_proj.bias', 'gpt2.h.11.attn.c_attn.weight', 'gpt2.h.10.mlp.c_fc.bias', 'gpt2.h.2.attn.c_attn.weight', 'gpt2.h.5.ln_2.weight', 'gpt2.h.8.ln_1.weight', 'gpt2.h.3.attn.c_proj.bias', 'gpt2.h.10.ln_2.weight', 'gpt2.h.1.mlp.c_fc.weight', 'gpt2.h.9.attn.c_proj.bias', 'gpt2.h.8.mlp.c_fc.bias', 'gpt2.h.6.attn.c_attn.weight', 'gpt2.h.7.mlp.c_fc.weight', 'gpt2.h.11.attn.c_proj.bias', 'gpt2.h.1.attn.bias', 'gpt2.h.1.ln_1.bias', 'gpt2.h.0.mlp.c_proj.weight', 'gpt2.h.11.mlp.c_proj.bias', 'gpt2.h.11.attn.c_attn.bias', 'gpt2.h.4.ln_2.bias', 'gpt2.h.5.ln_1.weight', 'gpt2.h.10.ln_1.bias', 'gpt2.h.4.mlp.c_fc.weight', 'gpt2.h.11.ln_1.bias', 'gpt2.h.4.mlp.c_proj.weight', 'gpt2.h.10.mlp.c_proj.weight', 'gpt2.h.6.ln_1.bias', 'gpt2.h.7.ln_2.bias', 'gpt2.h.0.attn.c_proj.weight', 'gpt2.h.11.ln_2.bias', 'gpt2.h.6.mlp.c_fc.weight', 'gpt2.h.7.ln_1.bias', 'gpt2.h.10.attn.masked_bias', 'gpt2.h.5.attn.masked_bias', 'gpt2.h.11.ln_1.weight', 'gpt2.h.4.attn.bias', 'gpt2.h.0.ln_2.bias', 'gpt2.h.3.attn.bias', 'gpt2.h.10.attn.c_attn.weight', 'gpt2.h.5.attn.bias', 'gpt2.h.11.mlp.c_fc.weight', 'gpt2.h.9.attn.bias', 'gpt2.h.2.mlp.c_fc.bias', 'gpt2.h.9.ln_2.weight', 'gpt2.h.3.attn.masked_bias', 'gpt2.h.4.ln_1.bias', 'gpt2.h.5.mlp.c_proj.bias', 'gpt2.h.2.attn.masked_bias', 'gpt2.h.8.ln_1.bias', 'gpt2.h.1.attn.c_attn.weight', 'gpt2.h.9.mlp.c_proj.bias', 'gpt2.h.11.mlp.c_fc.bias', 'gpt2.h.9.attn.c_attn.bias', 'gpt2.h.6.attn.bias', 'gpt2.h.8.ln_2.bias', 'gpt2.h.2.mlp.c_proj.bias', 'gpt2.h.3.mlp.c_fc.bias', 'gpt2.h.2.ln_1.bias', 'gpt2.h.5.attn.c_attn.weight', 'gpt2.h.10.attn.c_proj.weight', 'gpt2.h.11.attn.c_proj.weight', 'gpt2.h.8.mlp.c_fc.weight', 'gpt2.h.5.attn.c_attn.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m model\u001B[38;5;241m=\u001B[39mRepresentationModel(\n\u001B[0;32m      2\u001B[0m     model_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt2\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      3\u001B[0m     model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt2\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      4\u001B[0m     use_cuda\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m#fp16=True\u001B[39;00m\n\u001B[0;32m      6\u001B[0m )\n\u001B[1;32m----> 8\u001B[0m vectorialRepresentation \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_sentences\u001B[49m\u001B[43m(\u001B[49m\u001B[43memailsText\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcombine_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmean\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m vectorialRepresentation\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\simpletransformers\\language_representation\\representation_model.py:214\u001B[0m, in \u001B[0;36mRepresentationModel.encode_sentences\u001B[1;34m(self, text_list, combine_strategy, batch_size)\u001B[0m\n\u001B[0;32m    208\u001B[0m             token_vectors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\n\u001B[0;32m    209\u001B[0m                 input_ids\u001B[38;5;241m=\u001B[39mencoded[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice),\n\u001B[0;32m    210\u001B[0m                 attention_mask\u001B[38;5;241m=\u001B[39mencoded[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice),\n\u001B[0;32m    211\u001B[0m                 token_type_ids\u001B[38;5;241m=\u001B[39mencoded[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice),\n\u001B[0;32m    212\u001B[0m             )\n\u001B[0;32m    213\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 214\u001B[0m             token_vectors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m                \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoded\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput_ids\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[43m                \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoded\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mattention_mask\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m     embeddings\u001B[38;5;241m.\u001B[39mappend(embedding_func(token_vectors)\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[0;32m    219\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(embeddings, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\simpletransformers\\language_representation\\transformer_models\\gpt2_model.py:27\u001B[0m, in \u001B[0;36mGPT2ForTextRepresentation.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     21\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     26\u001B[0m ):\n\u001B[1;32m---> 27\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgpt2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mE:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:792\u001B[0m, in \u001B[0;36mGPT2Model.forward\u001B[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    790\u001B[0m     past_length \u001B[38;5;241m=\u001B[39m past_key_values[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    791\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m position_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 792\u001B[0m     position_ids \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpast_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mpast_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlong\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    793\u001B[0m     position_ids \u001B[38;5;241m=\u001B[39m position_ids\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, input_shape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    795\u001B[0m \u001B[38;5;66;03m# GPT2Attention mask.\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model=RepresentationModel(\n",
    "    model_type=\"gpt2\",\n",
    "    model_name=\"gpt2\",\n",
    "    use_cuda=True,\n",
    "    #fp16=True\n",
    ")\n",
    "\n",
    "vectorialRepresentation = model.encode_sentences(emailsText, combine_strategy=\"mean\")\n",
    "vectorialRepresentation.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpt2Dataframe = pd.DataFrame(vectorialRepresentation)\n",
    "gpt2Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualização de dados com TSNE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2, random_state=0)\n",
    "array_red = model.fit_transform(gpt2Dataframe)\n",
    "\n",
    "df_tsne = pd.DataFrame(array_red)\n",
    "\n",
    "df_tsne['Target'] = target\n",
    "print(df_tsne)\n",
    "df_tsne_c1 = df_tsne[df_tsne['Target'] == 0]\n",
    "\n",
    "df_tsne_c2 = df_tsne[df_tsne['Target'] == 1]\n",
    "\n",
    "plt.scatter(df_tsne_c1[0].array,df_tsne_c1[1].array,marker='o',color='blue')\n",
    "\n",
    "plt.scatter(df_tsne_c2[0].array,df_tsne_c2[1].array,marker='o',color='red')\n",
    "\n",
    "plt.title('Dados')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validação"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    return RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(gpt2Dataframe.values,target,test_size=0.2)\n",
    "modelo = getModel().fit(X_treino,y_treino)\n",
    "score = modelo.score(X_teste,y_teste)\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = cross_val_score(getModel(),gpt2Dataframe.values,target,cv=10)\n",
    "\n",
    "scores.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicoes = cross_val_predict(getModel(), gpt2Dataframe.values, target, cv=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report : \")\n",
    "print(classification_report(target, predicoes, target_names=[\"Ham\", \"Spam\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categories = [\"Ham\", \"Spam\"]\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(\n",
    "    [categories[i] for i in target], [categories[i] for i in predicoes.tolist()],\n",
    "    title=\"Confusion Matrix\",\n",
    "    cmap=\"Purples\",\n",
    "    hide_zeros=True,\n",
    "    figsize=(5,5)\n",
    ")\n",
    "\n",
    "plt.xticks()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(\n",
    "    [categories[i] for i in target], [categories[i] for i in predicoes.tolist()],\n",
    "    normalize=True,\n",
    "    title=\"Confusion Matrix\",\n",
    "    cmap=\"Purples\",\n",
    "    hide_zeros=True,\n",
    "    figsize=(5,5)\n",
    ")\n",
    "\n",
    "plt.xticks()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}