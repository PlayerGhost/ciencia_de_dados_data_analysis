{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T07:48:04.385408Z",
     "start_time": "2022-05-05T07:48:03.008408Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Carregando base de dados  pré-processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   email  target\n0      start date     hourahead timee  cardinall  hou...       0\n1      service long desk  price structure deal quote ...       0\n2      start date  cardinall    hourahead timee  card...       0\n3      start date     hourahead timee  cardinall  anc...       0\n4      cardinall deliverable revenue management marke...       0\n...                                                  ...     ...\n33340  bio  matrix scientific group   symbo   bmxg  p...       1\n33341   cardinall step away hot naked webcam girl liv...       1\n33342  need pill increase performance click  seroius ...       1\n33343  datee final nom       inlet hpl  eastrans  car...       0\n33344  ordinall time  offering male enhancement perfo...       1\n\n[33341 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>start date     hourahead timee  cardinall  hou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>service long desk  price structure deal quote ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>start date  cardinall    hourahead timee  card...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>start date     hourahead timee  cardinall  anc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cardinall deliverable revenue management marke...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33340</th>\n      <td>bio  matrix scientific group   symbo   bmxg  p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33341</th>\n      <td>cardinall step away hot naked webcam girl liv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33342</th>\n      <td>need pill increase performance click  seroius ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33343</th>\n      <td>datee final nom       inlet hpl  eastrans  car...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33344</th>\n      <td>ordinall time  offering male enhancement perfo...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>33341 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../../Database/dataBaseWithNER.csv\")\n",
    "dataset = dataset.drop(columns=[\"Unnamed: 0\"])\n",
    "dataset = dataset.dropna()\n",
    "targets = np.array(dataset[\"target\"].array)\n",
    "\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "emailsText = []\n",
    "for email in dataset[\"email\"]:\n",
    "    emailsText.append(email)\n",
    "\n",
    "del dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33341\n"
     ]
    }
   ],
   "source": [
    "print(len(emailsText))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Representação vetorial TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1593)\t0.26470874972054786\n",
      "  (0, 1098)\t0.35510965844285625\n",
      "  (0, 671)\t0.34195431682743727\n",
      "  (0, 535)\t0.3142974755284843\n",
      "  (0, 1663)\t0.2523502664970415\n",
      "  (0, 249)\t0.0882891907360702\n",
      "  (0, 1904)\t0.14585506953003874\n",
      "  (0, 861)\t0.6284245513555586\n",
      "  (0, 440)\t0.21615559903629922\n",
      "  (0, 1796)\t0.23177737406989862\n",
      "  (1, 1893)\t0.12322552160237797\n",
      "  (1, 432)\t0.16667910623163265\n",
      "  (1, 1405)\t0.2023515027069684\n",
      "  (1, 1910)\t0.21821281232441633\n",
      "  (1, 773)\t0.252147976524646\n",
      "  (1, 1814)\t0.24651126769711865\n",
      "  (1, 2073)\t0.1442701571707954\n",
      "  (1, 1342)\t0.19540664510107641\n",
      "  (1, 1962)\t0.21745283397516152\n",
      "  (1, 809)\t0.3089620245082559\n",
      "  (1, 1457)\t0.1585651873255142\n",
      "  (1, 297)\t0.26945510026530634\n",
      "  (1, 1102)\t0.268483606738479\n",
      "  (1, 105)\t0.2304674552193428\n",
      "  (1, 1514)\t0.2375975711797802\n",
      "  :\t:\n",
      "  (33340, 734)\t0.1499328111246709\n",
      "  (33340, 1274)\t0.08454655116352783\n",
      "  (33340, 1509)\t0.09899129231263658\n",
      "  (33340, 637)\t0.15067486614547307\n",
      "  (33340, 1426)\t0.1353816153153684\n",
      "  (33340, 1339)\t0.22427638740937866\n",
      "  (33340, 754)\t0.09188746055078964\n",
      "  (33340, 559)\t0.11491980925916795\n",
      "  (33340, 1769)\t0.10510884292075533\n",
      "  (33340, 1986)\t0.08636565336679641\n",
      "  (33340, 1031)\t0.10274780227612142\n",
      "  (33340, 922)\t0.1335163841406214\n",
      "  (33340, 2031)\t0.08105791498966726\n",
      "  (33340, 741)\t0.08739011828455572\n",
      "  (33340, 283)\t0.10256819866807917\n",
      "  (33340, 936)\t0.10740062813394481\n",
      "  (33340, 897)\t0.10944071839628189\n",
      "  (33340, 1336)\t0.15206155743866692\n",
      "  (33340, 1903)\t0.06622826958556323\n",
      "  (33340, 931)\t0.10240347739304079\n",
      "  (33340, 1892)\t0.1796402828958075\n",
      "  (33340, 982)\t0.07011904757700844\n",
      "  (33340, 1018)\t0.07853769601332126\n",
      "  (33340, 1433)\t0.07688428329132653\n",
      "  (33340, 249)\t0.035685123980728164\n"
     ]
    }
   ],
   "source": [
    "tfidfVectorizer = TfidfVectorizer(analyzer=\"word\",max_features=2100)\n",
    "\n",
    "tfidfTransform = tfidfVectorizer.fit_transform(emailsText)\n",
    "\n",
    "print(tfidfTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DevPack\\anaconda3\\envs\\data_science\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['aa',\n 'ability',\n 'able',\n 'absolutely',\n 'abuse',\n 'accept',\n 'acceptance',\n 'accepted',\n 'access',\n 'according',\n 'account',\n 'accounting',\n 'accuracy',\n 'achieve',\n 'acquire',\n 'acquired',\n 'acquisition',\n 'acrobat',\n 'act',\n 'action',\n 'active',\n 'activity',\n 'actual',\n 'actually',\n 'acy',\n 'ad',\n 'add',\n 'added',\n 'adding',\n 'addition',\n 'additional',\n 'additionally',\n 'address',\n 'administration',\n 'adobe',\n 'adult',\n 'advance',\n 'advanced',\n 'advantage',\n 'advertisement',\n 'advertising',\n 'advice',\n 'advise',\n 'advised',\n 'advises',\n 'advisor',\n 'aep',\n 'affair',\n 'affect',\n 'affiliate',\n 'affiliated',\n 'affordable',\n 'age',\n 'agency',\n 'agenda',\n 'agent',\n 'aggressive',\n 'agree',\n 'agreed',\n 'agreement',\n 'ahead',\n 'aid',\n 'ail',\n 'aimee',\n 'air',\n 'al',\n 'alert',\n 'alias',\n 'align',\n 'allen',\n 'allocated',\n 'allocation',\n 'allow',\n 'allowed',\n 'allows',\n 'alternative',\n 'america',\n 'amid',\n 'amount',\n 'amy',\n 'analysis',\n 'analyst',\n 'ancillary',\n 'andmanyother',\n 'andrew',\n 'anita',\n 'anjam',\n 'announce',\n 'announced',\n 'announcement',\n 'announces',\n 'answer',\n 'anti',\n 'anticipated',\n 'anticipates',\n 'anybody',\n 'aol',\n 'appear',\n 'appears',\n 'application',\n 'applied',\n 'apply',\n 'appointment',\n 'appreciate',\n 'approach',\n 'appropriate',\n 'approval',\n 'approved',\n 'ar',\n 'area',\n 'arm',\n 'arrange',\n 'arrangement',\n 'art',\n 'article',\n 'asap',\n 'ask',\n 'asked',\n 'asking',\n 'asset',\n 'assist',\n 'assistance',\n 'assistant',\n 'associate',\n 'associated',\n 'assume',\n 'assumption',\n 'assurance',\n 'attached',\n 'attachment',\n 'attack',\n 'attempt',\n 'attend',\n 'attention',\n 'attorney',\n 'auction',\n 'audit',\n 'authority',\n 'automatically',\n 'availability',\n 'available',\n 'average',\n 'avoid',\n 'award',\n 'awarded',\n 'aware',\n 'away',\n 'background',\n 'bad',\n 'balance',\n 'ballot',\n 'bandwidth',\n 'bank',\n 'banker',\n 'banking',\n 'bankruptcy',\n 'barry',\n 'base',\n 'based',\n 'basic',\n 'basin',\n 'basis',\n 'batch',\n 'baylor',\n 'bbb',\n 'bcf',\n 'bed',\n 'began',\n 'begin',\n 'beginning',\n 'behalf',\n 'belief',\n 'believe',\n 'beneficiary',\n 'benefit',\n 'best',\n 'beth',\n 'better',\n 'bid',\n 'big',\n 'biggest',\n 'bill',\n 'billing',\n 'billion',\n 'bit',\n 'biz',\n 'black',\n 'blank',\n 'block',\n 'bloomberg',\n 'blue',\n 'bn',\n 'board',\n 'bob',\n 'body',\n 'bond',\n 'bonus',\n 'book',\n 'boost',\n 'border',\n 'bought',\n 'box',\n 'boy',\n 'br',\n 'bra',\n 'brand',\n 'break',\n 'breaking',\n 'brent',\n 'brian',\n 'bridge',\n 'brief',\n 'bring',\n 'broadband',\n 'broadcast',\n 'broker',\n 'brought',\n 'brown',\n 'browser',\n 'budget',\n 'build',\n 'building',\n 'built',\n 'bulk',\n 'business',\n 'button',\n 'buy',\n 'buyer',\n 'buying',\n 'ca',\n 'cable',\n 'cal',\n 'calendar',\n 'calger',\n 'california',\n 'call',\n 'called',\n 'calling',\n 'calpine',\n 'came',\n 'campaign',\n 'candidate',\n 'cap',\n 'capability',\n 'capacity',\n 'capital',\n 'capture',\n 'car',\n 'card',\n 'cardinall',\n 'care',\n 'career',\n 'carefully',\n 'carol',\n 'carry',\n 'case',\n 'cash',\n 'category',\n 'cause',\n 'caused',\n 'cc',\n 'cd',\n 'ce',\n 'cell',\n 'cent',\n 'center',\n 'central',\n 'ceo',\n 'cera',\n 'certain',\n 'certainly',\n 'cfo',\n 'chair',\n 'chairman',\n 'challenge',\n 'chance',\n 'change',\n 'changed',\n 'changing',\n 'channel',\n 'charge',\n 'chart',\n 'cheap',\n 'check',\n 'chief',\n 'child',\n 'choice',\n 'choose',\n 'christie',\n 'city',\n 'cl',\n 'claim',\n 'claimed',\n 'claiming',\n 'class',\n 'clean',\n 'clear',\n 'clearly',\n 'click',\n 'client',\n 'close',\n 'closed',\n 'closely',\n 'closing',\n 'club',\n 'coal',\n 'code',\n 'collapse',\n 'collateral',\n 'colleague',\n 'college',\n 'color',\n 'column',\n 'com',\n 'combination',\n 'combined',\n 'come',\n 'coming',\n 'comment',\n 'commerce',\n 'commercial',\n 'commission',\n 'commitment',\n 'committed',\n 'committee',\n 'commodity',\n 'common',\n 'communication',\n 'community',\n 'company',\n 'compare',\n 'compared',\n 'compensated',\n 'compensation',\n 'competition',\n 'competitive',\n 'competitor',\n 'complaint',\n 'complete',\n 'completed',\n 'completely',\n 'completion',\n 'complex',\n 'compliance',\n 'component',\n 'computron',\n 'concept',\n 'concern',\n 'concerned',\n 'concerning',\n 'conclusion',\n 'condition',\n 'conduct',\n 'conference',\n 'confidence',\n 'confidential',\n 'confidentiality',\n 'confirm',\n 'confirmation',\n 'confirmed',\n 'conflict',\n 'congratulation',\n 'connection',\n 'consequently',\n 'consider',\n 'consideration',\n 'considered',\n 'consistent',\n 'constitutes',\n 'construction',\n 'construed',\n 'consultant',\n 'consultation',\n 'consulting',\n 'consumer',\n 'contact',\n 'contacted',\n 'contacting',\n 'contain',\n 'contained',\n 'contains',\n 'content',\n 'continue',\n 'continued',\n 'continues',\n 'continuing',\n 'contract',\n 'contractor',\n 'contribution',\n 'control',\n 'convenience',\n 'convenient',\n 'conversation',\n 'cooperation',\n 'coordinate',\n 'coordinator',\n 'copy',\n 'copyright',\n 'core',\n 'corel',\n 'corp',\n 'corporate',\n 'corporation',\n 'correct',\n 'correspondence',\n 'cost',\n 'couid',\n 'count',\n 'counterparties',\n 'counterparty',\n 'country',\n 'couple',\n 'coupon',\n 'course',\n 'court',\n 'cover',\n 'coverage',\n 'create',\n 'created',\n 'creating',\n 'creative',\n 'credit',\n 'creditor',\n 'crenshaw',\n 'crisis',\n 'critical',\n 'cross',\n 'crude',\n 'current',\n 'currently',\n 'curve',\n 'custom',\n 'customer',\n 'cut',\n 'da',\n 'dabhol',\n 'daily',\n 'daren',\n 'data',\n 'database',\n 'date',\n 'datee',\n 'david',\n 'davis',\n 'day',\n 'dbcaps',\n 'de',\n 'deadline',\n 'deal',\n 'dealer',\n 'dealing',\n 'dear',\n 'death',\n 'debt',\n 'dec',\n 'decide',\n 'decided',\n 'deciding',\n 'decision',\n 'decline',\n 'declined',\n 'default',\n 'degree',\n 'del',\n 'delay',\n 'delete',\n 'deliver',\n 'delivered',\n 'delivery',\n 'demand',\n 'department',\n 'deposit',\n 'deposited',\n 'dept',\n 'der',\n 'derivative',\n 'described',\n 'description',\n 'design',\n 'designated',\n 'designed',\n 'desire',\n 'desk',\n 'despite',\n 'detail',\n 'detailed',\n 'detected',\n 'determine',\n 'develop',\n 'developed',\n 'developing',\n 'development',\n 'device',\n 'dia',\n 'dial',\n 'die',\n 'died',\n 'differ',\n 'difference',\n 'different',\n 'difficult',\n 'difficulty',\n 'digital',\n 'diligence',\n 'dinner',\n 'direct',\n 'direction',\n 'directly',\n 'director',\n 'directory',\n 'disclose',\n 'disclosed',\n 'disclosure',\n 'discount',\n 'discovered',\n 'discreet',\n 'discus',\n 'discussed',\n 'discussion',\n 'distribute',\n 'distribution',\n 'division',\n 'doc',\n 'doctor',\n 'document',\n 'documentation',\n 'dollar',\n 'domain',\n 'domestic',\n 'door',\n 'dose',\n 'double',\n 'doubt',\n 'dow',\n 'downgrade',\n 'download',\n 'dpc',\n 'dr',\n 'draft',\n 'draw',\n 'drawn',\n 'drew',\n 'drink',\n 'drive',\n 'drop',\n 'dropped',\n 'drug',\n 'duke',\n 'duty',\n 'dvd',\n 'dynamic',\n 'dynegy',\n 'earlier',\n 'early',\n 'earn',\n 'earnings',\n 'easier',\n 'easily',\n 'east',\n 'easy',\n 'eb',\n 'economic',\n 'economy',\n 'ect',\n 'ed',\n 'edge',\n 'edison',\n 'edition',\n 'edu',\n 'education',\n 'ee',\n 'eff',\n 'effect',\n 'effective',\n 'effort',\n 'el',\n 'electric',\n 'electricity',\n 'electronic',\n 'element',\n 'em',\n 'emai',\n 'email',\n 'emerging',\n 'emerson',\n 'employee',\n 'en',\n 'ena',\n 'enable',\n 'end',\n 'ene',\n 'energy',\n 'engine',\n 'engineering',\n 'enjoy',\n 'enron',\n 'enrononline',\n 'enronxgate',\n 'ensure',\n 'enter',\n 'entered',\n 'enterprise',\n 'entertainment',\n 'entire',\n 'entity',\n 'entry',\n 'environment',\n 'enw',\n 'eol',\n 'epmi',\n 'equipment',\n 'equity',\n 'erection',\n 'error',\n 'especially',\n 'est',\n 'established',\n 'estate',\n 'estimate',\n 'estimated',\n 'et',\n 'ets',\n 'euro',\n 'evaluation',\n 'event',\n 'eventt',\n 'ew',\n 'ex',\n 'exactly',\n 'example',\n 'excellent',\n 'excess',\n 'exchange',\n 'exciting',\n 'exclusive',\n 'executed',\n 'executive',\n 'exercise',\n 'existing',\n 'expand',\n 'expansion',\n 'expect',\n 'expectation',\n 'expected',\n 'expects',\n 'expense',\n 'expensive',\n 'experience',\n 'experienced',\n 'expert',\n 'explain',\n 'exploration',\n 'export',\n 'exposure',\n 'express',\n 'expressed',\n 'ext',\n 'extend',\n 'extended',\n 'extension',\n 'extensive',\n 'external',\n 'extra',\n 'extremely',\n 'eye',\n 'facc',\n 'face',\n 'facilitate',\n 'facility',\n 'fact',\n 'factor',\n 'failed',\n 'failure',\n 'faith',\n 'fall',\n 'fallen',\n 'familiar',\n 'family',\n 'far',\n 'farmer',\n 'fast',\n 'faster',\n 'fastow',\n 'fat',\n 'father',\n 'favor',\n 'fax',\n 'fear',\n 'feature',\n 'featured',\n 'feb',\n 'federal',\n 'fee',\n 'feedback',\n 'feel',\n 'fell',\n 'field',\n 'figure',\n 'file',\n 'filed',\n 'filing',\n 'final',\n 'finally',\n 'finance',\n 'financial',\n 'financing',\n 'finding',\n 'fine',\n 'firm',\n 'fit',\n 'fixed',\n 'fl',\n 'flash',\n 'flight',\n 'floor',\n 'flow',\n 'focus',\n 'focused',\n 'follow',\n 'followed',\n 'following',\n 'follows',\n 'font',\n 'food',\n 'foot',\n 'force',\n 'forced',\n 'forecast',\n 'foreign',\n 'foreigner',\n 'foresee',\n 'form',\n 'formal',\n 'format',\n 'formula',\n 'forth',\n 'fortune',\n 'forward',\n 'forwarded',\n 'frank',\n 'fred',\n 'free',\n 'fresh',\n 'fri',\n 'friend',\n 'ft',\n 'fuel',\n 'fully',\n 'fun',\n 'function',\n 'fund',\n 'fundamental',\n 'funding',\n 'furthermore',\n 'future',\n 'fw',\n 'fyi',\n 'gain',\n 'game',\n 'gap',\n 'gas',\n 'gathered',\n 'gathering',\n 'gave',\n 'geec',\n 'general',\n 'generate',\n 'generated',\n 'generating',\n 'generation',\n 'generator',\n 'generic',\n 'george',\n 'get',\n 'getting',\n 'giant',\n 'gibner',\n 'gift',\n 'girl',\n 'give',\n 'given',\n 'giving',\n 'glad',\n 'global',\n 'go',\n 'goal',\n 'god',\n 'going',\n 'gold',\n 'gone',\n 'good',\n 'got',\n 'gotten',\n 'gov',\n 'government',\n 'governor',\n 'gpee',\n 'gr',\n 'grade',\n 'graduate',\n 'grand',\n 'grant',\n 'graphic',\n 'great',\n 'greater',\n 'green',\n 'greg',\n 'grid',\n 'ground',\n 'group',\n 'grow',\n 'growing',\n 'growth',\n 'guarantee',\n 'guaranteed',\n 'guide',\n 'guy',\n 'hall',\n 'hand',\n 'handle',\n 'handling',\n 'happen',\n 'happening',\n 'happy',\n 'hard',\n 'head',\n 'health',\n 'hear',\n 'heard',\n 'hearing',\n 'heart',\n 'heavy',\n 'hedge',\n 'height',\n 'held',\n 'hello',\n 'help',\n 'helped',\n 'helping',\n 'hesitate',\n 'hey',\n 'hi',\n 'high',\n 'higher',\n 'highest',\n 'highly',\n 'hin',\n 'historical',\n 'history',\n 'hit',\n 'hold',\n 'holding',\n 'holiday',\n 'home',\n 'hope',\n 'host',\n 'hot',\n 'hotel',\n 'hotmail',\n 'hou',\n 'hour',\n 'hourahead',\n 'house',\n 'houston',\n 'hpl',\n 'hr',\n 'href',\n 'hsc',\n 'html',\n 'http',\n 'hub',\n 'huge',\n 'human',\n 'husband',\n 'idea',\n 'identified',\n 'identify',\n 'identity',\n 'ii',\n 'iii',\n 'image',\n 'imagine',\n 'immediate',\n 'immediately',\n 'impact',\n 'implementation',\n 'importance',\n 'important',\n 'improve',\n 'improved',\n 'improvement',\n 'inciude',\n 'include',\n 'included',\n 'includes',\n 'including',\n 'income',\n 'increase',\n 'increased',\n 'increasing',\n 'independent',\n 'index',\n 'indicate',\n 'indicated',\n 'indicating',\n 'indicative',\n 'individual',\n 'industrial',\n 'industry',\n 'info',\n 'inform',\n 'information',\n 'informed',\n 'infrastructure',\n 'inherent',\n 'initial',\n 'initiative',\n 'innovative',\n 'input',\n 'inquiry',\n 'inside',\n 'instant',\n 'instead',\n 'institution',\n 'instruction',\n 'insurance',\n 'integration',\n 'intend',\n 'intended',\n 'intent',\n 'interest',\n 'interested',\n 'interesting',\n 'interface',\n 'internal',\n 'international',\n 'internet',\n 'interview',\n 'introduce',\n 'inventory',\n 'invest',\n 'invested',\n 'investigation',\n 'investing',\n 'investment',\n 'investor',\n 'invitation',\n 'invite',\n 'invoice',\n 'involve',\n 'involved',\n 'involving',\n 'ion',\n 'ire',\n 'iso',\n 'issue',\n 'issued',\n 'item',\n 'iv',\n 'jan',\n 'jeff',\n 'jim',\n 'job',\n 'john',\n 'join',\n 'joint',\n 'jones',\n 'judge',\n 'jul',\n 'jump',\n 'junk',\n 'kaminski',\n 'keeping',\n 'ken',\n 'kept',\n 'key',\n 'kimberly',\n 'kin',\n 'kind',\n 'kitchen',\n 'knew',\n 'kno',\n 'know',\n 'knowledge',\n 'known',\n 'la',\n 'lack',\n 'land',\n 'language',\n 'large',\n 'larger',\n 'largest',\n 'late',\n 'later',\n 'latest',\n 'launch',\n 'lauraan',\n 'law',\n 'lawsuit',\n 'laww',\n ...]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfLabels = tfidfVectorizer.get_feature_names()\n",
    "tfidfLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfTfidf = pd.DataFrame(data=tfidfTransform.toarray(), columns=tfidfLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        aa  ability  able  absolutely  abuse  accept  acceptance  accepted  \\\n0      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n1      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n2      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n3      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n4      0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n...    ...      ...   ...         ...    ...     ...         ...       ...   \n33336  0.0      0.0   0.0         0.0    0.0     0.0    0.015667       0.0   \n33337  0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n33338  0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n33339  0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n33340  0.0      0.0   0.0         0.0    0.0     0.0    0.000000       0.0   \n\n         access  according  ...  xanax   xl   xp     yahoo  year  yes  yield  \\\n0      0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n1      0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n2      0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n3      0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n4      0.143700        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n...         ...        ...  ...    ...  ...  ...       ...   ...  ...    ...   \n33336  0.000000        0.0  ...    0.0  0.0  0.0  0.013857   0.0  0.0    0.0   \n33337  0.207355        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n33338  0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n33339  0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n33340  0.000000        0.0  ...    0.0  0.0  0.0  0.000000   0.0  0.0    0.0   \n\n        yo  young  zone  \n0      0.0    0.0   0.0  \n1      0.0    0.0   0.0  \n2      0.0    0.0   0.0  \n3      0.0    0.0   0.0  \n4      0.0    0.0   0.0  \n...    ...    ...   ...  \n33336  0.0    0.0   0.0  \n33337  0.0    0.0   0.0  \n33338  0.0    0.0   0.0  \n33339  0.0    0.0   0.0  \n33340  0.0    0.0   0.0  \n\n[33341 rows x 2100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aa</th>\n      <th>ability</th>\n      <th>able</th>\n      <th>absolutely</th>\n      <th>abuse</th>\n      <th>accept</th>\n      <th>acceptance</th>\n      <th>accepted</th>\n      <th>access</th>\n      <th>according</th>\n      <th>...</th>\n      <th>xanax</th>\n      <th>xl</th>\n      <th>xp</th>\n      <th>yahoo</th>\n      <th>year</th>\n      <th>yes</th>\n      <th>yield</th>\n      <th>yo</th>\n      <th>young</th>\n      <th>zone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.143700</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33336</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.015667</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.013857</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33337</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.207355</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33338</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33339</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33340</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>33341 rows × 2100 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTfidf = np.array(dfTfidf)\n",
    "dfTfidf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33341, 1, 2100)\n"
     ]
    }
   ],
   "source": [
    "dfTfidf = dfTfidf.reshape((dfTfidf.shape[0], 1, dfTfidf.shape[1]))\n",
    "\n",
    "print(dfTfidf.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualização de dados com TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = TSNE(n_components=2, random_state=0)\n",
    "# array_red = model.fit_transform(dfTfidf)\n",
    "#\n",
    "# df_tsne = pd.DataFrame(array_red)\n",
    "#\n",
    "# df_tsne['Target'] = target\n",
    "# df_tsne_c1 = df_tsne[df_tsne['Target'] == 0]\n",
    "#\n",
    "# df_tsne_c2 = df_tsne[df_tsne['Target'] == 1]\n",
    "#\n",
    "# plt.scatter(df_tsne_c1[0].array,df_tsne_c1[1].array,marker='o',color='blue')\n",
    "#\n",
    "# plt.scatter(df_tsne_c2[0].array,df_tsne_c2[1].array,marker='o',color='red')\n",
    "#\n",
    "# plt.title('Dados')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "#\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "foldsAccuracy = []\n",
    "foldLosses = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=4, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Iniciando treinamento da fold: 1.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 5s 3ms/step - loss: 0.6912 - accuracy: 0.5485 - val_loss: 0.6886 - val_accuracy: 0.6739 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6862 - accuracy: 0.6217 - val_loss: 0.6835 - val_accuracy: 0.6531 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6809 - accuracy: 0.7030 - val_loss: 0.6778 - val_accuracy: 0.7458 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6750 - accuracy: 0.7539 - val_loss: 0.6712 - val_accuracy: 0.8513 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6680 - accuracy: 0.8146 - val_loss: 0.6635 - val_accuracy: 0.8689 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6596 - accuracy: 0.8337 - val_loss: 0.6543 - val_accuracy: 0.8937 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6497 - accuracy: 0.8751 - val_loss: 0.6432 - val_accuracy: 0.8393 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6377 - accuracy: 0.8615 - val_loss: 0.6299 - val_accuracy: 0.8841 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6235 - accuracy: 0.8802 - val_loss: 0.6142 - val_accuracy: 0.8921 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6068 - accuracy: 0.8880 - val_loss: 0.5960 - val_accuracy: 0.9009 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5877 - accuracy: 0.8972 - val_loss: 0.5753 - val_accuracy: 0.8985 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5661 - accuracy: 0.8981 - val_loss: 0.5523 - val_accuracy: 0.9121 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.9062 - val_loss: 0.5273 - val_accuracy: 0.9081 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5172 - accuracy: 0.9082 - val_loss: 0.5011 - val_accuracy: 0.9137 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4911 - accuracy: 0.9125 - val_loss: 0.4743 - val_accuracy: 0.9169 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4646 - accuracy: 0.9166 - val_loss: 0.4477 - val_accuracy: 0.9169 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4386 - accuracy: 0.9190 - val_loss: 0.4220 - val_accuracy: 0.9161 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4135 - accuracy: 0.9212 - val_loss: 0.3971 - val_accuracy: 0.9201 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3896 - accuracy: 0.9239 - val_loss: 0.3737 - val_accuracy: 0.9249 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3673 - accuracy: 0.9270 - val_loss: 0.3522 - val_accuracy: 0.9257 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3466 - accuracy: 0.9289 - val_loss: 0.3322 - val_accuracy: 0.9305 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3276 - accuracy: 0.9318 - val_loss: 0.3140 - val_accuracy: 0.9329 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3102 - accuracy: 0.9342 - val_loss: 0.2974 - val_accuracy: 0.9376 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2944 - accuracy: 0.9364 - val_loss: 0.2823 - val_accuracy: 0.9440 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2800 - accuracy: 0.9382 - val_loss: 0.2686 - val_accuracy: 0.9408 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2668 - accuracy: 0.9402 - val_loss: 0.2561 - val_accuracy: 0.9432 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2548 - accuracy: 0.9416 - val_loss: 0.2449 - val_accuracy: 0.9416 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2439 - accuracy: 0.9429 - val_loss: 0.2343 - val_accuracy: 0.9448 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2339 - accuracy: 0.9446 - val_loss: 0.2248 - val_accuracy: 0.9456 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2247 - accuracy: 0.9468 - val_loss: 0.2161 - val_accuracy: 0.9464 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2163 - accuracy: 0.9486 - val_loss: 0.2081 - val_accuracy: 0.9480 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2087 - accuracy: 0.9500 - val_loss: 0.2007 - val_accuracy: 0.9464 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2016 - accuracy: 0.9515 - val_loss: 0.1939 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1950 - accuracy: 0.9523 - val_loss: 0.1876 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1890 - accuracy: 0.9536 - val_loss: 0.1817 - val_accuracy: 0.9520 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1834 - accuracy: 0.9545 - val_loss: 0.1763 - val_accuracy: 0.9560 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1782 - accuracy: 0.9560 - val_loss: 0.1712 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1733 - accuracy: 0.9574 - val_loss: 0.1665 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1688 - accuracy: 0.9583 - val_loss: 0.1621 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1645 - accuracy: 0.9593 - val_loss: 0.1579 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1605 - accuracy: 0.9602 - val_loss: 0.1540 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1568 - accuracy: 0.9601 - val_loss: 0.1503 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1533 - accuracy: 0.9612 - val_loss: 0.1469 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1500 - accuracy: 0.9620 - val_loss: 0.1438 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1469 - accuracy: 0.9626 - val_loss: 0.1404 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1439 - accuracy: 0.9630 - val_loss: 0.1375 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1411 - accuracy: 0.9635 - val_loss: 0.1347 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1384 - accuracy: 0.9639 - val_loss: 0.1320 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1359 - accuracy: 0.9646 - val_loss: 0.1295 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1334 - accuracy: 0.9647 - val_loss: 0.1271 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1311 - accuracy: 0.9648 - val_loss: 0.1248 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1289 - accuracy: 0.9651 - val_loss: 0.1226 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1268 - accuracy: 0.9655 - val_loss: 0.1204 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1248 - accuracy: 0.9662 - val_loss: 0.1185 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1228 - accuracy: 0.9666 - val_loss: 0.1166 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1209 - accuracy: 0.9671 - val_loss: 0.1146 - val_accuracy: 0.9704 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1191 - accuracy: 0.9673 - val_loss: 0.1130 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1174 - accuracy: 0.9675 - val_loss: 0.1111 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1158 - accuracy: 0.9679 - val_loss: 0.1094 - val_accuracy: 0.9704 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1142 - accuracy: 0.9684 - val_loss: 0.1079 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1126 - accuracy: 0.9686 - val_loss: 0.1063 - val_accuracy: 0.9704 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1111 - accuracy: 0.9690 - val_loss: 0.1051 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1097 - accuracy: 0.9692 - val_loss: 0.1036 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1083 - accuracy: 0.9697 - val_loss: 0.1021 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1069 - accuracy: 0.9699 - val_loss: 0.1009 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1057 - accuracy: 0.9700 - val_loss: 0.0995 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1044 - accuracy: 0.9708 - val_loss: 0.0983 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1032 - accuracy: 0.9710 - val_loss: 0.0972 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1020 - accuracy: 0.9713 - val_loss: 0.0959 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1008 - accuracy: 0.9716 - val_loss: 0.0950 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0997 - accuracy: 0.9715 - val_loss: 0.0937 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0986 - accuracy: 0.9722 - val_loss: 0.0929 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0976 - accuracy: 0.9721 - val_loss: 0.0917 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0966 - accuracy: 0.9726 - val_loss: 0.0907 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0956 - accuracy: 0.9724 - val_loss: 0.0899 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0946 - accuracy: 0.9726 - val_loss: 0.0889 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0936 - accuracy: 0.9729 - val_loss: 0.0880 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0927 - accuracy: 0.9731 - val_loss: 0.0872 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0918 - accuracy: 0.9732 - val_loss: 0.0863 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0909 - accuracy: 0.9734 - val_loss: 0.0857 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0901 - accuracy: 0.9735 - val_loss: 0.0847 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0893 - accuracy: 0.9737 - val_loss: 0.0839 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0885 - accuracy: 0.9740 - val_loss: 0.0835 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0877 - accuracy: 0.9740 - val_loss: 0.0826 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0869 - accuracy: 0.9741 - val_loss: 0.0818 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0861 - accuracy: 0.9741 - val_loss: 0.0815 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0855 - accuracy: 0.9744 - val_loss: 0.0805 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0847 - accuracy: 0.9745 - val_loss: 0.0802 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0841 - accuracy: 0.9746 - val_loss: 0.0794 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0834 - accuracy: 0.9748 - val_loss: 0.0788 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0827 - accuracy: 0.9751 - val_loss: 0.0785 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0820 - accuracy: 0.9752 - val_loss: 0.0776 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0814 - accuracy: 0.9757 - val_loss: 0.0768 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0808 - accuracy: 0.9758 - val_loss: 0.0763 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0801 - accuracy: 0.9758 - val_loss: 0.0760 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0796 - accuracy: 0.9759 - val_loss: 0.0752 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0790 - accuracy: 0.9764 - val_loss: 0.0747 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0784 - accuracy: 0.9760 - val_loss: 0.0745 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0778 - accuracy: 0.9766 - val_loss: 0.0741 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0773 - accuracy: 0.9766 - val_loss: 0.0733 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0768 - accuracy: 0.9767 - val_loss: 0.0730 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0762 - accuracy: 0.9769 - val_loss: 0.0724 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0758 - accuracy: 0.9774 - val_loss: 0.0721 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0752 - accuracy: 0.9774 - val_loss: 0.0715 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0747 - accuracy: 0.9775 - val_loss: 0.0712 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0742 - accuracy: 0.9772 - val_loss: 0.0709 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9780 - val_loss: 0.0704 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0733 - accuracy: 0.9782 - val_loss: 0.0699 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0728 - accuracy: 0.9784 - val_loss: 0.0695 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0724 - accuracy: 0.9786 - val_loss: 0.0691 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0719 - accuracy: 0.9784 - val_loss: 0.0688 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0715 - accuracy: 0.9787 - val_loss: 0.0685 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0710 - accuracy: 0.9788 - val_loss: 0.0685 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0706 - accuracy: 0.9790 - val_loss: 0.0677 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0702 - accuracy: 0.9789 - val_loss: 0.0675 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0698 - accuracy: 0.9790 - val_loss: 0.0671 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0694 - accuracy: 0.9793 - val_loss: 0.0669 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0690 - accuracy: 0.9791 - val_loss: 0.0669 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0686 - accuracy: 0.9792 - val_loss: 0.0662 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0682 - accuracy: 0.9797 - val_loss: 0.0661 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0678 - accuracy: 0.9796 - val_loss: 0.0656 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0675 - accuracy: 0.9796 - val_loss: 0.0652 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0671 - accuracy: 0.9800 - val_loss: 0.0652 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0668 - accuracy: 0.9800 - val_loss: 0.0647 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0664 - accuracy: 0.9800 - val_loss: 0.0644 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0661 - accuracy: 0.9801 - val_loss: 0.0641 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0657 - accuracy: 0.9801 - val_loss: 0.0639 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0654 - accuracy: 0.9802 - val_loss: 0.0638 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0651 - accuracy: 0.9803 - val_loss: 0.0634 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0646 - accuracy: 0.9803 - val_loss: 0.0631 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0644 - accuracy: 0.9806 - val_loss: 0.0629 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0641 - accuracy: 0.9805 - val_loss: 0.0630 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0638 - accuracy: 0.9804 - val_loss: 0.0626 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 134/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0635 - accuracy: 0.9807 - val_loss: 0.0626 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 135/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0632 - accuracy: 0.9808 - val_loss: 0.0621 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 136/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0629 - accuracy: 0.9807 - val_loss: 0.0618 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 137/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0626 - accuracy: 0.9812 - val_loss: 0.0617 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 138/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0623 - accuracy: 0.9811 - val_loss: 0.0614 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 139/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0620 - accuracy: 0.9811 - val_loss: 0.0616 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 140/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0617 - accuracy: 0.9814 - val_loss: 0.0612 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 141/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0614 - accuracy: 0.9812 - val_loss: 0.0606 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 142/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0611 - accuracy: 0.9815 - val_loss: 0.0608 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 143/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 0.0602 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 144/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0606 - accuracy: 0.9818 - val_loss: 0.0601 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 145/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0603 - accuracy: 0.9820 - val_loss: 0.0602 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 146/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0601 - accuracy: 0.9817 - val_loss: 0.0598 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 147/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0598 - accuracy: 0.9819 - val_loss: 0.0594 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 148/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0595 - accuracy: 0.9823 - val_loss: 0.0597 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 149/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 0.0596 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 150/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0590 - accuracy: 0.9825 - val_loss: 0.0593 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 151/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 0.0590 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 152/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0585 - accuracy: 0.9823 - val_loss: 0.0588 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 153/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0583 - accuracy: 0.9823 - val_loss: 0.0584 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 154/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0581 - accuracy: 0.9823 - val_loss: 0.0587 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 155/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0578 - accuracy: 0.9824 - val_loss: 0.0580 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 156/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0576 - accuracy: 0.9827 - val_loss: 0.0581 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 157/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0574 - accuracy: 0.9826 - val_loss: 0.0578 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 158/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0571 - accuracy: 0.9830 - val_loss: 0.0579 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 159/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.0576 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 160/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0567 - accuracy: 0.9832 - val_loss: 0.0576 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 161/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0565 - accuracy: 0.9831 - val_loss: 0.0576 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 162/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0563 - accuracy: 0.9832 - val_loss: 0.0569 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 163/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0560 - accuracy: 0.9833 - val_loss: 0.0569 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 164/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0558 - accuracy: 0.9833 - val_loss: 0.0567 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 165/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0556 - accuracy: 0.9833 - val_loss: 0.0566 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 166/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0554 - accuracy: 0.9834 - val_loss: 0.0563 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 167/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0552 - accuracy: 0.9835 - val_loss: 0.0562 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 168/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0549 - accuracy: 0.9835 - val_loss: 0.0560 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 169/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0548 - accuracy: 0.9836 - val_loss: 0.0564 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 170/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0546 - accuracy: 0.9835 - val_loss: 0.0559 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 171/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.0558 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 172/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0542 - accuracy: 0.9837 - val_loss: 0.0558 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 173/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0540 - accuracy: 0.9836 - val_loss: 0.0556 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 174/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.0558 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 175/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0536 - accuracy: 0.9837 - val_loss: 0.0556 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 176/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0534 - accuracy: 0.9836 - val_loss: 0.0552 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 177/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0532 - accuracy: 0.9839 - val_loss: 0.0552 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 178/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0530 - accuracy: 0.9838 - val_loss: 0.0550 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 179/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 0.0549 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 180/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0526 - accuracy: 0.9842 - val_loss: 0.0557 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 181/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0525 - accuracy: 0.9839 - val_loss: 0.0547 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 182/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0523 - accuracy: 0.9840 - val_loss: 0.0547 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 183/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0521 - accuracy: 0.9840 - val_loss: 0.0546 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 184/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.0544 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 185/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0518 - accuracy: 0.9843 - val_loss: 0.0545 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 186/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0516 - accuracy: 0.9843 - val_loss: 0.0545 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 187/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0514 - accuracy: 0.9843 - val_loss: 0.0539 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 188/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0512 - accuracy: 0.9845 - val_loss: 0.0536 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 189/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0511 - accuracy: 0.9844 - val_loss: 0.0537 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 190/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0509 - accuracy: 0.9845 - val_loss: 0.0536 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 191/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0507 - accuracy: 0.9846 - val_loss: 0.0536 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 192/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.0536 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 193/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0504 - accuracy: 0.9845 - val_loss: 0.0536 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 194/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0503 - accuracy: 0.9846 - val_loss: 0.0531 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 195/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0501 - accuracy: 0.9846 - val_loss: 0.0530 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 196/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.0529 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 197/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0498 - accuracy: 0.9847 - val_loss: 0.0535 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 198/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0496 - accuracy: 0.9848 - val_loss: 0.0529 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 199/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0495 - accuracy: 0.9847 - val_loss: 0.0534 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 200/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0493 - accuracy: 0.9849 - val_loss: 0.0528 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Score fold 1: loss de 0.06222359091043472; accuracy de 97.93666005134583%\n",
      "****************************************************\n",
      "Iniciando treinamento da fold: 2.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 3s 3ms/step - loss: 0.6914 - accuracy: 0.5720 - val_loss: 0.6889 - val_accuracy: 0.7506 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6863 - accuracy: 0.7385 - val_loss: 0.6837 - val_accuracy: 0.7466 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6807 - accuracy: 0.7924 - val_loss: 0.6780 - val_accuracy: 0.7810 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6744 - accuracy: 0.7982 - val_loss: 0.6711 - val_accuracy: 0.9009 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6672 - accuracy: 0.8767 - val_loss: 0.6635 - val_accuracy: 0.8185 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6585 - accuracy: 0.8659 - val_loss: 0.6539 - val_accuracy: 0.8777 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6481 - accuracy: 0.8843 - val_loss: 0.6426 - val_accuracy: 0.8761 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6356 - accuracy: 0.8798 - val_loss: 0.6289 - val_accuracy: 0.9081 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6208 - accuracy: 0.8960 - val_loss: 0.6130 - val_accuracy: 0.9057 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6035 - accuracy: 0.9014 - val_loss: 0.5948 - val_accuracy: 0.8873 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5837 - accuracy: 0.8993 - val_loss: 0.5736 - val_accuracy: 0.9073 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5616 - accuracy: 0.9044 - val_loss: 0.5503 - val_accuracy: 0.9121 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.9088 - val_loss: 0.5254 - val_accuracy: 0.9121 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5118 - accuracy: 0.9132 - val_loss: 0.5001 - val_accuracy: 0.9033 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4855 - accuracy: 0.9117 - val_loss: 0.4725 - val_accuracy: 0.9209 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4590 - accuracy: 0.9198 - val_loss: 0.4467 - val_accuracy: 0.9177 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4330 - accuracy: 0.9208 - val_loss: 0.4208 - val_accuracy: 0.9209 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4081 - accuracy: 0.9234 - val_loss: 0.3964 - val_accuracy: 0.9225 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3845 - accuracy: 0.9258 - val_loss: 0.3733 - val_accuracy: 0.9257 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3626 - accuracy: 0.9284 - val_loss: 0.3522 - val_accuracy: 0.9289 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3423 - accuracy: 0.9315 - val_loss: 0.3326 - val_accuracy: 0.9305 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3237 - accuracy: 0.9336 - val_loss: 0.3147 - val_accuracy: 0.9313 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3066 - accuracy: 0.9359 - val_loss: 0.2980 - val_accuracy: 0.9361 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2910 - accuracy: 0.9375 - val_loss: 0.2831 - val_accuracy: 0.9376 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2768 - accuracy: 0.9386 - val_loss: 0.2696 - val_accuracy: 0.9369 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2639 - accuracy: 0.9407 - val_loss: 0.2573 - val_accuracy: 0.9369 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2522 - accuracy: 0.9424 - val_loss: 0.2456 - val_accuracy: 0.9376 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2414 - accuracy: 0.9439 - val_loss: 0.2349 - val_accuracy: 0.9440 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2316 - accuracy: 0.9458 - val_loss: 0.2256 - val_accuracy: 0.9440 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2225 - accuracy: 0.9472 - val_loss: 0.2167 - val_accuracy: 0.9464 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2143 - accuracy: 0.9494 - val_loss: 0.2086 - val_accuracy: 0.9504 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2067 - accuracy: 0.9508 - val_loss: 0.2014 - val_accuracy: 0.9488 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1997 - accuracy: 0.9518 - val_loss: 0.1945 - val_accuracy: 0.9520 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1933 - accuracy: 0.9526 - val_loss: 0.1880 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1873 - accuracy: 0.9538 - val_loss: 0.1821 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1818 - accuracy: 0.9552 - val_loss: 0.1767 - val_accuracy: 0.9600 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1766 - accuracy: 0.9560 - val_loss: 0.1720 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1718 - accuracy: 0.9571 - val_loss: 0.1671 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1673 - accuracy: 0.9579 - val_loss: 0.1625 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1631 - accuracy: 0.9587 - val_loss: 0.1581 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1592 - accuracy: 0.9593 - val_loss: 0.1542 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1555 - accuracy: 0.9599 - val_loss: 0.1507 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1520 - accuracy: 0.9605 - val_loss: 0.1473 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1487 - accuracy: 0.9609 - val_loss: 0.1438 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1457 - accuracy: 0.9616 - val_loss: 0.1413 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1427 - accuracy: 0.9619 - val_loss: 0.1377 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1400 - accuracy: 0.9625 - val_loss: 0.1352 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1373 - accuracy: 0.9633 - val_loss: 0.1324 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1348 - accuracy: 0.9638 - val_loss: 0.1303 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1324 - accuracy: 0.9642 - val_loss: 0.1276 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1301 - accuracy: 0.9645 - val_loss: 0.1253 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1279 - accuracy: 0.9646 - val_loss: 0.1234 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1258 - accuracy: 0.9655 - val_loss: 0.1210 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1238 - accuracy: 0.9657 - val_loss: 0.1187 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1219 - accuracy: 0.9666 - val_loss: 0.1170 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1201 - accuracy: 0.9668 - val_loss: 0.1152 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1182 - accuracy: 0.9672 - val_loss: 0.1137 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1166 - accuracy: 0.9678 - val_loss: 0.1119 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1149 - accuracy: 0.9680 - val_loss: 0.1101 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1133 - accuracy: 0.9685 - val_loss: 0.1086 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1118 - accuracy: 0.9688 - val_loss: 0.1071 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1103 - accuracy: 0.9692 - val_loss: 0.1054 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1089 - accuracy: 0.9693 - val_loss: 0.1044 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1075 - accuracy: 0.9697 - val_loss: 0.1030 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1062 - accuracy: 0.9700 - val_loss: 0.1014 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1049 - accuracy: 0.9698 - val_loss: 0.1001 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1037 - accuracy: 0.9706 - val_loss: 0.0990 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1024 - accuracy: 0.9708 - val_loss: 0.0984 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1013 - accuracy: 0.9712 - val_loss: 0.0970 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1001 - accuracy: 0.9712 - val_loss: 0.0961 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0991 - accuracy: 0.9719 - val_loss: 0.0944 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0979 - accuracy: 0.9721 - val_loss: 0.0939 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0969 - accuracy: 0.9723 - val_loss: 0.0924 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0959 - accuracy: 0.9726 - val_loss: 0.0915 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0949 - accuracy: 0.9730 - val_loss: 0.0902 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0940 - accuracy: 0.9733 - val_loss: 0.0898 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0930 - accuracy: 0.9732 - val_loss: 0.0892 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0921 - accuracy: 0.9736 - val_loss: 0.0877 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0912 - accuracy: 0.9739 - val_loss: 0.0872 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0904 - accuracy: 0.9738 - val_loss: 0.0864 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0895 - accuracy: 0.9743 - val_loss: 0.0853 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0887 - accuracy: 0.9746 - val_loss: 0.0859 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0879 - accuracy: 0.9744 - val_loss: 0.0845 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0872 - accuracy: 0.9749 - val_loss: 0.0833 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0864 - accuracy: 0.9749 - val_loss: 0.0821 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0856 - accuracy: 0.9748 - val_loss: 0.0813 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0850 - accuracy: 0.9752 - val_loss: 0.0811 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0842 - accuracy: 0.9754 - val_loss: 0.0801 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0835 - accuracy: 0.9758 - val_loss: 0.0797 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0828 - accuracy: 0.9759 - val_loss: 0.0796 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0822 - accuracy: 0.9760 - val_loss: 0.0786 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0815 - accuracy: 0.9760 - val_loss: 0.0791 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0809 - accuracy: 0.9762 - val_loss: 0.0774 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0803 - accuracy: 0.9762 - val_loss: 0.0772 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0797 - accuracy: 0.9762 - val_loss: 0.0768 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0791 - accuracy: 0.9767 - val_loss: 0.0755 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0785 - accuracy: 0.9767 - val_loss: 0.0754 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0779 - accuracy: 0.9771 - val_loss: 0.0750 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0774 - accuracy: 0.9771 - val_loss: 0.0742 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0768 - accuracy: 0.9772 - val_loss: 0.0735 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0763 - accuracy: 0.9773 - val_loss: 0.0733 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0758 - accuracy: 0.9772 - val_loss: 0.0728 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0752 - accuracy: 0.9775 - val_loss: 0.0729 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0747 - accuracy: 0.9775 - val_loss: 0.0719 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0743 - accuracy: 0.9779 - val_loss: 0.0717 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9779 - val_loss: 0.0720 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0733 - accuracy: 0.9780 - val_loss: 0.0716 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0728 - accuracy: 0.9779 - val_loss: 0.0703 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0723 - accuracy: 0.9781 - val_loss: 0.0699 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0718 - accuracy: 0.9780 - val_loss: 0.0691 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0714 - accuracy: 0.9781 - val_loss: 0.0702 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0710 - accuracy: 0.9783 - val_loss: 0.0688 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0706 - accuracy: 0.9784 - val_loss: 0.0682 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0702 - accuracy: 0.9788 - val_loss: 0.0688 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0697 - accuracy: 0.9789 - val_loss: 0.0682 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0693 - accuracy: 0.9787 - val_loss: 0.0679 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0689 - accuracy: 0.9789 - val_loss: 0.0671 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0685 - accuracy: 0.9792 - val_loss: 0.0671 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0681 - accuracy: 0.9794 - val_loss: 0.0660 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0678 - accuracy: 0.9795 - val_loss: 0.0660 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.0659 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0670 - accuracy: 0.9794 - val_loss: 0.0656 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0666 - accuracy: 0.9797 - val_loss: 0.0648 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9798 - val_loss: 0.0654 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0659 - accuracy: 0.9799 - val_loss: 0.0653 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0656 - accuracy: 0.9799 - val_loss: 0.0646 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0652 - accuracy: 0.9799 - val_loss: 0.0638 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0649 - accuracy: 0.9802 - val_loss: 0.0638 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0645 - accuracy: 0.9801 - val_loss: 0.0633 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0642 - accuracy: 0.9804 - val_loss: 0.0632 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0639 - accuracy: 0.9806 - val_loss: 0.0632 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0635 - accuracy: 0.9803 - val_loss: 0.0627 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0629 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 134/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0629 - accuracy: 0.9807 - val_loss: 0.0626 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 135/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0627 - accuracy: 0.9809 - val_loss: 0.0619 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 136/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0623 - accuracy: 0.9810 - val_loss: 0.0619 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 137/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0620 - accuracy: 0.9811 - val_loss: 0.0616 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 138/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0617 - accuracy: 0.9812 - val_loss: 0.0617 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 139/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0614 - accuracy: 0.9812 - val_loss: 0.0610 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 140/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0612 - accuracy: 0.9813 - val_loss: 0.0610 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 141/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0609 - accuracy: 0.9814 - val_loss: 0.0607 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 142/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0606 - accuracy: 0.9815 - val_loss: 0.0606 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 143/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0603 - accuracy: 0.9816 - val_loss: 0.0598 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 144/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0601 - accuracy: 0.9816 - val_loss: 0.0605 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 145/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.0595 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 146/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0595 - accuracy: 0.9819 - val_loss: 0.0597 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 147/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0593 - accuracy: 0.9816 - val_loss: 0.0596 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 148/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0590 - accuracy: 0.9818 - val_loss: 0.0594 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 149/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0587 - accuracy: 0.9822 - val_loss: 0.0586 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 150/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0585 - accuracy: 0.9822 - val_loss: 0.0590 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 151/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0582 - accuracy: 0.9824 - val_loss: 0.0582 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 152/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0580 - accuracy: 0.9823 - val_loss: 0.0585 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 153/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0577 - accuracy: 0.9827 - val_loss: 0.0583 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 154/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0575 - accuracy: 0.9824 - val_loss: 0.0588 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 155/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0572 - accuracy: 0.9827 - val_loss: 0.0581 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 156/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 0.0581 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 157/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0568 - accuracy: 0.9828 - val_loss: 0.0574 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 158/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0566 - accuracy: 0.9828 - val_loss: 0.0578 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 159/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0563 - accuracy: 0.9830 - val_loss: 0.0574 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 160/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0561 - accuracy: 0.9831 - val_loss: 0.0572 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 161/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0559 - accuracy: 0.9831 - val_loss: 0.0570 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 162/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0556 - accuracy: 0.9832 - val_loss: 0.0570 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 163/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0554 - accuracy: 0.9835 - val_loss: 0.0571 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 164/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0552 - accuracy: 0.9833 - val_loss: 0.0567 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 165/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0550 - accuracy: 0.9835 - val_loss: 0.0580 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 166/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0548 - accuracy: 0.9834 - val_loss: 0.0569 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 167/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0545 - accuracy: 0.9837 - val_loss: 0.0568 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 168/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0544 - accuracy: 0.9835 - val_loss: 0.0560 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 169/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0541 - accuracy: 0.9840 - val_loss: 0.0556 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 170/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0539 - accuracy: 0.9838 - val_loss: 0.0561 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 171/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0537 - accuracy: 0.9840 - val_loss: 0.0563 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 172/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.0563 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 173/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0533 - accuracy: 0.9839 - val_loss: 0.0550 - val_accuracy: 0.9856 - lr: 0.0100\n",
      "Epoch 174/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.0555 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 175/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0530 - accuracy: 0.9842 - val_loss: 0.0555 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 176/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0528 - accuracy: 0.9841 - val_loss: 0.0549 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 177/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.0545 - val_accuracy: 0.9856 - lr: 0.0100\n",
      "Epoch 178/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0524 - accuracy: 0.9843 - val_loss: 0.0554 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 179/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0522 - accuracy: 0.9844 - val_loss: 0.0551 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 180/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0520 - accuracy: 0.9844 - val_loss: 0.0547 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 181/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0518 - accuracy: 0.9843 - val_loss: 0.0544 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 182/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 0.0542 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 183/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0515 - accuracy: 0.9845 - val_loss: 0.0547 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 184/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0513 - accuracy: 0.9848 - val_loss: 0.0543 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 185/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0510 - accuracy: 0.9845 - val_loss: 0.0532 - val_accuracy: 0.9856 - lr: 0.0100\n",
      "Epoch 186/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0510 - accuracy: 0.9848 - val_loss: 0.0538 - val_accuracy: 0.9856 - lr: 0.0100\n",
      "Epoch 187/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0508 - accuracy: 0.9846 - val_loss: 0.0538 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 188/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 0.0541 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 189/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0504 - accuracy: 0.9848 - val_loss: 0.0535 - val_accuracy: 0.9856 - lr: 0.0100\n",
      "Epoch 190/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0502 - accuracy: 0.9847 - val_loss: 0.0545 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 191/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0501 - accuracy: 0.9846 - val_loss: 0.0546 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 192/200\n",
      "733/743 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9848\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0499 - accuracy: 0.9848 - val_loss: 0.0539 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 193/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0497 - accuracy: 0.9848 - val_loss: 0.0537 - val_accuracy: 0.9848 - lr: 1.0000e-03\n",
      "Epoch 194/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0497 - accuracy: 0.9848 - val_loss: 0.0534 - val_accuracy: 0.9848 - lr: 1.0000e-03\n",
      "Epoch 195/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0496 - accuracy: 0.9848 - val_loss: 0.0534 - val_accuracy: 0.9848 - lr: 1.0000e-03\n",
      "Epoch 196/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0496 - accuracy: 0.9849 - val_loss: 0.0534 - val_accuracy: 0.9848 - lr: 1.0000e-03\n",
      "Epoch 197/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0496 - accuracy: 0.9849 - val_loss: 0.0534 - val_accuracy: 0.9856 - lr: 1.0000e-03\n",
      "Epoch 198/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0496 - accuracy: 0.9849 - val_loss: 0.0534 - val_accuracy: 0.9848 - lr: 1.0000e-03\n",
      "Epoch 199/200\n",
      "726/743 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9848\n",
      "Epoch 199: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0496 - accuracy: 0.9849 - val_loss: 0.0533 - val_accuracy: 0.9856 - lr: 1.0000e-03\n",
      "Epoch 200/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0495 - accuracy: 0.9849 - val_loss: 0.0533 - val_accuracy: 0.9856 - lr: 1.0000e-04\n",
      "Score fold 2: loss de 0.0626860111951828; accuracy de 97.73245453834534%\n",
      "****************************************************\n",
      "Iniciando treinamento da fold: 3.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 4s 3ms/step - loss: 0.6917 - accuracy: 0.5356 - val_loss: 0.6899 - val_accuracy: 0.5164 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6868 - accuracy: 0.6069 - val_loss: 0.6845 - val_accuracy: 0.8305 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6815 - accuracy: 0.7038 - val_loss: 0.6793 - val_accuracy: 0.7138 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6757 - accuracy: 0.7966 - val_loss: 0.6733 - val_accuracy: 0.6779 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6689 - accuracy: 0.8051 - val_loss: 0.6657 - val_accuracy: 0.7842 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6607 - accuracy: 0.8355 - val_loss: 0.6567 - val_accuracy: 0.8433 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6510 - accuracy: 0.8511 - val_loss: 0.6458 - val_accuracy: 0.9001 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6393 - accuracy: 0.8805 - val_loss: 0.6332 - val_accuracy: 0.8857 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6253 - accuracy: 0.8881 - val_loss: 0.6184 - val_accuracy: 0.8689 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6089 - accuracy: 0.8927 - val_loss: 0.6014 - val_accuracy: 0.8529 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5901 - accuracy: 0.8900 - val_loss: 0.5805 - val_accuracy: 0.8945 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5688 - accuracy: 0.8985 - val_loss: 0.5578 - val_accuracy: 0.9201 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5454 - accuracy: 0.9059 - val_loss: 0.5337 - val_accuracy: 0.9089 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5203 - accuracy: 0.9107 - val_loss: 0.5084 - val_accuracy: 0.9017 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4943 - accuracy: 0.9106 - val_loss: 0.4815 - val_accuracy: 0.9209 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4680 - accuracy: 0.9160 - val_loss: 0.4554 - val_accuracy: 0.9177 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4419 - accuracy: 0.9184 - val_loss: 0.4293 - val_accuracy: 0.9257 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4166 - accuracy: 0.9215 - val_loss: 0.4048 - val_accuracy: 0.9217 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3926 - accuracy: 0.9235 - val_loss: 0.3809 - val_accuracy: 0.9353 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3701 - accuracy: 0.9269 - val_loss: 0.3593 - val_accuracy: 0.9305 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3493 - accuracy: 0.9290 - val_loss: 0.3391 - val_accuracy: 0.9345 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.9316 - val_loss: 0.3208 - val_accuracy: 0.9353 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3124 - accuracy: 0.9345 - val_loss: 0.3038 - val_accuracy: 0.9369 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2964 - accuracy: 0.9366 - val_loss: 0.2885 - val_accuracy: 0.9392 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2818 - accuracy: 0.9387 - val_loss: 0.2746 - val_accuracy: 0.9376 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2684 - accuracy: 0.9404 - val_loss: 0.2619 - val_accuracy: 0.9376 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2563 - accuracy: 0.9423 - val_loss: 0.2504 - val_accuracy: 0.9400 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2451 - accuracy: 0.9440 - val_loss: 0.2402 - val_accuracy: 0.9384 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2350 - accuracy: 0.9451 - val_loss: 0.2301 - val_accuracy: 0.9416 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2258 - accuracy: 0.9464 - val_loss: 0.2210 - val_accuracy: 0.9456 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2172 - accuracy: 0.9481 - val_loss: 0.2129 - val_accuracy: 0.9480 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2095 - accuracy: 0.9492 - val_loss: 0.2054 - val_accuracy: 0.9488 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2023 - accuracy: 0.9506 - val_loss: 0.1985 - val_accuracy: 0.9504 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1957 - accuracy: 0.9521 - val_loss: 0.1921 - val_accuracy: 0.9552 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1895 - accuracy: 0.9535 - val_loss: 0.1862 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1838 - accuracy: 0.9543 - val_loss: 0.1807 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1786 - accuracy: 0.9553 - val_loss: 0.1755 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1737 - accuracy: 0.9566 - val_loss: 0.1707 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1691 - accuracy: 0.9574 - val_loss: 0.1662 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1648 - accuracy: 0.9584 - val_loss: 0.1620 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1608 - accuracy: 0.9591 - val_loss: 0.1580 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1570 - accuracy: 0.9602 - val_loss: 0.1543 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1535 - accuracy: 0.9608 - val_loss: 0.1508 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1501 - accuracy: 0.9613 - val_loss: 0.1475 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1470 - accuracy: 0.9615 - val_loss: 0.1444 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1440 - accuracy: 0.9629 - val_loss: 0.1413 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1412 - accuracy: 0.9628 - val_loss: 0.1385 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1385 - accuracy: 0.9629 - val_loss: 0.1358 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1359 - accuracy: 0.9633 - val_loss: 0.1332 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1335 - accuracy: 0.9641 - val_loss: 0.1308 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1312 - accuracy: 0.9646 - val_loss: 0.1284 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1289 - accuracy: 0.9648 - val_loss: 0.1262 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1268 - accuracy: 0.9652 - val_loss: 0.1240 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1248 - accuracy: 0.9658 - val_loss: 0.1219 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1228 - accuracy: 0.9659 - val_loss: 0.1199 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1210 - accuracy: 0.9662 - val_loss: 0.1180 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1191 - accuracy: 0.9667 - val_loss: 0.1163 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1174 - accuracy: 0.9672 - val_loss: 0.1145 - val_accuracy: 0.9704 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1158 - accuracy: 0.9672 - val_loss: 0.1128 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1142 - accuracy: 0.9680 - val_loss: 0.1111 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1126 - accuracy: 0.9685 - val_loss: 0.1096 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1111 - accuracy: 0.9686 - val_loss: 0.1080 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1097 - accuracy: 0.9689 - val_loss: 0.1066 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1083 - accuracy: 0.9694 - val_loss: 0.1052 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1069 - accuracy: 0.9699 - val_loss: 0.1038 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1057 - accuracy: 0.9702 - val_loss: 0.1025 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1044 - accuracy: 0.9704 - val_loss: 0.1012 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1032 - accuracy: 0.9706 - val_loss: 0.1000 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1020 - accuracy: 0.9707 - val_loss: 0.0988 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1008 - accuracy: 0.9714 - val_loss: 0.0976 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0997 - accuracy: 0.9715 - val_loss: 0.0966 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0986 - accuracy: 0.9718 - val_loss: 0.0954 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0975 - accuracy: 0.9717 - val_loss: 0.0946 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0965 - accuracy: 0.9720 - val_loss: 0.0934 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0955 - accuracy: 0.9726 - val_loss: 0.0923 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0946 - accuracy: 0.9731 - val_loss: 0.0915 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0936 - accuracy: 0.9730 - val_loss: 0.0904 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0927 - accuracy: 0.9732 - val_loss: 0.0895 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0918 - accuracy: 0.9729 - val_loss: 0.0887 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0909 - accuracy: 0.9731 - val_loss: 0.0878 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0900 - accuracy: 0.9739 - val_loss: 0.0874 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0893 - accuracy: 0.9739 - val_loss: 0.0862 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0885 - accuracy: 0.9739 - val_loss: 0.0853 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0877 - accuracy: 0.9743 - val_loss: 0.0847 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0869 - accuracy: 0.9743 - val_loss: 0.0838 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0862 - accuracy: 0.9744 - val_loss: 0.0831 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0854 - accuracy: 0.9749 - val_loss: 0.0824 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.0817 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0840 - accuracy: 0.9754 - val_loss: 0.0810 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0833 - accuracy: 0.9751 - val_loss: 0.0804 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0826 - accuracy: 0.9756 - val_loss: 0.0797 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0820 - accuracy: 0.9761 - val_loss: 0.0792 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0813 - accuracy: 0.9763 - val_loss: 0.0787 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0807 - accuracy: 0.9762 - val_loss: 0.0779 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0801 - accuracy: 0.9764 - val_loss: 0.0773 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0795 - accuracy: 0.9770 - val_loss: 0.0769 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0789 - accuracy: 0.9766 - val_loss: 0.0763 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0783 - accuracy: 0.9767 - val_loss: 0.0757 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0778 - accuracy: 0.9767 - val_loss: 0.0751 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0772 - accuracy: 0.9772 - val_loss: 0.0747 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0767 - accuracy: 0.9771 - val_loss: 0.0744 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0762 - accuracy: 0.9771 - val_loss: 0.0737 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0756 - accuracy: 0.9772 - val_loss: 0.0732 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0751 - accuracy: 0.9777 - val_loss: 0.0727 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0746 - accuracy: 0.9777 - val_loss: 0.0723 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0741 - accuracy: 0.9777 - val_loss: 0.0718 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0736 - accuracy: 0.9781 - val_loss: 0.0713 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0732 - accuracy: 0.9782 - val_loss: 0.0709 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0727 - accuracy: 0.9781 - val_loss: 0.0705 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0722 - accuracy: 0.9782 - val_loss: 0.0702 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0718 - accuracy: 0.9784 - val_loss: 0.0697 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0713 - accuracy: 0.9783 - val_loss: 0.0693 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0709 - accuracy: 0.9789 - val_loss: 0.0689 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0705 - accuracy: 0.9790 - val_loss: 0.0686 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0701 - accuracy: 0.9790 - val_loss: 0.0682 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0697 - accuracy: 0.9792 - val_loss: 0.0678 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0692 - accuracy: 0.9797 - val_loss: 0.0677 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0688 - accuracy: 0.9795 - val_loss: 0.0674 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0684 - accuracy: 0.9791 - val_loss: 0.0670 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0680 - accuracy: 0.9797 - val_loss: 0.0669 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0677 - accuracy: 0.9798 - val_loss: 0.0663 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0673 - accuracy: 0.9800 - val_loss: 0.0658 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0669 - accuracy: 0.9800 - val_loss: 0.0658 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0666 - accuracy: 0.9800 - val_loss: 0.0654 - val_accuracy: 0.9800 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0662 - accuracy: 0.9801 - val_loss: 0.0649 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0659 - accuracy: 0.9800 - val_loss: 0.0647 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0655 - accuracy: 0.9804 - val_loss: 0.0644 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0652 - accuracy: 0.9805 - val_loss: 0.0642 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0648 - accuracy: 0.9802 - val_loss: 0.0640 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0645 - accuracy: 0.9808 - val_loss: 0.0638 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0642 - accuracy: 0.9806 - val_loss: 0.0633 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0638 - accuracy: 0.9807 - val_loss: 0.0633 - val_accuracy: 0.9816 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0635 - accuracy: 0.9804 - val_loss: 0.0629 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 134/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0632 - accuracy: 0.9808 - val_loss: 0.0627 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 135/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.0622 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 136/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0626 - accuracy: 0.9811 - val_loss: 0.0620 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 137/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0623 - accuracy: 0.9809 - val_loss: 0.0619 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 138/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0620 - accuracy: 0.9812 - val_loss: 0.0614 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 139/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0617 - accuracy: 0.9813 - val_loss: 0.0616 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 140/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0614 - accuracy: 0.9813 - val_loss: 0.0611 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 141/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0611 - accuracy: 0.9813 - val_loss: 0.0609 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 142/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0608 - accuracy: 0.9816 - val_loss: 0.0611 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 143/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0606 - accuracy: 0.9816 - val_loss: 0.0605 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 144/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0603 - accuracy: 0.9817 - val_loss: 0.0604 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 145/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0600 - accuracy: 0.9816 - val_loss: 0.0600 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 146/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0598 - accuracy: 0.9818 - val_loss: 0.0598 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 147/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0595 - accuracy: 0.9820 - val_loss: 0.0596 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 148/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0592 - accuracy: 0.9818 - val_loss: 0.0593 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 149/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0590 - accuracy: 0.9824 - val_loss: 0.0592 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 150/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0587 - accuracy: 0.9824 - val_loss: 0.0591 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 151/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0585 - accuracy: 0.9822 - val_loss: 0.0589 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 152/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0582 - accuracy: 0.9825 - val_loss: 0.0596 - val_accuracy: 0.9824 - lr: 0.0100\n",
      "Epoch 153/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0579 - accuracy: 0.9828 - val_loss: 0.0584 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 154/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0577 - accuracy: 0.9827 - val_loss: 0.0586 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 155/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0575 - accuracy: 0.9827 - val_loss: 0.0582 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 156/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0573 - accuracy: 0.9829 - val_loss: 0.0579 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 157/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 0.0583 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 158/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0568 - accuracy: 0.9828 - val_loss: 0.0578 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 159/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 0.0575 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 160/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0564 - accuracy: 0.9830 - val_loss: 0.0574 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 161/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0561 - accuracy: 0.9830 - val_loss: 0.0572 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 162/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0559 - accuracy: 0.9833 - val_loss: 0.0574 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 163/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0556 - accuracy: 0.9833 - val_loss: 0.0568 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 164/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0554 - accuracy: 0.9835 - val_loss: 0.0574 - val_accuracy: 0.9832 - lr: 0.0100\n",
      "Epoch 165/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0553 - accuracy: 0.9835 - val_loss: 0.0566 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 166/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0550 - accuracy: 0.9834 - val_loss: 0.0565 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 167/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0548 - accuracy: 0.9840 - val_loss: 0.0563 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 168/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0546 - accuracy: 0.9839 - val_loss: 0.0560 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 169/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0544 - accuracy: 0.9839 - val_loss: 0.0561 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 170/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0542 - accuracy: 0.9841 - val_loss: 0.0560 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 171/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0540 - accuracy: 0.9841 - val_loss: 0.0559 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 172/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0538 - accuracy: 0.9841 - val_loss: 0.0557 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 173/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0536 - accuracy: 0.9840 - val_loss: 0.0554 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 174/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0534 - accuracy: 0.9840 - val_loss: 0.0557 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 175/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0532 - accuracy: 0.9842 - val_loss: 0.0554 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 176/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0530 - accuracy: 0.9843 - val_loss: 0.0550 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 177/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0528 - accuracy: 0.9843 - val_loss: 0.0547 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 178/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.0548 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 179/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0524 - accuracy: 0.9846 - val_loss: 0.0550 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 180/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 0.0546 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 181/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0520 - accuracy: 0.9844 - val_loss: 0.0542 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 182/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0519 - accuracy: 0.9844 - val_loss: 0.0543 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 183/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0517 - accuracy: 0.9846 - val_loss: 0.0547 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 184/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0515 - accuracy: 0.9848 - val_loss: 0.0542 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 185/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0513 - accuracy: 0.9848 - val_loss: 0.0538 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 186/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0512 - accuracy: 0.9848 - val_loss: 0.0538 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 187/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0509 - accuracy: 0.9849 - val_loss: 0.0539 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 188/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0508 - accuracy: 0.9850 - val_loss: 0.0538 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 189/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0506 - accuracy: 0.9850 - val_loss: 0.0536 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 190/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0505 - accuracy: 0.9850 - val_loss: 0.0535 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 191/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0503 - accuracy: 0.9849 - val_loss: 0.0534 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 192/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0502 - accuracy: 0.9852 - val_loss: 0.0534 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 193/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0499 - accuracy: 0.9853 - val_loss: 0.0541 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 194/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0498 - accuracy: 0.9852 - val_loss: 0.0532 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 195/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.0536 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 196/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0495 - accuracy: 0.9853 - val_loss: 0.0532 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 197/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0494 - accuracy: 0.9853 - val_loss: 0.0529 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 198/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0492 - accuracy: 0.9854 - val_loss: 0.0530 - val_accuracy: 0.9840 - lr: 0.0100\n",
      "Epoch 199/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0490 - accuracy: 0.9854 - val_loss: 0.0525 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Epoch 200/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0489 - accuracy: 0.9856 - val_loss: 0.0526 - val_accuracy: 0.9848 - lr: 0.0100\n",
      "Score fold 3: loss de 0.0632193461060524; accuracy de 97.72045612335205%\n",
      "****************************************************\n",
      "Iniciando treinamento da fold: 4.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 3s 3ms/step - loss: 0.6900 - accuracy: 0.6186 - val_loss: 0.6885 - val_accuracy: 0.5052 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6847 - accuracy: 0.6548 - val_loss: 0.6829 - val_accuracy: 0.6187 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6789 - accuracy: 0.7072 - val_loss: 0.6764 - val_accuracy: 0.8633 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6724 - accuracy: 0.8226 - val_loss: 0.6696 - val_accuracy: 0.8449 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6647 - accuracy: 0.8543 - val_loss: 0.6618 - val_accuracy: 0.7850 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6555 - accuracy: 0.8443 - val_loss: 0.6513 - val_accuracy: 0.8769 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6444 - accuracy: 0.8828 - val_loss: 0.6401 - val_accuracy: 0.8225 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6312 - accuracy: 0.8710 - val_loss: 0.6250 - val_accuracy: 0.8897 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6156 - accuracy: 0.8945 - val_loss: 0.6086 - val_accuracy: 0.8753 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5975 - accuracy: 0.8959 - val_loss: 0.5897 - val_accuracy: 0.8737 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5768 - accuracy: 0.8964 - val_loss: 0.5675 - val_accuracy: 0.8945 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5539 - accuracy: 0.9035 - val_loss: 0.5433 - val_accuracy: 0.9033 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5291 - accuracy: 0.9096 - val_loss: 0.5184 - val_accuracy: 0.8977 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5031 - accuracy: 0.9108 - val_loss: 0.4917 - val_accuracy: 0.9065 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4766 - accuracy: 0.9141 - val_loss: 0.4649 - val_accuracy: 0.9209 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4501 - accuracy: 0.9177 - val_loss: 0.4391 - val_accuracy: 0.9177 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4244 - accuracy: 0.9209 - val_loss: 0.4142 - val_accuracy: 0.9177 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3998 - accuracy: 0.9233 - val_loss: 0.3904 - val_accuracy: 0.9209 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3766 - accuracy: 0.9263 - val_loss: 0.3678 - val_accuracy: 0.9257 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3551 - accuracy: 0.9297 - val_loss: 0.3475 - val_accuracy: 0.9265 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3353 - accuracy: 0.9319 - val_loss: 0.3285 - val_accuracy: 0.9273 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3171 - accuracy: 0.9342 - val_loss: 0.3107 - val_accuracy: 0.9329 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3005 - accuracy: 0.9373 - val_loss: 0.2955 - val_accuracy: 0.9305 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2854 - accuracy: 0.9387 - val_loss: 0.2812 - val_accuracy: 0.9337 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2716 - accuracy: 0.9409 - val_loss: 0.2680 - val_accuracy: 0.9384 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2591 - accuracy: 0.9425 - val_loss: 0.2557 - val_accuracy: 0.9384 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2476 - accuracy: 0.9443 - val_loss: 0.2450 - val_accuracy: 0.9400 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2372 - accuracy: 0.9462 - val_loss: 0.2356 - val_accuracy: 0.9408 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2276 - accuracy: 0.9470 - val_loss: 0.2259 - val_accuracy: 0.9424 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2188 - accuracy: 0.9489 - val_loss: 0.2175 - val_accuracy: 0.9432 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2108 - accuracy: 0.9510 - val_loss: 0.2106 - val_accuracy: 0.9440 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2034 - accuracy: 0.9516 - val_loss: 0.2030 - val_accuracy: 0.9440 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1967 - accuracy: 0.9522 - val_loss: 0.1962 - val_accuracy: 0.9472 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1904 - accuracy: 0.9532 - val_loss: 0.1900 - val_accuracy: 0.9504 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1846 - accuracy: 0.9545 - val_loss: 0.1845 - val_accuracy: 0.9528 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1792 - accuracy: 0.9560 - val_loss: 0.1789 - val_accuracy: 0.9568 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1742 - accuracy: 0.9567 - val_loss: 0.1740 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1694 - accuracy: 0.9580 - val_loss: 0.1710 - val_accuracy: 0.9512 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1651 - accuracy: 0.9587 - val_loss: 0.1651 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1610 - accuracy: 0.9603 - val_loss: 0.1608 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1571 - accuracy: 0.9609 - val_loss: 0.1579 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1536 - accuracy: 0.9611 - val_loss: 0.1534 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1502 - accuracy: 0.9626 - val_loss: 0.1503 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1470 - accuracy: 0.9628 - val_loss: 0.1468 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1440 - accuracy: 0.9636 - val_loss: 0.1443 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1412 - accuracy: 0.9642 - val_loss: 0.1412 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1384 - accuracy: 0.9650 - val_loss: 0.1384 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1358 - accuracy: 0.9648 - val_loss: 0.1358 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1334 - accuracy: 0.9655 - val_loss: 0.1328 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1309 - accuracy: 0.9654 - val_loss: 0.1302 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1288 - accuracy: 0.9665 - val_loss: 0.1284 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1266 - accuracy: 0.9667 - val_loss: 0.1261 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1246 - accuracy: 0.9669 - val_loss: 0.1240 - val_accuracy: 0.9704 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1226 - accuracy: 0.9672 - val_loss: 0.1217 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1208 - accuracy: 0.9674 - val_loss: 0.1199 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1189 - accuracy: 0.9679 - val_loss: 0.1179 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1172 - accuracy: 0.9685 - val_loss: 0.1165 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1155 - accuracy: 0.9688 - val_loss: 0.1144 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1139 - accuracy: 0.9695 - val_loss: 0.1130 - val_accuracy: 0.9720 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1123 - accuracy: 0.9697 - val_loss: 0.1114 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1108 - accuracy: 0.9702 - val_loss: 0.1099 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1094 - accuracy: 0.9703 - val_loss: 0.1080 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1080 - accuracy: 0.9705 - val_loss: 0.1065 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1066 - accuracy: 0.9710 - val_loss: 0.1057 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1053 - accuracy: 0.9711 - val_loss: 0.1043 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1040 - accuracy: 0.9716 - val_loss: 0.1023 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1029 - accuracy: 0.9721 - val_loss: 0.1015 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1016 - accuracy: 0.9723 - val_loss: 0.1004 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1005 - accuracy: 0.9723 - val_loss: 0.0988 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0993 - accuracy: 0.9725 - val_loss: 0.0978 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0982 - accuracy: 0.9727 - val_loss: 0.0965 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0972 - accuracy: 0.9728 - val_loss: 0.0957 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0961 - accuracy: 0.9734 - val_loss: 0.0945 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0952 - accuracy: 0.9732 - val_loss: 0.0939 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0942 - accuracy: 0.9737 - val_loss: 0.0929 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0932 - accuracy: 0.9737 - val_loss: 0.0917 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0923 - accuracy: 0.9740 - val_loss: 0.0907 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0914 - accuracy: 0.9741 - val_loss: 0.0898 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0905 - accuracy: 0.9747 - val_loss: 0.0889 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0897 - accuracy: 0.9748 - val_loss: 0.0881 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0888 - accuracy: 0.9747 - val_loss: 0.0875 - val_accuracy: 0.9736 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0880 - accuracy: 0.9749 - val_loss: 0.0863 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0872 - accuracy: 0.9753 - val_loss: 0.0856 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0864 - accuracy: 0.9749 - val_loss: 0.0849 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0856 - accuracy: 0.9756 - val_loss: 0.0851 - val_accuracy: 0.9728 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0850 - accuracy: 0.9756 - val_loss: 0.0836 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0842 - accuracy: 0.9758 - val_loss: 0.0830 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0835 - accuracy: 0.9758 - val_loss: 0.0824 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0828 - accuracy: 0.9759 - val_loss: 0.0815 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0822 - accuracy: 0.9759 - val_loss: 0.0811 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0815 - accuracy: 0.9760 - val_loss: 0.0803 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0809 - accuracy: 0.9763 - val_loss: 0.0795 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0802 - accuracy: 0.9763 - val_loss: 0.0790 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0796 - accuracy: 0.9765 - val_loss: 0.0785 - val_accuracy: 0.9744 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0790 - accuracy: 0.9765 - val_loss: 0.0778 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0784 - accuracy: 0.9768 - val_loss: 0.0772 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0778 - accuracy: 0.9769 - val_loss: 0.0767 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0773 - accuracy: 0.9767 - val_loss: 0.0763 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0767 - accuracy: 0.9771 - val_loss: 0.0759 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0761 - accuracy: 0.9774 - val_loss: 0.0754 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0756 - accuracy: 0.9772 - val_loss: 0.0749 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0751 - accuracy: 0.9775 - val_loss: 0.0744 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0746 - accuracy: 0.9777 - val_loss: 0.0742 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0741 - accuracy: 0.9777 - val_loss: 0.0734 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0736 - accuracy: 0.9779 - val_loss: 0.0727 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0731 - accuracy: 0.9778 - val_loss: 0.0722 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0726 - accuracy: 0.9781 - val_loss: 0.0720 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0721 - accuracy: 0.9781 - val_loss: 0.0715 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0717 - accuracy: 0.9785 - val_loss: 0.0712 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0712 - accuracy: 0.9784 - val_loss: 0.0707 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0707 - accuracy: 0.9789 - val_loss: 0.0706 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0703 - accuracy: 0.9789 - val_loss: 0.0700 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0699 - accuracy: 0.9791 - val_loss: 0.0693 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0695 - accuracy: 0.9791 - val_loss: 0.0694 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0691 - accuracy: 0.9794 - val_loss: 0.0692 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0687 - accuracy: 0.9796 - val_loss: 0.0688 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0682 - accuracy: 0.9796 - val_loss: 0.0684 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0678 - accuracy: 0.9795 - val_loss: 0.0678 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0675 - accuracy: 0.9798 - val_loss: 0.0676 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0671 - accuracy: 0.9799 - val_loss: 0.0671 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0667 - accuracy: 0.9801 - val_loss: 0.0665 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0664 - accuracy: 0.9799 - val_loss: 0.0671 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0660 - accuracy: 0.9801 - val_loss: 0.0660 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0656 - accuracy: 0.9802 - val_loss: 0.0658 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0653 - accuracy: 0.9806 - val_loss: 0.0655 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0649 - accuracy: 0.9805 - val_loss: 0.0653 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0646 - accuracy: 0.9805 - val_loss: 0.0654 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0642 - accuracy: 0.9806 - val_loss: 0.0646 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0639 - accuracy: 0.9806 - val_loss: 0.0649 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0636 - accuracy: 0.9811 - val_loss: 0.0646 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9810 - val_loss: 0.0639 - val_accuracy: 0.9752 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0629 - accuracy: 0.9809 - val_loss: 0.0635 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0626 - accuracy: 0.9809 - val_loss: 0.0633 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 134/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0623 - accuracy: 0.9808 - val_loss: 0.0637 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 135/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0620 - accuracy: 0.9809 - val_loss: 0.0632 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 136/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0617 - accuracy: 0.9811 - val_loss: 0.0626 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 137/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0614 - accuracy: 0.9814 - val_loss: 0.0623 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 138/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0611 - accuracy: 0.9814 - val_loss: 0.0626 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 139/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0608 - accuracy: 0.9816 - val_loss: 0.0618 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 140/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0606 - accuracy: 0.9816 - val_loss: 0.0616 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 141/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0603 - accuracy: 0.9819 - val_loss: 0.0616 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 142/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0600 - accuracy: 0.9818 - val_loss: 0.0616 - val_accuracy: 0.9760 - lr: 0.0100\n",
      "Epoch 143/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0597 - accuracy: 0.9818 - val_loss: 0.0608 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 144/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0595 - accuracy: 0.9820 - val_loss: 0.0608 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 145/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0592 - accuracy: 0.9819 - val_loss: 0.0614 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 146/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0589 - accuracy: 0.9821 - val_loss: 0.0603 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 147/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0587 - accuracy: 0.9822 - val_loss: 0.0603 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 148/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0584 - accuracy: 0.9823 - val_loss: 0.0604 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 149/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0582 - accuracy: 0.9824 - val_loss: 0.0599 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 150/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0579 - accuracy: 0.9826 - val_loss: 0.0595 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 151/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0576 - accuracy: 0.9828 - val_loss: 0.0596 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 152/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0574 - accuracy: 0.9825 - val_loss: 0.0589 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 153/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0572 - accuracy: 0.9830 - val_loss: 0.0594 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 154/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0569 - accuracy: 0.9827 - val_loss: 0.0591 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 155/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.0591 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 156/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0564 - accuracy: 0.9831 - val_loss: 0.0587 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 157/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0562 - accuracy: 0.9830 - val_loss: 0.0594 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 158/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0560 - accuracy: 0.9830 - val_loss: 0.0582 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 159/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0558 - accuracy: 0.9833 - val_loss: 0.0578 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 160/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0555 - accuracy: 0.9834 - val_loss: 0.0584 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 161/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.0579 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 162/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0551 - accuracy: 0.9835 - val_loss: 0.0572 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 163/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0549 - accuracy: 0.9834 - val_loss: 0.0574 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 164/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0546 - accuracy: 0.9836 - val_loss: 0.0570 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 165/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0545 - accuracy: 0.9838 - val_loss: 0.0574 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 166/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.0573 - val_accuracy: 0.9768 - lr: 0.0100\n",
      "Epoch 167/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0540 - accuracy: 0.9836 - val_loss: 0.0567 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 168/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0538 - accuracy: 0.9838 - val_loss: 0.0564 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 169/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0536 - accuracy: 0.9837 - val_loss: 0.0562 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 170/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0534 - accuracy: 0.9838 - val_loss: 0.0561 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 171/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0532 - accuracy: 0.9841 - val_loss: 0.0564 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 172/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0530 - accuracy: 0.9841 - val_loss: 0.0563 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 173/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0528 - accuracy: 0.9842 - val_loss: 0.0562 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 174/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0527 - accuracy: 0.9841 - val_loss: 0.0561 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 175/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0524 - accuracy: 0.9840 - val_loss: 0.0557 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 176/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0523 - accuracy: 0.9842 - val_loss: 0.0554 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 177/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0521 - accuracy: 0.9842 - val_loss: 0.0557 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 178/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.0551 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 179/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0517 - accuracy: 0.9843 - val_loss: 0.0553 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 180/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0550 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 181/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0513 - accuracy: 0.9846 - val_loss: 0.0547 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 182/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0511 - accuracy: 0.9846 - val_loss: 0.0543 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 183/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0510 - accuracy: 0.9845 - val_loss: 0.0547 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 184/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.0546 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 185/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.0541 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 186/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0504 - accuracy: 0.9845 - val_loss: 0.0552 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 187/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0503 - accuracy: 0.9849 - val_loss: 0.0547 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 188/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0501 - accuracy: 0.9849 - val_loss: 0.0540 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 189/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 0.0542 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 190/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0497 - accuracy: 0.9848 - val_loss: 0.0540 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 191/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.0539 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 192/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0494 - accuracy: 0.9852 - val_loss: 0.0530 - val_accuracy: 0.9808 - lr: 0.0100\n",
      "Epoch 193/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0493 - accuracy: 0.9853 - val_loss: 0.0534 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 194/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0491 - accuracy: 0.9852 - val_loss: 0.0540 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 195/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0490 - accuracy: 0.9852 - val_loss: 0.0532 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 196/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 0.0530 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 197/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0486 - accuracy: 0.9853 - val_loss: 0.0538 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Epoch 198/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0485 - accuracy: 0.9854 - val_loss: 0.0532 - val_accuracy: 0.9784 - lr: 0.0100\n",
      "Epoch 199/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 0.0527 - val_accuracy: 0.9792 - lr: 0.0100\n",
      "Epoch 200/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0481 - accuracy: 0.9856 - val_loss: 0.0535 - val_accuracy: 0.9776 - lr: 0.0100\n",
      "Score fold 4: loss de 0.07025174796581268; accuracy de 97.58847951889038%\n"
     ]
    }
   ],
   "source": [
    "foldCount = 1\n",
    "for train, test in kfold.split(dfTfidf, targets):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.LSTM(500, activation='tanh',recurrent_activation='sigmoid',input_shape=[1, dfTfidf.shape[2]]),\n",
    "\n",
    "        ########## Stacked LSTM\n",
    "        # keras.layers.LSTM(784, activation='relu', return_sequences=True, input_shape=[1, dfTfidf.shape[2]]),\n",
    "        # keras.layers.LSTM(250, activation='relu', return_sequences=True),\n",
    "        # keras.layers.LSTM(90, activation='relu', return_sequences=True),\n",
    "        # keras.layers.LSTM(30, activation='relu'),\n",
    "\n",
    "        keras.layers.Dense(len(set(targets)), activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=['accuracy'])\n",
    "\n",
    "    print('****************************************************')\n",
    "    print(f'Iniciando treinamento da fold: {foldCount}.')\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4,mode='min'), tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0, restore_best_weights=True)]\n",
    "\n",
    "    history = model.fit(dfTfidf[train], targets[train], epochs=200, callbacks=callbacks, validation_split=0.05)\n",
    "\n",
    "    scores = model.evaluate(dfTfidf[test], targets[test], verbose=0)\n",
    "    print(f'Score fold {foldCount}: {model.metrics_names[0]} de {scores[0]}; {model.metrics_names[1]} de {scores[1]*100}%')\n",
    "\n",
    "    foldsAccuracy.append(scores[1] * 100)\n",
    "    foldLosses.append(scores[0])\n",
    "\n",
    "    foldCount = foldCount + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Score de cada fold:\n",
      "****************************************************\n",
      "--> Fold 1: Loss: 0.06222359091043472 ; Accuracy: 97.93666005134583%\n",
      "****************************************************\n",
      "--> Fold 2: Loss: 0.0626860111951828 ; Accuracy: 97.73245453834534%\n",
      "****************************************************\n",
      "--> Fold 3: Loss: 0.0632193461060524 ; Accuracy: 97.72045612335205%\n",
      "****************************************************\n",
      "--> Fold 4: Loss: 0.07025174796581268 ; Accuracy: 97.58847951889038%\n",
      "****************************************************\n",
      "Média de accuracy das folds:\n",
      "--> Accuracy: 97.7445125579834 (+- 0.12449003612622093)\n",
      "--> Loss: 0.06459517404437065\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "print('****************************************************')\n",
    "print('Score de cada fold:')\n",
    "for i in range(0, len(foldsAccuracy)):\n",
    "    print('****************************************************')\n",
    "    print(f'--> Fold {i+1}: Loss: {foldLosses[i]} ; Accuracy: {foldsAccuracy[i]}%')\n",
    "\n",
    "print('****************************************************')\n",
    "print('Média de accuracy das folds:')\n",
    "print(f'--> Accuracy: {np.mean(foldsAccuracy)} (+- {np.std(foldsAccuracy)})')\n",
    "print(f'--> Loss: {np.mean(foldLosses)}')\n",
    "print('****************************************************')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}