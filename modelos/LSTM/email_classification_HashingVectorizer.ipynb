{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Carregando base de dados  pré-processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   email  target\n0      start date     hourahead timee  cardinall  hou...       0\n1      service long desk  price structure deal quote ...       0\n2      start date  cardinall    hourahead timee  card...       0\n3      start date     hourahead timee  cardinall  anc...       0\n4      cardinall deliverable revenue management marke...       0\n...                                                  ...     ...\n33340  bio  matrix scientific group   symbo   bmxg  p...       1\n33341   cardinall step away hot naked webcam girl liv...       1\n33342  need pill increase performance click  seroius ...       1\n33343  datee final nom       inlet hpl  eastrans  car...       0\n33344  ordinall time  offering male enhancement perfo...       1\n\n[33341 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>start date     hourahead timee  cardinall  hou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>service long desk  price structure deal quote ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>start date  cardinall    hourahead timee  card...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>start date     hourahead timee  cardinall  anc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cardinall deliverable revenue management marke...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33340</th>\n      <td>bio  matrix scientific group   symbo   bmxg  p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33341</th>\n      <td>cardinall step away hot naked webcam girl liv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33342</th>\n      <td>need pill increase performance click  seroius ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33343</th>\n      <td>datee final nom       inlet hpl  eastrans  car...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33344</th>\n      <td>ordinall time  offering male enhancement perfo...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>33341 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../../Database/dataBaseWithNER.csv\")\n",
    "dataset = dataset.drop(columns=[\"Unnamed: 0\"])\n",
    "dataset = dataset.dropna()\n",
    "targets = np.array(dataset[\"target\"].array)\n",
    "\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "emailsText = []\n",
    "for email in dataset[\"email\"]:\n",
    "    emailsText.append(email)\n",
    "\n",
    "del dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33341\n"
     ]
    }
   ],
   "source": [
    "print(len(emailsText))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Representação vetorial Hashing Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           0     1     2         3         4     5     6     7     8     9     \\\n0      0.000000   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n1      0.000000   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n2      0.000000   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n3      0.000000   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n4      0.000000   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n...         ...   ...   ...       ...       ...   ...   ...   ...   ...   ...   \n33336 -0.028318   0.0   0.0  0.014159 -0.028318   0.0   0.0   0.0   0.0   0.0   \n33337  0.000000   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n33338  0.000000   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n33339  0.000000   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n33340  0.000000   0.0   0.0  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n\n       ...      2090  2091  2092  2093  2094  2095      2096  2097  2098  2099  \n0      ...  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n1      ...  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n2      ...  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n3      ...  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n4      ...  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n...    ...       ...   ...   ...   ...   ...   ...       ...   ...   ...   ...  \n33336  ...  0.014159   0.0   0.0   0.0   0.0   0.0 -0.028318   0.0   0.0   0.0  \n33337  ...  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n33338  ...  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n33339  ...  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n33340  ...  0.000000   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n\n[33341 rows x 2100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>2090</th>\n      <th>2091</th>\n      <th>2092</th>\n      <th>2093</th>\n      <th>2094</th>\n      <th>2095</th>\n      <th>2096</th>\n      <th>2097</th>\n      <th>2098</th>\n      <th>2099</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33336</th>\n      <td>-0.028318</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.014159</td>\n      <td>-0.028318</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.014159</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.028318</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33337</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33338</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33339</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33340</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>33341 rows × 2100 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = HashingVectorizer(n_features=2100)\n",
    "X = vectorizer.fit_transform(emailsText)\n",
    "hashing = pd.DataFrame(X.toarray())\n",
    "\n",
    "hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashing = np.array(hashing)\n",
    "hashing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33341, 1, 2100)\n"
     ]
    }
   ],
   "source": [
    "hashing = hashing.reshape((hashing.shape[0], 1, hashing.shape[1]))\n",
    "\n",
    "print(hashing.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualização de dados com TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = TSNE(n_components=2, random_state=0)\n",
    "# array_red = model.fit_transform(hashing)\n",
    "#\n",
    "# df_tsne = pd.DataFrame(array_red)\n",
    "#\n",
    "# df_tsne['Target'] = target\n",
    "# df_tsne_c1 = df_tsne[df_tsne['Target'] == 0]\n",
    "#\n",
    "# df_tsne_c2 = df_tsne[df_tsne['Target'] == 1]\n",
    "#\n",
    "# plt.scatter(df_tsne_c1[0].array,df_tsne_c1[1].array,marker='o',color='blue')\n",
    "#\n",
    "# plt.scatter(df_tsne_c2[0].array,df_tsne_c2[1].array,marker='o',color='red')\n",
    "#\n",
    "# plt.title('Dados')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "#\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "foldsAccuracy = []\n",
    "foldLosses = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=4, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Iniciando treinamento da fold: 1.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 5s 3ms/step - loss: 0.6884 - accuracy: 0.6013 - val_loss: 0.6839 - val_accuracy: 0.6954 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6793 - accuracy: 0.7205 - val_loss: 0.6742 - val_accuracy: 0.7626 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6695 - accuracy: 0.7712 - val_loss: 0.6633 - val_accuracy: 0.7842 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6581 - accuracy: 0.7928 - val_loss: 0.6504 - val_accuracy: 0.7986 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6446 - accuracy: 0.8015 - val_loss: 0.6353 - val_accuracy: 0.8002 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6285 - accuracy: 0.8065 - val_loss: 0.6169 - val_accuracy: 0.8145 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6096 - accuracy: 0.8125 - val_loss: 0.5960 - val_accuracy: 0.8137 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5878 - accuracy: 0.8154 - val_loss: 0.5718 - val_accuracy: 0.8177 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5634 - accuracy: 0.8179 - val_loss: 0.5458 - val_accuracy: 0.8177 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5373 - accuracy: 0.8205 - val_loss: 0.5184 - val_accuracy: 0.8273 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5104 - accuracy: 0.8265 - val_loss: 0.4912 - val_accuracy: 0.8289 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4839 - accuracy: 0.8296 - val_loss: 0.4647 - val_accuracy: 0.8393 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4585 - accuracy: 0.8362 - val_loss: 0.4401 - val_accuracy: 0.8465 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4349 - accuracy: 0.8403 - val_loss: 0.4176 - val_accuracy: 0.8489 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4131 - accuracy: 0.8503 - val_loss: 0.3970 - val_accuracy: 0.8577 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3931 - accuracy: 0.8575 - val_loss: 0.3785 - val_accuracy: 0.8569 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3748 - accuracy: 0.8624 - val_loss: 0.3618 - val_accuracy: 0.8633 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3582 - accuracy: 0.8689 - val_loss: 0.3460 - val_accuracy: 0.8665 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3427 - accuracy: 0.8745 - val_loss: 0.3318 - val_accuracy: 0.8713 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3285 - accuracy: 0.8808 - val_loss: 0.3187 - val_accuracy: 0.8777 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3152 - accuracy: 0.8861 - val_loss: 0.3066 - val_accuracy: 0.8793 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3029 - accuracy: 0.8920 - val_loss: 0.2955 - val_accuracy: 0.8841 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2916 - accuracy: 0.8967 - val_loss: 0.2847 - val_accuracy: 0.8897 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2809 - accuracy: 0.9007 - val_loss: 0.2750 - val_accuracy: 0.8929 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2709 - accuracy: 0.9050 - val_loss: 0.2657 - val_accuracy: 0.8969 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2618 - accuracy: 0.9086 - val_loss: 0.2570 - val_accuracy: 0.9001 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2532 - accuracy: 0.9116 - val_loss: 0.2488 - val_accuracy: 0.9033 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2450 - accuracy: 0.9159 - val_loss: 0.2416 - val_accuracy: 0.9073 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2375 - accuracy: 0.9191 - val_loss: 0.2339 - val_accuracy: 0.9089 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2303 - accuracy: 0.9226 - val_loss: 0.2270 - val_accuracy: 0.9113 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2236 - accuracy: 0.9252 - val_loss: 0.2205 - val_accuracy: 0.9169 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2173 - accuracy: 0.9277 - val_loss: 0.2143 - val_accuracy: 0.9145 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2113 - accuracy: 0.9302 - val_loss: 0.2085 - val_accuracy: 0.9201 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2057 - accuracy: 0.9318 - val_loss: 0.2030 - val_accuracy: 0.9217 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2003 - accuracy: 0.9333 - val_loss: 0.1976 - val_accuracy: 0.9217 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1954 - accuracy: 0.9357 - val_loss: 0.1927 - val_accuracy: 0.9233 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1906 - accuracy: 0.9377 - val_loss: 0.1879 - val_accuracy: 0.9249 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1861 - accuracy: 0.9391 - val_loss: 0.1834 - val_accuracy: 0.9265 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1818 - accuracy: 0.9403 - val_loss: 0.1791 - val_accuracy: 0.9289 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1779 - accuracy: 0.9417 - val_loss: 0.1751 - val_accuracy: 0.9321 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1740 - accuracy: 0.9434 - val_loss: 0.1719 - val_accuracy: 0.9345 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1705 - accuracy: 0.9449 - val_loss: 0.1679 - val_accuracy: 0.9337 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1671 - accuracy: 0.9463 - val_loss: 0.1647 - val_accuracy: 0.9353 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1639 - accuracy: 0.9470 - val_loss: 0.1609 - val_accuracy: 0.9424 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1608 - accuracy: 0.9480 - val_loss: 0.1580 - val_accuracy: 0.9400 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1579 - accuracy: 0.9488 - val_loss: 0.1551 - val_accuracy: 0.9408 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1550 - accuracy: 0.9497 - val_loss: 0.1520 - val_accuracy: 0.9440 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1526 - accuracy: 0.9504 - val_loss: 0.1493 - val_accuracy: 0.9448 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1501 - accuracy: 0.9509 - val_loss: 0.1468 - val_accuracy: 0.9448 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1477 - accuracy: 0.9519 - val_loss: 0.1445 - val_accuracy: 0.9464 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1455 - accuracy: 0.9520 - val_loss: 0.1422 - val_accuracy: 0.9488 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1432 - accuracy: 0.9530 - val_loss: 0.1403 - val_accuracy: 0.9456 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1412 - accuracy: 0.9534 - val_loss: 0.1382 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1394 - accuracy: 0.9538 - val_loss: 0.1359 - val_accuracy: 0.9504 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1375 - accuracy: 0.9544 - val_loss: 0.1341 - val_accuracy: 0.9480 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1356 - accuracy: 0.9547 - val_loss: 0.1323 - val_accuracy: 0.9520 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1339 - accuracy: 0.9554 - val_loss: 0.1306 - val_accuracy: 0.9504 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1322 - accuracy: 0.9560 - val_loss: 0.1291 - val_accuracy: 0.9488 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1307 - accuracy: 0.9568 - val_loss: 0.1275 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1291 - accuracy: 0.9576 - val_loss: 0.1269 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1277 - accuracy: 0.9578 - val_loss: 0.1244 - val_accuracy: 0.9512 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1263 - accuracy: 0.9583 - val_loss: 0.1235 - val_accuracy: 0.9520 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1249 - accuracy: 0.9584 - val_loss: 0.1219 - val_accuracy: 0.9520 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1235 - accuracy: 0.9590 - val_loss: 0.1208 - val_accuracy: 0.9544 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1223 - accuracy: 0.9597 - val_loss: 0.1195 - val_accuracy: 0.9536 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1210 - accuracy: 0.9598 - val_loss: 0.1183 - val_accuracy: 0.9536 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1199 - accuracy: 0.9600 - val_loss: 0.1170 - val_accuracy: 0.9552 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1188 - accuracy: 0.9605 - val_loss: 0.1166 - val_accuracy: 0.9560 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1176 - accuracy: 0.9611 - val_loss: 0.1150 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1166 - accuracy: 0.9617 - val_loss: 0.1141 - val_accuracy: 0.9568 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1155 - accuracy: 0.9621 - val_loss: 0.1130 - val_accuracy: 0.9552 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1145 - accuracy: 0.9620 - val_loss: 0.1132 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1134 - accuracy: 0.9632 - val_loss: 0.1111 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1125 - accuracy: 0.9631 - val_loss: 0.1108 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1116 - accuracy: 0.9632 - val_loss: 0.1093 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1106 - accuracy: 0.9635 - val_loss: 0.1099 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1097 - accuracy: 0.9640 - val_loss: 0.1078 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1089 - accuracy: 0.9639 - val_loss: 0.1074 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1080 - accuracy: 0.9646 - val_loss: 0.1064 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1072 - accuracy: 0.9644 - val_loss: 0.1056 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1064 - accuracy: 0.9649 - val_loss: 0.1049 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1056 - accuracy: 0.9650 - val_loss: 0.1043 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1048 - accuracy: 0.9655 - val_loss: 0.1036 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1041 - accuracy: 0.9655 - val_loss: 0.1037 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1033 - accuracy: 0.9655 - val_loss: 0.1027 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1027 - accuracy: 0.9659 - val_loss: 0.1018 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1020 - accuracy: 0.9660 - val_loss: 0.1010 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1012 - accuracy: 0.9667 - val_loss: 0.1005 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1006 - accuracy: 0.9666 - val_loss: 0.1000 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0999 - accuracy: 0.9667 - val_loss: 0.0994 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0993 - accuracy: 0.9668 - val_loss: 0.0991 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0986 - accuracy: 0.9676 - val_loss: 0.0987 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0981 - accuracy: 0.9673 - val_loss: 0.0985 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0975 - accuracy: 0.9675 - val_loss: 0.0983 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0969 - accuracy: 0.9678 - val_loss: 0.0969 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0962 - accuracy: 0.9683 - val_loss: 0.0964 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0957 - accuracy: 0.9683 - val_loss: 0.0966 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0952 - accuracy: 0.9683 - val_loss: 0.0956 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0946 - accuracy: 0.9685 - val_loss: 0.0953 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0941 - accuracy: 0.9688 - val_loss: 0.0949 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0934 - accuracy: 0.9696 - val_loss: 0.0944 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0931 - accuracy: 0.9688 - val_loss: 0.0942 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0926 - accuracy: 0.9694 - val_loss: 0.0935 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0921 - accuracy: 0.9696 - val_loss: 0.0933 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0916 - accuracy: 0.9696 - val_loss: 0.0929 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0910 - accuracy: 0.9697 - val_loss: 0.0930 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0906 - accuracy: 0.9697 - val_loss: 0.0923 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0901 - accuracy: 0.9698 - val_loss: 0.0921 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0896 - accuracy: 0.9705 - val_loss: 0.0919 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0892 - accuracy: 0.9704 - val_loss: 0.0919 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0887 - accuracy: 0.9709 - val_loss: 0.0915 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0884 - accuracy: 0.9709 - val_loss: 0.0906 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0878 - accuracy: 0.9710 - val_loss: 0.0903 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0874 - accuracy: 0.9708 - val_loss: 0.0902 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0871 - accuracy: 0.9712 - val_loss: 0.0899 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0866 - accuracy: 0.9717 - val_loss: 0.0898 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0862 - accuracy: 0.9710 - val_loss: 0.0895 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0859 - accuracy: 0.9719 - val_loss: 0.0891 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0854 - accuracy: 0.9714 - val_loss: 0.0897 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0851 - accuracy: 0.9721 - val_loss: 0.0884 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0847 - accuracy: 0.9724 - val_loss: 0.0881 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0843 - accuracy: 0.9722 - val_loss: 0.0881 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0839 - accuracy: 0.9726 - val_loss: 0.0881 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 0.0884 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0831 - accuracy: 0.9727 - val_loss: 0.0876 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0829 - accuracy: 0.9729 - val_loss: 0.0870 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0825 - accuracy: 0.9732 - val_loss: 0.0874 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0821 - accuracy: 0.9733 - val_loss: 0.0878 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0818 - accuracy: 0.9729 - val_loss: 0.0867 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0813 - accuracy: 0.9732 - val_loss: 0.0862 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0811 - accuracy: 0.9731 - val_loss: 0.0859 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0808 - accuracy: 0.9737 - val_loss: 0.0858 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0804 - accuracy: 0.9739 - val_loss: 0.0859 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 134/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0801 - accuracy: 0.9738 - val_loss: 0.0857 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 135/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0799 - accuracy: 0.9740 - val_loss: 0.0853 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 136/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0796 - accuracy: 0.9742 - val_loss: 0.0851 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 137/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0793 - accuracy: 0.9742 - val_loss: 0.0849 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 138/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0788 - accuracy: 0.9745 - val_loss: 0.0848 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 139/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0786 - accuracy: 0.9746 - val_loss: 0.0847 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 140/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0783 - accuracy: 0.9745 - val_loss: 0.0847 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 141/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0780 - accuracy: 0.9750 - val_loss: 0.0844 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 142/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0777 - accuracy: 0.9750 - val_loss: 0.0842 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 143/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0774 - accuracy: 0.9750 - val_loss: 0.0844 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 144/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 0.0840 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 145/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0769 - accuracy: 0.9753 - val_loss: 0.0837 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 146/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0765 - accuracy: 0.9756 - val_loss: 0.0845 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 147/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0764 - accuracy: 0.9756 - val_loss: 0.0837 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 148/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0760 - accuracy: 0.9759 - val_loss: 0.0841 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 149/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0758 - accuracy: 0.9755 - val_loss: 0.0834 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 150/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0755 - accuracy: 0.9758 - val_loss: 0.0831 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 151/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0752 - accuracy: 0.9758 - val_loss: 0.0829 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 152/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0750 - accuracy: 0.9762 - val_loss: 0.0830 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 153/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0747 - accuracy: 0.9761 - val_loss: 0.0828 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 154/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0745 - accuracy: 0.9760 - val_loss: 0.0826 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 155/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0742 - accuracy: 0.9760 - val_loss: 0.0832 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 156/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0739 - accuracy: 0.9762 - val_loss: 0.0828 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 157/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0736 - accuracy: 0.9766 - val_loss: 0.0829 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 158/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0735 - accuracy: 0.9764 - val_loss: 0.0824 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 159/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0733 - accuracy: 0.9764 - val_loss: 0.0822 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 160/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0730 - accuracy: 0.9765 - val_loss: 0.0820 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 161/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0728 - accuracy: 0.9765 - val_loss: 0.0824 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 162/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0725 - accuracy: 0.9772 - val_loss: 0.0820 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 163/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0722 - accuracy: 0.9772 - val_loss: 0.0823 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 164/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0720 - accuracy: 0.9770 - val_loss: 0.0817 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 165/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0719 - accuracy: 0.9770 - val_loss: 0.0821 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 166/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0717 - accuracy: 0.9769 - val_loss: 0.0816 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 167/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0714 - accuracy: 0.9771 - val_loss: 0.0818 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 168/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0711 - accuracy: 0.9775 - val_loss: 0.0815 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 169/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0708 - accuracy: 0.9770 - val_loss: 0.0815 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 170/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0707 - accuracy: 0.9776 - val_loss: 0.0814 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 171/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0705 - accuracy: 0.9776 - val_loss: 0.0811 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 172/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0703 - accuracy: 0.9771 - val_loss: 0.0809 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 173/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0700 - accuracy: 0.9775 - val_loss: 0.0810 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 174/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0699 - accuracy: 0.9777 - val_loss: 0.0810 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 175/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0697 - accuracy: 0.9779 - val_loss: 0.0809 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 176/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0695 - accuracy: 0.9779 - val_loss: 0.0809 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 177/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0693 - accuracy: 0.9781 - val_loss: 0.0810 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 178/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0691 - accuracy: 0.9783 - val_loss: 0.0806 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 179/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0688 - accuracy: 0.9784 - val_loss: 0.0807 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 180/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0686 - accuracy: 0.9788 - val_loss: 0.0813 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 181/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0685 - accuracy: 0.9781 - val_loss: 0.0805 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 182/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0683 - accuracy: 0.9781 - val_loss: 0.0809 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 183/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0681 - accuracy: 0.9782 - val_loss: 0.0803 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 184/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0679 - accuracy: 0.9784 - val_loss: 0.0804 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 185/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0677 - accuracy: 0.9786 - val_loss: 0.0806 - val_accuracy: 0.9712 - lr: 0.0100\n",
      "Epoch 186/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0676 - accuracy: 0.9782 - val_loss: 0.0804 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 187/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0674 - accuracy: 0.9782 - val_loss: 0.0820 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 188/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0672 - accuracy: 0.9785 - val_loss: 0.0805 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 189/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0669 - accuracy: 0.9790 - val_loss: 0.0803 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 190/200\n",
      "727/743 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.9788\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0668 - accuracy: 0.9789 - val_loss: 0.0806 - val_accuracy: 0.9696 - lr: 0.0100\n",
      "Epoch 191/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0662 - accuracy: 0.9792 - val_loss: 0.0802 - val_accuracy: 0.9680 - lr: 1.0000e-03\n",
      "Epoch 192/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0662 - accuracy: 0.9792 - val_loss: 0.0802 - val_accuracy: 0.9680 - lr: 1.0000e-03\n",
      "Epoch 193/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0662 - accuracy: 0.9791 - val_loss: 0.0802 - val_accuracy: 0.9680 - lr: 1.0000e-03\n",
      "Epoch 194/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0661 - accuracy: 0.9793 - val_loss: 0.0801 - val_accuracy: 0.9680 - lr: 1.0000e-03\n",
      "Epoch 195/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.0803 - val_accuracy: 0.9688 - lr: 1.0000e-03\n",
      "Epoch 196/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0661 - accuracy: 0.9792 - val_loss: 0.0802 - val_accuracy: 0.9680 - lr: 1.0000e-03\n",
      "Epoch 197/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0661 - accuracy: 0.9792 - val_loss: 0.0801 - val_accuracy: 0.9680 - lr: 1.0000e-03\n",
      "Epoch 198/200\n",
      "726/743 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 0.9793\n",
      "Epoch 198: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0661 - accuracy: 0.9793 - val_loss: 0.0802 - val_accuracy: 0.9680 - lr: 1.0000e-03\n",
      "Epoch 199/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0660 - accuracy: 0.9792 - val_loss: 0.0802 - val_accuracy: 0.9680 - lr: 1.0000e-04\n",
      "Epoch 200/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0660 - accuracy: 0.9792 - val_loss: 0.0802 - val_accuracy: 0.9680 - lr: 1.0000e-04\n",
      "Score fold 1: loss de 0.10126055777072906; accuracy de 96.60508632659912%\n",
      "****************************************************\n",
      "Iniciando treinamento da fold: 2.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 3s 3ms/step - loss: 0.6904 - accuracy: 0.5968 - val_loss: 0.6880 - val_accuracy: 0.5052 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6847 - accuracy: 0.6764 - val_loss: 0.6813 - val_accuracy: 0.7482 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6782 - accuracy: 0.7482 - val_loss: 0.6741 - val_accuracy: 0.7946 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6706 - accuracy: 0.7804 - val_loss: 0.6656 - val_accuracy: 0.8002 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6613 - accuracy: 0.7928 - val_loss: 0.6552 - val_accuracy: 0.7914 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6499 - accuracy: 0.7973 - val_loss: 0.6419 - val_accuracy: 0.8129 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6357 - accuracy: 0.8061 - val_loss: 0.6261 - val_accuracy: 0.8169 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6185 - accuracy: 0.8099 - val_loss: 0.6068 - val_accuracy: 0.8193 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5979 - accuracy: 0.8115 - val_loss: 0.5842 - val_accuracy: 0.8161 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5741 - accuracy: 0.8149 - val_loss: 0.5586 - val_accuracy: 0.8193 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5476 - accuracy: 0.8176 - val_loss: 0.5310 - val_accuracy: 0.8209 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5196 - accuracy: 0.8218 - val_loss: 0.5021 - val_accuracy: 0.8297 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4912 - accuracy: 0.8275 - val_loss: 0.4742 - val_accuracy: 0.8345 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4637 - accuracy: 0.8327 - val_loss: 0.4473 - val_accuracy: 0.8369 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4379 - accuracy: 0.8391 - val_loss: 0.4227 - val_accuracy: 0.8441 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4140 - accuracy: 0.8498 - val_loss: 0.4008 - val_accuracy: 0.8537 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3923 - accuracy: 0.8565 - val_loss: 0.3801 - val_accuracy: 0.8609 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3723 - accuracy: 0.8628 - val_loss: 0.3614 - val_accuracy: 0.8673 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3542 - accuracy: 0.8692 - val_loss: 0.3450 - val_accuracy: 0.8737 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3375 - accuracy: 0.8751 - val_loss: 0.3295 - val_accuracy: 0.8753 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3220 - accuracy: 0.8828 - val_loss: 0.3156 - val_accuracy: 0.8865 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3079 - accuracy: 0.8892 - val_loss: 0.3028 - val_accuracy: 0.8889 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2947 - accuracy: 0.8949 - val_loss: 0.2912 - val_accuracy: 0.8937 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2825 - accuracy: 0.8987 - val_loss: 0.2804 - val_accuracy: 0.8961 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2713 - accuracy: 0.9032 - val_loss: 0.2705 - val_accuracy: 0.9017 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2608 - accuracy: 0.9080 - val_loss: 0.2607 - val_accuracy: 0.9041 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2512 - accuracy: 0.9125 - val_loss: 0.2519 - val_accuracy: 0.9073 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2422 - accuracy: 0.9165 - val_loss: 0.2438 - val_accuracy: 0.9089 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2338 - accuracy: 0.9202 - val_loss: 0.2362 - val_accuracy: 0.9129 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2259 - accuracy: 0.9242 - val_loss: 0.2286 - val_accuracy: 0.9201 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2187 - accuracy: 0.9272 - val_loss: 0.2221 - val_accuracy: 0.9153 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2118 - accuracy: 0.9300 - val_loss: 0.2156 - val_accuracy: 0.9201 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2054 - accuracy: 0.9331 - val_loss: 0.2094 - val_accuracy: 0.9257 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1995 - accuracy: 0.9348 - val_loss: 0.2047 - val_accuracy: 0.9289 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1939 - accuracy: 0.9373 - val_loss: 0.1987 - val_accuracy: 0.9289 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1886 - accuracy: 0.9393 - val_loss: 0.1932 - val_accuracy: 0.9345 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1838 - accuracy: 0.9406 - val_loss: 0.1885 - val_accuracy: 0.9353 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1792 - accuracy: 0.9422 - val_loss: 0.1844 - val_accuracy: 0.9361 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1748 - accuracy: 0.9436 - val_loss: 0.1802 - val_accuracy: 0.9376 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1707 - accuracy: 0.9451 - val_loss: 0.1765 - val_accuracy: 0.9400 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1669 - accuracy: 0.9466 - val_loss: 0.1724 - val_accuracy: 0.9408 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1633 - accuracy: 0.9475 - val_loss: 0.1687 - val_accuracy: 0.9408 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1599 - accuracy: 0.9488 - val_loss: 0.1652 - val_accuracy: 0.9416 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1568 - accuracy: 0.9496 - val_loss: 0.1620 - val_accuracy: 0.9432 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1537 - accuracy: 0.9498 - val_loss: 0.1594 - val_accuracy: 0.9448 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1509 - accuracy: 0.9522 - val_loss: 0.1575 - val_accuracy: 0.9456 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1482 - accuracy: 0.9521 - val_loss: 0.1544 - val_accuracy: 0.9448 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1457 - accuracy: 0.9527 - val_loss: 0.1514 - val_accuracy: 0.9448 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1433 - accuracy: 0.9535 - val_loss: 0.1495 - val_accuracy: 0.9472 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1409 - accuracy: 0.9538 - val_loss: 0.1493 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1389 - accuracy: 0.9549 - val_loss: 0.1449 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1368 - accuracy: 0.9552 - val_loss: 0.1424 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1349 - accuracy: 0.9560 - val_loss: 0.1407 - val_accuracy: 0.9504 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1330 - accuracy: 0.9563 - val_loss: 0.1396 - val_accuracy: 0.9536 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1312 - accuracy: 0.9570 - val_loss: 0.1369 - val_accuracy: 0.9520 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1294 - accuracy: 0.9575 - val_loss: 0.1370 - val_accuracy: 0.9536 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1277 - accuracy: 0.9576 - val_loss: 0.1338 - val_accuracy: 0.9544 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1262 - accuracy: 0.9582 - val_loss: 0.1331 - val_accuracy: 0.9552 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1247 - accuracy: 0.9587 - val_loss: 0.1308 - val_accuracy: 0.9536 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1234 - accuracy: 0.9587 - val_loss: 0.1296 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1218 - accuracy: 0.9599 - val_loss: 0.1282 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1205 - accuracy: 0.9596 - val_loss: 0.1272 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1193 - accuracy: 0.9607 - val_loss: 0.1259 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1180 - accuracy: 0.9604 - val_loss: 0.1249 - val_accuracy: 0.9560 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1168 - accuracy: 0.9611 - val_loss: 0.1238 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1156 - accuracy: 0.9614 - val_loss: 0.1230 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1145 - accuracy: 0.9617 - val_loss: 0.1223 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1135 - accuracy: 0.9621 - val_loss: 0.1202 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1122 - accuracy: 0.9621 - val_loss: 0.1194 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1113 - accuracy: 0.9623 - val_loss: 0.1188 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1104 - accuracy: 0.9620 - val_loss: 0.1188 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1093 - accuracy: 0.9626 - val_loss: 0.1164 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1085 - accuracy: 0.9636 - val_loss: 0.1161 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1076 - accuracy: 0.9633 - val_loss: 0.1149 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1067 - accuracy: 0.9642 - val_loss: 0.1153 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1058 - accuracy: 0.9648 - val_loss: 0.1134 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1049 - accuracy: 0.9643 - val_loss: 0.1130 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1042 - accuracy: 0.9651 - val_loss: 0.1121 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1033 - accuracy: 0.9653 - val_loss: 0.1137 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1026 - accuracy: 0.9656 - val_loss: 0.1105 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1018 - accuracy: 0.9663 - val_loss: 0.1111 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1011 - accuracy: 0.9664 - val_loss: 0.1093 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1004 - accuracy: 0.9669 - val_loss: 0.1103 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0997 - accuracy: 0.9666 - val_loss: 0.1082 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0991 - accuracy: 0.9674 - val_loss: 0.1077 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0983 - accuracy: 0.9675 - val_loss: 0.1084 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0976 - accuracy: 0.9680 - val_loss: 0.1068 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0970 - accuracy: 0.9678 - val_loss: 0.1061 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0964 - accuracy: 0.9682 - val_loss: 0.1055 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0959 - accuracy: 0.9684 - val_loss: 0.1051 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0953 - accuracy: 0.9682 - val_loss: 0.1048 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0947 - accuracy: 0.9693 - val_loss: 0.1042 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0941 - accuracy: 0.9693 - val_loss: 0.1041 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0935 - accuracy: 0.9694 - val_loss: 0.1039 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0930 - accuracy: 0.9699 - val_loss: 0.1035 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0925 - accuracy: 0.9699 - val_loss: 0.1026 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0919 - accuracy: 0.9702 - val_loss: 0.1023 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0913 - accuracy: 0.9702 - val_loss: 0.1020 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0908 - accuracy: 0.9702 - val_loss: 0.1019 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0903 - accuracy: 0.9706 - val_loss: 0.1017 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0899 - accuracy: 0.9710 - val_loss: 0.1011 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0894 - accuracy: 0.9707 - val_loss: 0.1011 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0889 - accuracy: 0.9710 - val_loss: 0.1003 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0884 - accuracy: 0.9711 - val_loss: 0.1002 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0878 - accuracy: 0.9720 - val_loss: 0.0995 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0873 - accuracy: 0.9718 - val_loss: 0.0994 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0869 - accuracy: 0.9716 - val_loss: 0.0989 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0866 - accuracy: 0.9718 - val_loss: 0.0986 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0863 - accuracy: 0.9718 - val_loss: 0.0990 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0858 - accuracy: 0.9718 - val_loss: 0.0987 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0852 - accuracy: 0.9726 - val_loss: 0.0989 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0850 - accuracy: 0.9724 - val_loss: 0.0977 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0845 - accuracy: 0.9724 - val_loss: 0.0975 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0841 - accuracy: 0.9725 - val_loss: 0.0978 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0836 - accuracy: 0.9726 - val_loss: 0.0970 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0833 - accuracy: 0.9731 - val_loss: 0.0973 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0829 - accuracy: 0.9731 - val_loss: 0.0968 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0825 - accuracy: 0.9731 - val_loss: 0.0964 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0823 - accuracy: 0.9733 - val_loss: 0.0966 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0818 - accuracy: 0.9734 - val_loss: 0.0962 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0814 - accuracy: 0.9736 - val_loss: 0.0959 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0811 - accuracy: 0.9736 - val_loss: 0.0960 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0808 - accuracy: 0.9734 - val_loss: 0.0965 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0803 - accuracy: 0.9738 - val_loss: 0.0971 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0800 - accuracy: 0.9738 - val_loss: 0.0953 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0797 - accuracy: 0.9742 - val_loss: 0.0951 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0794 - accuracy: 0.9740 - val_loss: 0.0961 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0790 - accuracy: 0.9742 - val_loss: 0.0951 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0787 - accuracy: 0.9743 - val_loss: 0.0951 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0784 - accuracy: 0.9744 - val_loss: 0.0946 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0781 - accuracy: 0.9747 - val_loss: 0.0949 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0777 - accuracy: 0.9743 - val_loss: 0.0942 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0774 - accuracy: 0.9744 - val_loss: 0.0952 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 134/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0771 - accuracy: 0.9750 - val_loss: 0.0951 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 135/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0768 - accuracy: 0.9751 - val_loss: 0.0940 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 136/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0764 - accuracy: 0.9751 - val_loss: 0.0940 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 137/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0762 - accuracy: 0.9750 - val_loss: 0.0937 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 138/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0758 - accuracy: 0.9750 - val_loss: 0.0934 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 139/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0755 - accuracy: 0.9754 - val_loss: 0.0935 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 140/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0753 - accuracy: 0.9754 - val_loss: 0.0941 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 141/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0751 - accuracy: 0.9755 - val_loss: 0.0937 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 142/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0748 - accuracy: 0.9760 - val_loss: 0.0949 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 143/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0745 - accuracy: 0.9755 - val_loss: 0.0937 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 144/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0741 - accuracy: 0.9759 - val_loss: 0.0943 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 145/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0739 - accuracy: 0.9760 - val_loss: 0.0931 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 146/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0736 - accuracy: 0.9761 - val_loss: 0.0930 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 147/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0733 - accuracy: 0.9763 - val_loss: 0.0949 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 148/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0732 - accuracy: 0.9761 - val_loss: 0.0928 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 149/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0728 - accuracy: 0.9762 - val_loss: 0.0934 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 150/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0725 - accuracy: 0.9768 - val_loss: 0.0928 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 151/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0723 - accuracy: 0.9763 - val_loss: 0.0925 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 152/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0722 - accuracy: 0.9767 - val_loss: 0.0927 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 153/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0719 - accuracy: 0.9763 - val_loss: 0.0924 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 154/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0716 - accuracy: 0.9764 - val_loss: 0.0926 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 155/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0713 - accuracy: 0.9769 - val_loss: 0.0925 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 156/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0711 - accuracy: 0.9772 - val_loss: 0.0927 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 157/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0709 - accuracy: 0.9771 - val_loss: 0.0923 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 158/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 0.0925 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 159/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0704 - accuracy: 0.9768 - val_loss: 0.0922 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 160/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0703 - accuracy: 0.9770 - val_loss: 0.0931 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 161/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0700 - accuracy: 0.9770 - val_loss: 0.0923 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 162/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0698 - accuracy: 0.9774 - val_loss: 0.0922 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 163/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 0.0943 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 164/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0692 - accuracy: 0.9771 - val_loss: 0.0932 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 165/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0691 - accuracy: 0.9770 - val_loss: 0.0932 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 166/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0689 - accuracy: 0.9775 - val_loss: 0.0919 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 167/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0686 - accuracy: 0.9775 - val_loss: 0.0918 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 168/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0684 - accuracy: 0.9772 - val_loss: 0.0921 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 169/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0682 - accuracy: 0.9772 - val_loss: 0.0919 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 170/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0679 - accuracy: 0.9774 - val_loss: 0.0918 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 171/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0678 - accuracy: 0.9781 - val_loss: 0.0924 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 172/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0676 - accuracy: 0.9776 - val_loss: 0.0919 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 173/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0672 - accuracy: 0.9781 - val_loss: 0.0923 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 174/200\n",
      "731/743 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 0.9785\n",
      "Epoch 174: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0672 - accuracy: 0.9785 - val_loss: 0.0924 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 175/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0665 - accuracy: 0.9784 - val_loss: 0.0924 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 176/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0665 - accuracy: 0.9784 - val_loss: 0.0923 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 177/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0665 - accuracy: 0.9785 - val_loss: 0.0925 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 178/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0665 - accuracy: 0.9783 - val_loss: 0.0923 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 179/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0665 - accuracy: 0.9782 - val_loss: 0.0922 - val_accuracy: 0.9648 - lr: 1.0000e-03\n",
      "Epoch 180/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0664 - accuracy: 0.9784 - val_loss: 0.0922 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 181/200\n",
      "734/743 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9786\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0664 - accuracy: 0.9785 - val_loss: 0.0922 - val_accuracy: 0.9648 - lr: 1.0000e-03\n",
      "Epoch 182/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 0.0922 - val_accuracy: 0.9648 - lr: 1.0000e-04\n",
      "Epoch 183/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 0.0922 - val_accuracy: 0.9648 - lr: 1.0000e-04\n",
      "Epoch 184/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 0.0921 - val_accuracy: 0.9648 - lr: 1.0000e-04\n",
      "Epoch 185/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 0.0921 - val_accuracy: 0.9648 - lr: 1.0000e-04\n",
      "Epoch 186/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 0.0921 - val_accuracy: 0.9648 - lr: 1.0000e-04\n",
      "Epoch 187/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 0.0921 - val_accuracy: 0.9648 - lr: 1.0000e-04\n",
      "Epoch 188/200\n",
      "729/743 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9784\n",
      "Epoch 188: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9784 - val_loss: 0.0921 - val_accuracy: 0.9648 - lr: 1.0000e-04\n",
      "Epoch 189/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 0.0921 - val_accuracy: 0.9648 - lr: 1.0000e-05\n",
      "Epoch 190/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 0.0921 - val_accuracy: 0.9648 - lr: 1.0000e-05\n",
      "Score fold 2: loss de 0.09962841868400574; accuracy de 96.30473852157593%\n",
      "****************************************************\n",
      "Iniciando treinamento da fold: 3.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 3s 3ms/step - loss: 0.6923 - accuracy: 0.5118 - val_loss: 0.6901 - val_accuracy: 0.5300 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6863 - accuracy: 0.6417 - val_loss: 0.6836 - val_accuracy: 0.7466 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6797 - accuracy: 0.7549 - val_loss: 0.6766 - val_accuracy: 0.7842 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6721 - accuracy: 0.7909 - val_loss: 0.6687 - val_accuracy: 0.7658 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6628 - accuracy: 0.7931 - val_loss: 0.6584 - val_accuracy: 0.7898 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6515 - accuracy: 0.8096 - val_loss: 0.6464 - val_accuracy: 0.7882 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6373 - accuracy: 0.8149 - val_loss: 0.6312 - val_accuracy: 0.7930 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6200 - accuracy: 0.8156 - val_loss: 0.6118 - val_accuracy: 0.7954 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5991 - accuracy: 0.8184 - val_loss: 0.5896 - val_accuracy: 0.7978 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5748 - accuracy: 0.8217 - val_loss: 0.5649 - val_accuracy: 0.8026 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5476 - accuracy: 0.8228 - val_loss: 0.5366 - val_accuracy: 0.8066 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5186 - accuracy: 0.8270 - val_loss: 0.5076 - val_accuracy: 0.8161 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4890 - accuracy: 0.8320 - val_loss: 0.4791 - val_accuracy: 0.8217 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4603 - accuracy: 0.8359 - val_loss: 0.4514 - val_accuracy: 0.8321 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4333 - accuracy: 0.8424 - val_loss: 0.4267 - val_accuracy: 0.8329 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4084 - accuracy: 0.8512 - val_loss: 0.4029 - val_accuracy: 0.8457 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3858 - accuracy: 0.8588 - val_loss: 0.3818 - val_accuracy: 0.8497 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3652 - accuracy: 0.8644 - val_loss: 0.3621 - val_accuracy: 0.8585 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3464 - accuracy: 0.8709 - val_loss: 0.3439 - val_accuracy: 0.8713 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3292 - accuracy: 0.8779 - val_loss: 0.3276 - val_accuracy: 0.8769 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3134 - accuracy: 0.8853 - val_loss: 0.3118 - val_accuracy: 0.8921 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2989 - accuracy: 0.8918 - val_loss: 0.2978 - val_accuracy: 0.8953 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2855 - accuracy: 0.8971 - val_loss: 0.2848 - val_accuracy: 0.8953 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2732 - accuracy: 0.9024 - val_loss: 0.2727 - val_accuracy: 0.8969 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2617 - accuracy: 0.9071 - val_loss: 0.2608 - val_accuracy: 0.9041 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2512 - accuracy: 0.9121 - val_loss: 0.2506 - val_accuracy: 0.9057 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2414 - accuracy: 0.9156 - val_loss: 0.2412 - val_accuracy: 0.9105 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2324 - accuracy: 0.9204 - val_loss: 0.2316 - val_accuracy: 0.9161 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2240 - accuracy: 0.9240 - val_loss: 0.2235 - val_accuracy: 0.9185 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2161 - accuracy: 0.9279 - val_loss: 0.2152 - val_accuracy: 0.9225 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2089 - accuracy: 0.9308 - val_loss: 0.2080 - val_accuracy: 0.9281 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2021 - accuracy: 0.9334 - val_loss: 0.2013 - val_accuracy: 0.9289 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1959 - accuracy: 0.9366 - val_loss: 0.1954 - val_accuracy: 0.9329 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1900 - accuracy: 0.9387 - val_loss: 0.1894 - val_accuracy: 0.9361 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1846 - accuracy: 0.9406 - val_loss: 0.1850 - val_accuracy: 0.9337 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1795 - accuracy: 0.9425 - val_loss: 0.1785 - val_accuracy: 0.9408 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1747 - accuracy: 0.9433 - val_loss: 0.1736 - val_accuracy: 0.9480 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1703 - accuracy: 0.9452 - val_loss: 0.1700 - val_accuracy: 0.9432 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1662 - accuracy: 0.9472 - val_loss: 0.1651 - val_accuracy: 0.9488 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1623 - accuracy: 0.9484 - val_loss: 0.1620 - val_accuracy: 0.9504 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1585 - accuracy: 0.9493 - val_loss: 0.1579 - val_accuracy: 0.9528 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1552 - accuracy: 0.9502 - val_loss: 0.1558 - val_accuracy: 0.9512 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1520 - accuracy: 0.9520 - val_loss: 0.1517 - val_accuracy: 0.9544 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1489 - accuracy: 0.9519 - val_loss: 0.1494 - val_accuracy: 0.9536 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1461 - accuracy: 0.9529 - val_loss: 0.1462 - val_accuracy: 0.9552 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1435 - accuracy: 0.9533 - val_loss: 0.1439 - val_accuracy: 0.9560 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1410 - accuracy: 0.9540 - val_loss: 0.1410 - val_accuracy: 0.9568 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1387 - accuracy: 0.9542 - val_loss: 0.1388 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1364 - accuracy: 0.9547 - val_loss: 0.1367 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1342 - accuracy: 0.9551 - val_loss: 0.1347 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1321 - accuracy: 0.9556 - val_loss: 0.1327 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1303 - accuracy: 0.9566 - val_loss: 0.1313 - val_accuracy: 0.9600 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1284 - accuracy: 0.9574 - val_loss: 0.1297 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1267 - accuracy: 0.9579 - val_loss: 0.1281 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1249 - accuracy: 0.9585 - val_loss: 0.1263 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1234 - accuracy: 0.9589 - val_loss: 0.1246 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1219 - accuracy: 0.9597 - val_loss: 0.1233 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1204 - accuracy: 0.9605 - val_loss: 0.1233 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1190 - accuracy: 0.9609 - val_loss: 0.1220 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1176 - accuracy: 0.9606 - val_loss: 0.1209 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1162 - accuracy: 0.9617 - val_loss: 0.1185 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1150 - accuracy: 0.9618 - val_loss: 0.1186 - val_accuracy: 0.9600 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1138 - accuracy: 0.9621 - val_loss: 0.1169 - val_accuracy: 0.9600 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1126 - accuracy: 0.9633 - val_loss: 0.1166 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1114 - accuracy: 0.9638 - val_loss: 0.1152 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1104 - accuracy: 0.9637 - val_loss: 0.1134 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1094 - accuracy: 0.9639 - val_loss: 0.1139 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1083 - accuracy: 0.9644 - val_loss: 0.1133 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1073 - accuracy: 0.9646 - val_loss: 0.1108 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1064 - accuracy: 0.9640 - val_loss: 0.1115 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1053 - accuracy: 0.9655 - val_loss: 0.1101 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1045 - accuracy: 0.9650 - val_loss: 0.1088 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1037 - accuracy: 0.9654 - val_loss: 0.1081 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1029 - accuracy: 0.9655 - val_loss: 0.1075 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1020 - accuracy: 0.9656 - val_loss: 0.1066 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1011 - accuracy: 0.9662 - val_loss: 0.1064 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1004 - accuracy: 0.9666 - val_loss: 0.1064 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0997 - accuracy: 0.9665 - val_loss: 0.1054 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0988 - accuracy: 0.9671 - val_loss: 0.1075 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0981 - accuracy: 0.9671 - val_loss: 0.1038 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0975 - accuracy: 0.9676 - val_loss: 0.1031 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0968 - accuracy: 0.9681 - val_loss: 0.1034 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0960 - accuracy: 0.9682 - val_loss: 0.1022 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0954 - accuracy: 0.9681 - val_loss: 0.1032 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0948 - accuracy: 0.9684 - val_loss: 0.1022 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0940 - accuracy: 0.9686 - val_loss: 0.1007 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0935 - accuracy: 0.9693 - val_loss: 0.1005 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0929 - accuracy: 0.9688 - val_loss: 0.1016 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0923 - accuracy: 0.9697 - val_loss: 0.1009 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0918 - accuracy: 0.9694 - val_loss: 0.1000 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0912 - accuracy: 0.9696 - val_loss: 0.0988 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0905 - accuracy: 0.9697 - val_loss: 0.0998 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0901 - accuracy: 0.9700 - val_loss: 0.0992 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0895 - accuracy: 0.9704 - val_loss: 0.0999 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0890 - accuracy: 0.9703 - val_loss: 0.0974 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0885 - accuracy: 0.9706 - val_loss: 0.0980 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0879 - accuracy: 0.9712 - val_loss: 0.0970 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0876 - accuracy: 0.9710 - val_loss: 0.0973 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0870 - accuracy: 0.9709 - val_loss: 0.0964 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0865 - accuracy: 0.9710 - val_loss: 0.0986 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0861 - accuracy: 0.9714 - val_loss: 0.0964 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0857 - accuracy: 0.9715 - val_loss: 0.0962 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0852 - accuracy: 0.9717 - val_loss: 0.0964 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0847 - accuracy: 0.9718 - val_loss: 0.0966 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0843 - accuracy: 0.9720 - val_loss: 0.0944 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0838 - accuracy: 0.9719 - val_loss: 0.0942 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0833 - accuracy: 0.9725 - val_loss: 0.0940 - val_accuracy: 0.9688 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0830 - accuracy: 0.9720 - val_loss: 0.0954 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0825 - accuracy: 0.9726 - val_loss: 0.0948 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0822 - accuracy: 0.9721 - val_loss: 0.0947 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0818 - accuracy: 0.9723 - val_loss: 0.0932 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0814 - accuracy: 0.9731 - val_loss: 0.0936 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 0.0931 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0807 - accuracy: 0.9729 - val_loss: 0.0928 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0803 - accuracy: 0.9728 - val_loss: 0.0926 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0799 - accuracy: 0.9734 - val_loss: 0.0924 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0795 - accuracy: 0.9737 - val_loss: 0.0923 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0792 - accuracy: 0.9737 - val_loss: 0.0922 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0788 - accuracy: 0.9736 - val_loss: 0.0937 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0783 - accuracy: 0.9736 - val_loss: 0.0936 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0782 - accuracy: 0.9736 - val_loss: 0.0920 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0778 - accuracy: 0.9743 - val_loss: 0.0916 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0774 - accuracy: 0.9742 - val_loss: 0.0911 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0770 - accuracy: 0.9747 - val_loss: 0.0912 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0767 - accuracy: 0.9747 - val_loss: 0.0909 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0765 - accuracy: 0.9743 - val_loss: 0.0911 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0762 - accuracy: 0.9748 - val_loss: 0.0909 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0758 - accuracy: 0.9751 - val_loss: 0.0924 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0755 - accuracy: 0.9749 - val_loss: 0.0912 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0753 - accuracy: 0.9751 - val_loss: 0.0912 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0749 - accuracy: 0.9750 - val_loss: 0.0909 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "734/743 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 0.9751\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0746 - accuracy: 0.9751 - val_loss: 0.0910 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0740 - accuracy: 0.9757 - val_loss: 0.0905 - val_accuracy: 0.9648 - lr: 1.0000e-03\n",
      "Epoch 134/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0740 - accuracy: 0.9757 - val_loss: 0.0908 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 135/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0740 - accuracy: 0.9756 - val_loss: 0.0905 - val_accuracy: 0.9640 - lr: 1.0000e-03\n",
      "Epoch 136/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0739 - accuracy: 0.9755 - val_loss: 0.0906 - val_accuracy: 0.9640 - lr: 1.0000e-03\n",
      "Epoch 137/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0739 - accuracy: 0.9757 - val_loss: 0.0907 - val_accuracy: 0.9648 - lr: 1.0000e-03\n",
      "Epoch 138/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0739 - accuracy: 0.9757 - val_loss: 0.0907 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 139/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0738 - accuracy: 0.9756 - val_loss: 0.0907 - val_accuracy: 0.9648 - lr: 1.0000e-03\n",
      "Epoch 140/200\n",
      "727/743 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9755\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0738 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9640 - lr: 1.0000e-03\n",
      "Epoch 141/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 142/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9757 - val_loss: 0.0906 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 143/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9755 - val_loss: 0.0906 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 144/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9632 - lr: 1.0000e-04\n",
      "Epoch 145/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9757 - val_loss: 0.0906 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 146/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 147/200\n",
      "730/743 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9756\n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 148/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9640 - lr: 1.0000e-05\n",
      "Epoch 149/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9632 - lr: 1.0000e-05\n",
      "Epoch 150/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9632 - lr: 1.0000e-05\n",
      "Epoch 151/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9632 - lr: 1.0000e-05\n",
      "Epoch 152/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9632 - lr: 1.0000e-05\n",
      "Epoch 153/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9632 - lr: 1.0000e-05\n",
      "Score fold 3: loss de 0.108824223279953; accuracy de 96.0167944431305%\n",
      "****************************************************\n",
      "Iniciando treinamento da fold: 4.\n",
      "Epoch 1/200\n",
      "743/743 [==============================] - 3s 3ms/step - loss: 0.6915 - accuracy: 0.5734 - val_loss: 0.6887 - val_accuracy: 0.6131 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6862 - accuracy: 0.6875 - val_loss: 0.6831 - val_accuracy: 0.7730 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6805 - accuracy: 0.7862 - val_loss: 0.6768 - val_accuracy: 0.7962 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6736 - accuracy: 0.7976 - val_loss: 0.6693 - val_accuracy: 0.7938 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6653 - accuracy: 0.8002 - val_loss: 0.6598 - val_accuracy: 0.8177 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6549 - accuracy: 0.8143 - val_loss: 0.6481 - val_accuracy: 0.8090 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6419 - accuracy: 0.8139 - val_loss: 0.6335 - val_accuracy: 0.8209 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6258 - accuracy: 0.8172 - val_loss: 0.6156 - val_accuracy: 0.8201 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.6065 - accuracy: 0.8199 - val_loss: 0.5944 - val_accuracy: 0.8193 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5836 - accuracy: 0.8212 - val_loss: 0.5700 - val_accuracy: 0.8161 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5579 - accuracy: 0.8228 - val_loss: 0.5429 - val_accuracy: 0.8257 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5302 - accuracy: 0.8267 - val_loss: 0.5146 - val_accuracy: 0.8305 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.5015 - accuracy: 0.8304 - val_loss: 0.4862 - val_accuracy: 0.8313 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4733 - accuracy: 0.8342 - val_loss: 0.4590 - val_accuracy: 0.8337 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4465 - accuracy: 0.8386 - val_loss: 0.4339 - val_accuracy: 0.8409 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.4217 - accuracy: 0.8441 - val_loss: 0.4105 - val_accuracy: 0.8473 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3990 - accuracy: 0.8543 - val_loss: 0.3894 - val_accuracy: 0.8521 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3783 - accuracy: 0.8626 - val_loss: 0.3704 - val_accuracy: 0.8577 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3593 - accuracy: 0.8689 - val_loss: 0.3530 - val_accuracy: 0.8657 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3421 - accuracy: 0.8740 - val_loss: 0.3369 - val_accuracy: 0.8737 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3261 - accuracy: 0.8804 - val_loss: 0.3222 - val_accuracy: 0.8817 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.3114 - accuracy: 0.8875 - val_loss: 0.3085 - val_accuracy: 0.8857 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2977 - accuracy: 0.8940 - val_loss: 0.2959 - val_accuracy: 0.8913 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2851 - accuracy: 0.8983 - val_loss: 0.2843 - val_accuracy: 0.8953 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2734 - accuracy: 0.9028 - val_loss: 0.2734 - val_accuracy: 0.8985 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2625 - accuracy: 0.9074 - val_loss: 0.2633 - val_accuracy: 0.9001 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2525 - accuracy: 0.9108 - val_loss: 0.2539 - val_accuracy: 0.9041 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2431 - accuracy: 0.9154 - val_loss: 0.2450 - val_accuracy: 0.9049 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2344 - accuracy: 0.9201 - val_loss: 0.2368 - val_accuracy: 0.9089 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2263 - accuracy: 0.9232 - val_loss: 0.2295 - val_accuracy: 0.9121 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2186 - accuracy: 0.9266 - val_loss: 0.2218 - val_accuracy: 0.9145 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2117 - accuracy: 0.9292 - val_loss: 0.2155 - val_accuracy: 0.9209 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.2050 - accuracy: 0.9324 - val_loss: 0.2088 - val_accuracy: 0.9225 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1989 - accuracy: 0.9344 - val_loss: 0.2026 - val_accuracy: 0.9233 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1932 - accuracy: 0.9361 - val_loss: 0.1971 - val_accuracy: 0.9273 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1877 - accuracy: 0.9378 - val_loss: 0.1920 - val_accuracy: 0.9265 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1827 - accuracy: 0.9395 - val_loss: 0.1868 - val_accuracy: 0.9273 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1779 - accuracy: 0.9417 - val_loss: 0.1822 - val_accuracy: 0.9281 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1735 - accuracy: 0.9428 - val_loss: 0.1776 - val_accuracy: 0.9321 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1694 - accuracy: 0.9442 - val_loss: 0.1737 - val_accuracy: 0.9337 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1655 - accuracy: 0.9461 - val_loss: 0.1699 - val_accuracy: 0.9369 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1619 - accuracy: 0.9467 - val_loss: 0.1663 - val_accuracy: 0.9376 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1585 - accuracy: 0.9481 - val_loss: 0.1624 - val_accuracy: 0.9400 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1552 - accuracy: 0.9491 - val_loss: 0.1594 - val_accuracy: 0.9416 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1521 - accuracy: 0.9498 - val_loss: 0.1563 - val_accuracy: 0.9416 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1493 - accuracy: 0.9515 - val_loss: 0.1542 - val_accuracy: 0.9456 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1467 - accuracy: 0.9524 - val_loss: 0.1506 - val_accuracy: 0.9448 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1439 - accuracy: 0.9529 - val_loss: 0.1484 - val_accuracy: 0.9448 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1417 - accuracy: 0.9537 - val_loss: 0.1457 - val_accuracy: 0.9472 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1393 - accuracy: 0.9545 - val_loss: 0.1447 - val_accuracy: 0.9440 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1372 - accuracy: 0.9548 - val_loss: 0.1413 - val_accuracy: 0.9472 - lr: 0.0100\n",
      "Epoch 52/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1351 - accuracy: 0.9555 - val_loss: 0.1406 - val_accuracy: 0.9448 - lr: 0.0100\n",
      "Epoch 53/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1332 - accuracy: 0.9566 - val_loss: 0.1374 - val_accuracy: 0.9488 - lr: 0.0100\n",
      "Epoch 54/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1313 - accuracy: 0.9568 - val_loss: 0.1356 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 55/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1295 - accuracy: 0.9574 - val_loss: 0.1339 - val_accuracy: 0.9520 - lr: 0.0100\n",
      "Epoch 56/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1277 - accuracy: 0.9581 - val_loss: 0.1322 - val_accuracy: 0.9528 - lr: 0.0100\n",
      "Epoch 57/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1261 - accuracy: 0.9582 - val_loss: 0.1308 - val_accuracy: 0.9488 - lr: 0.0100\n",
      "Epoch 58/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1245 - accuracy: 0.9592 - val_loss: 0.1297 - val_accuracy: 0.9496 - lr: 0.0100\n",
      "Epoch 59/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1229 - accuracy: 0.9601 - val_loss: 0.1285 - val_accuracy: 0.9568 - lr: 0.0100\n",
      "Epoch 60/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1216 - accuracy: 0.9600 - val_loss: 0.1266 - val_accuracy: 0.9520 - lr: 0.0100\n",
      "Epoch 61/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1201 - accuracy: 0.9606 - val_loss: 0.1253 - val_accuracy: 0.9560 - lr: 0.0100\n",
      "Epoch 62/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1188 - accuracy: 0.9616 - val_loss: 0.1237 - val_accuracy: 0.9528 - lr: 0.0100\n",
      "Epoch 63/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1176 - accuracy: 0.9619 - val_loss: 0.1226 - val_accuracy: 0.9544 - lr: 0.0100\n",
      "Epoch 64/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1163 - accuracy: 0.9624 - val_loss: 0.1214 - val_accuracy: 0.9552 - lr: 0.0100\n",
      "Epoch 65/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1151 - accuracy: 0.9629 - val_loss: 0.1210 - val_accuracy: 0.9536 - lr: 0.0100\n",
      "Epoch 66/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1139 - accuracy: 0.9633 - val_loss: 0.1194 - val_accuracy: 0.9544 - lr: 0.0100\n",
      "Epoch 67/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1128 - accuracy: 0.9634 - val_loss: 0.1182 - val_accuracy: 0.9560 - lr: 0.0100\n",
      "Epoch 68/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1117 - accuracy: 0.9640 - val_loss: 0.1174 - val_accuracy: 0.9552 - lr: 0.0100\n",
      "Epoch 69/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1107 - accuracy: 0.9639 - val_loss: 0.1163 - val_accuracy: 0.9552 - lr: 0.0100\n",
      "Epoch 70/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1095 - accuracy: 0.9648 - val_loss: 0.1156 - val_accuracy: 0.9568 - lr: 0.0100\n",
      "Epoch 71/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1086 - accuracy: 0.9649 - val_loss: 0.1144 - val_accuracy: 0.9560 - lr: 0.0100\n",
      "Epoch 72/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1077 - accuracy: 0.9652 - val_loss: 0.1136 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 73/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1068 - accuracy: 0.9652 - val_loss: 0.1127 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 74/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1059 - accuracy: 0.9654 - val_loss: 0.1120 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 75/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1049 - accuracy: 0.9658 - val_loss: 0.1113 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 76/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1041 - accuracy: 0.9663 - val_loss: 0.1106 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 77/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1032 - accuracy: 0.9666 - val_loss: 0.1102 - val_accuracy: 0.9552 - lr: 0.0100\n",
      "Epoch 78/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1025 - accuracy: 0.9672 - val_loss: 0.1093 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 79/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1017 - accuracy: 0.9675 - val_loss: 0.1084 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 80/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1009 - accuracy: 0.9674 - val_loss: 0.1078 - val_accuracy: 0.9600 - lr: 0.0100\n",
      "Epoch 81/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.1002 - accuracy: 0.9676 - val_loss: 0.1080 - val_accuracy: 0.9576 - lr: 0.0100\n",
      "Epoch 82/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0994 - accuracy: 0.9680 - val_loss: 0.1077 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 83/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0987 - accuracy: 0.9685 - val_loss: 0.1059 - val_accuracy: 0.9584 - lr: 0.0100\n",
      "Epoch 84/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0980 - accuracy: 0.9683 - val_loss: 0.1056 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 85/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0973 - accuracy: 0.9683 - val_loss: 0.1051 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 86/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0967 - accuracy: 0.9685 - val_loss: 0.1045 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 87/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0960 - accuracy: 0.9692 - val_loss: 0.1043 - val_accuracy: 0.9600 - lr: 0.0100\n",
      "Epoch 88/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0954 - accuracy: 0.9692 - val_loss: 0.1035 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 89/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0947 - accuracy: 0.9691 - val_loss: 0.1041 - val_accuracy: 0.9600 - lr: 0.0100\n",
      "Epoch 90/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0943 - accuracy: 0.9695 - val_loss: 0.1027 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 91/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0936 - accuracy: 0.9696 - val_loss: 0.1019 - val_accuracy: 0.9592 - lr: 0.0100\n",
      "Epoch 92/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0931 - accuracy: 0.9695 - val_loss: 0.1014 - val_accuracy: 0.9608 - lr: 0.0100\n",
      "Epoch 93/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0924 - accuracy: 0.9703 - val_loss: 0.1009 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 94/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0918 - accuracy: 0.9700 - val_loss: 0.1009 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 95/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0913 - accuracy: 0.9704 - val_loss: 0.1004 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 96/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0909 - accuracy: 0.9705 - val_loss: 0.0996 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 97/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0903 - accuracy: 0.9708 - val_loss: 0.0992 - val_accuracy: 0.9616 - lr: 0.0100\n",
      "Epoch 98/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0896 - accuracy: 0.9707 - val_loss: 0.0989 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 99/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0892 - accuracy: 0.9710 - val_loss: 0.0984 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 100/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0887 - accuracy: 0.9708 - val_loss: 0.0986 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 101/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0881 - accuracy: 0.9708 - val_loss: 0.0977 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 102/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0878 - accuracy: 0.9714 - val_loss: 0.0976 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 103/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0873 - accuracy: 0.9714 - val_loss: 0.0973 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 104/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0868 - accuracy: 0.9719 - val_loss: 0.0973 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 105/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0863 - accuracy: 0.9720 - val_loss: 0.0987 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 106/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0859 - accuracy: 0.9717 - val_loss: 0.0964 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 107/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0854 - accuracy: 0.9722 - val_loss: 0.0958 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 108/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0851 - accuracy: 0.9720 - val_loss: 0.0956 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 109/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0845 - accuracy: 0.9729 - val_loss: 0.0961 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 110/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0840 - accuracy: 0.9723 - val_loss: 0.0951 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 111/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0838 - accuracy: 0.9725 - val_loss: 0.0947 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 112/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0834 - accuracy: 0.9728 - val_loss: 0.0948 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 113/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0830 - accuracy: 0.9727 - val_loss: 0.0949 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 114/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0826 - accuracy: 0.9729 - val_loss: 0.0942 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 115/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0821 - accuracy: 0.9731 - val_loss: 0.0939 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 116/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0817 - accuracy: 0.9731 - val_loss: 0.0941 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 117/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0813 - accuracy: 0.9735 - val_loss: 0.0932 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 118/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0808 - accuracy: 0.9739 - val_loss: 0.0933 - val_accuracy: 0.9624 - lr: 0.0100\n",
      "Epoch 119/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0806 - accuracy: 0.9739 - val_loss: 0.0930 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 120/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0801 - accuracy: 0.9737 - val_loss: 0.0926 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 121/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0798 - accuracy: 0.9742 - val_loss: 0.0926 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 122/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0795 - accuracy: 0.9739 - val_loss: 0.0922 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 123/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0791 - accuracy: 0.9742 - val_loss: 0.0934 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 124/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0788 - accuracy: 0.9743 - val_loss: 0.0921 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 125/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0783 - accuracy: 0.9746 - val_loss: 0.0931 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 126/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0781 - accuracy: 0.9753 - val_loss: 0.0916 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 127/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0778 - accuracy: 0.9750 - val_loss: 0.0914 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 128/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0775 - accuracy: 0.9746 - val_loss: 0.0914 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 129/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0772 - accuracy: 0.9748 - val_loss: 0.0911 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 130/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0768 - accuracy: 0.9752 - val_loss: 0.0917 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 131/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0764 - accuracy: 0.9755 - val_loss: 0.0913 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 132/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0761 - accuracy: 0.9756 - val_loss: 0.0910 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 133/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0759 - accuracy: 0.9753 - val_loss: 0.0909 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 134/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0756 - accuracy: 0.9756 - val_loss: 0.0906 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 135/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0753 - accuracy: 0.9758 - val_loss: 0.0902 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 136/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0749 - accuracy: 0.9760 - val_loss: 0.0901 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 137/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0746 - accuracy: 0.9761 - val_loss: 0.0902 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 138/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0743 - accuracy: 0.9760 - val_loss: 0.0897 - val_accuracy: 0.9680 - lr: 0.0100\n",
      "Epoch 139/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0740 - accuracy: 0.9755 - val_loss: 0.0904 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 140/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0738 - accuracy: 0.9758 - val_loss: 0.0899 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 141/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0735 - accuracy: 0.9763 - val_loss: 0.0914 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 142/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0733 - accuracy: 0.9763 - val_loss: 0.0894 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 143/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0730 - accuracy: 0.9762 - val_loss: 0.0891 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 144/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0726 - accuracy: 0.9770 - val_loss: 0.0892 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 145/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0724 - accuracy: 0.9764 - val_loss: 0.0890 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 146/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0721 - accuracy: 0.9766 - val_loss: 0.0890 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 147/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0719 - accuracy: 0.9765 - val_loss: 0.0888 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 148/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0715 - accuracy: 0.9766 - val_loss: 0.0896 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 149/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0713 - accuracy: 0.9767 - val_loss: 0.0892 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 150/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0710 - accuracy: 0.9770 - val_loss: 0.0885 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 151/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0708 - accuracy: 0.9775 - val_loss: 0.0885 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 152/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0705 - accuracy: 0.9774 - val_loss: 0.0893 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 153/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0704 - accuracy: 0.9773 - val_loss: 0.0883 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 154/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0701 - accuracy: 0.9776 - val_loss: 0.0882 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 155/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0699 - accuracy: 0.9774 - val_loss: 0.0884 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 156/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0695 - accuracy: 0.9781 - val_loss: 0.0885 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 157/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0694 - accuracy: 0.9774 - val_loss: 0.0881 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 158/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0691 - accuracy: 0.9779 - val_loss: 0.0884 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 159/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0689 - accuracy: 0.9779 - val_loss: 0.0880 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 160/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0686 - accuracy: 0.9778 - val_loss: 0.0890 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 161/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0684 - accuracy: 0.9782 - val_loss: 0.0881 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 162/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0682 - accuracy: 0.9781 - val_loss: 0.0880 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 163/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0679 - accuracy: 0.9781 - val_loss: 0.0882 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 164/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0677 - accuracy: 0.9784 - val_loss: 0.0877 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 165/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0674 - accuracy: 0.9786 - val_loss: 0.0883 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 166/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0672 - accuracy: 0.9787 - val_loss: 0.0881 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 167/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0670 - accuracy: 0.9788 - val_loss: 0.0886 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 168/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0667 - accuracy: 0.9786 - val_loss: 0.0877 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 169/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0666 - accuracy: 0.9790 - val_loss: 0.0879 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 170/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0663 - accuracy: 0.9791 - val_loss: 0.0881 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 171/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0662 - accuracy: 0.9794 - val_loss: 0.0875 - val_accuracy: 0.9672 - lr: 0.0100\n",
      "Epoch 172/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0659 - accuracy: 0.9796 - val_loss: 0.0885 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 173/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0657 - accuracy: 0.9796 - val_loss: 0.0877 - val_accuracy: 0.9648 - lr: 0.0100\n",
      "Epoch 174/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0655 - accuracy: 0.9795 - val_loss: 0.0873 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 175/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0652 - accuracy: 0.9798 - val_loss: 0.0876 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 176/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0651 - accuracy: 0.9797 - val_loss: 0.0876 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 177/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0649 - accuracy: 0.9799 - val_loss: 0.0899 - val_accuracy: 0.9632 - lr: 0.0100\n",
      "Epoch 178/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0647 - accuracy: 0.9797 - val_loss: 0.0876 - val_accuracy: 0.9664 - lr: 0.0100\n",
      "Epoch 179/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0644 - accuracy: 0.9797 - val_loss: 0.0887 - val_accuracy: 0.9640 - lr: 0.0100\n",
      "Epoch 180/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0643 - accuracy: 0.9799 - val_loss: 0.0872 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 181/200\n",
      "730/743 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9802\n",
      "Epoch 181: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0641 - accuracy: 0.9800 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 0.0100\n",
      "Epoch 182/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0635 - accuracy: 0.9804 - val_loss: 0.0877 - val_accuracy: 0.9648 - lr: 1.0000e-03\n",
      "Epoch 183/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0635 - accuracy: 0.9802 - val_loss: 0.0876 - val_accuracy: 0.9648 - lr: 1.0000e-03\n",
      "Epoch 184/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0635 - accuracy: 0.9805 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 185/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0634 - accuracy: 0.9804 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 186/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.0876 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 187/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.0874 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 188/200\n",
      "734/743 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9804\n",
      "Epoch 188: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0634 - accuracy: 0.9804 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-03\n",
      "Epoch 189/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9803 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
      "Epoch 190/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
      "Epoch 191/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
      "Epoch 192/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
      "Epoch 193/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
      "Epoch 194/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
      "Epoch 195/200\n",
      "734/743 [============================>.] - ETA: 0s - loss: 0.0636 - accuracy: 0.9804\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
      "Epoch 196/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-05\n",
      "Epoch 197/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-05\n",
      "Epoch 198/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-05\n",
      "Epoch 199/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-05\n",
      "Epoch 200/200\n",
      "743/743 [==============================] - 2s 3ms/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 0.0875 - val_accuracy: 0.9656 - lr: 1.0000e-05\n",
      "Score fold 4: loss de 0.10547486692667007; accuracy de 96.13677263259888%\n"
     ]
    }
   ],
   "source": [
    "foldCount = 1\n",
    "for train, test in kfold.split(hashing, targets):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.LSTM(50, activation='tanh',recurrent_activation='sigmoid',input_shape=[1, hashing.shape[2]]),\n",
    "\n",
    "        ########## Stacked LSTM\n",
    "        # keras.layers.LSTM(784, activation='relu', return_sequences=True, input_shape=[1, hashing.shape[2]]),\n",
    "        # keras.layers.LSTM(250, activation='relu', return_sequences=True),\n",
    "        # keras.layers.LSTM(90, activation='relu', return_sequences=True),\n",
    "        # keras.layers.LSTM(30, activation='relu'),\n",
    "\n",
    "        keras.layers.Dense(len(set(targets)), activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=['accuracy'])\n",
    "\n",
    "    print('****************************************************')\n",
    "    print(f'Iniciando treinamento da fold: {foldCount}.')\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4,mode='min'), tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0, restore_best_weights=True)]\n",
    "\n",
    "    history = model.fit(hashing[train], targets[train], epochs=200, callbacks=callbacks, validation_split=0.05)\n",
    "\n",
    "    scores = model.evaluate(hashing[test], targets[test], verbose=0)\n",
    "    print(f'Score fold {foldCount}: {model.metrics_names[0]} de {scores[0]}; {model.metrics_names[1]} de {scores[1]*100}%')\n",
    "\n",
    "    foldsAccuracy.append(scores[1] * 100)\n",
    "    foldLosses.append(scores[0])\n",
    "\n",
    "    foldCount = foldCount + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Score de cada fold:\n",
      "****************************************************\n",
      "--> Fold 1: Loss: 0.10126055777072906 ; Accuracy: 96.60508632659912%\n",
      "****************************************************\n",
      "--> Fold 2: Loss: 0.09962841868400574 ; Accuracy: 96.30473852157593%\n",
      "****************************************************\n",
      "--> Fold 3: Loss: 0.108824223279953 ; Accuracy: 96.0167944431305%\n",
      "****************************************************\n",
      "--> Fold 4: Loss: 0.10547486692667007 ; Accuracy: 96.13677263259888%\n",
      "****************************************************\n",
      "Média de accuracy das folds:\n",
      "--> Accuracy: 96.2658479809761 (+- 0.22095431629711704)\n",
      "--> Loss: 0.10379701666533947\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "print('****************************************************')\n",
    "print('Score de cada fold:')\n",
    "for i in range(0, len(foldsAccuracy)):\n",
    "    print('****************************************************')\n",
    "    print(f'--> Fold {i+1}: Loss: {foldLosses[i]} ; Accuracy: {foldsAccuracy[i]}%')\n",
    "\n",
    "print('****************************************************')\n",
    "print('Média de accuracy das folds:')\n",
    "print(f'--> Accuracy: {np.mean(foldsAccuracy)} (+- {np.std(foldsAccuracy)})')\n",
    "print(f'--> Loss: {np.mean(foldLosses)}')\n",
    "print('****************************************************')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}