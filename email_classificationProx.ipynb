{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "import math\n",
    "#from langdetect import detect,detect_langs\n",
    "#import validators\n",
    "#import spacy\n",
    "#from spacy import displacy\n",
    "#import en_core_web_sm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import email\n",
    "import email.policy\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer,word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "#from gensim.parsing.preprocessing import STOPWORDS\n",
    "#from gensim.models import word2vec\n",
    "#from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import re\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import TextVectorization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import gc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   email  target\n0      start date     hourahead timee  cardinall  hou...       0\n1      service long desk  price structure deal quote ...       0\n2      start date  cardinall    hourahead timee  card...       0\n3      start date     hourahead timee  cardinall  anc...       0\n4      cardinall deliverable revenue management marke...       0\n...                                                  ...     ...\n33340  bio  matrix scientific group   symbo   bmxg  p...       1\n33341   cardinall step away hot naked webcam girl liv...       1\n33342  need pill increase performance click  seroius ...       1\n33343  datee final nom       inlet hpl  eastrans  car...       0\n33344  ordinall time  offering male enhancement perfo...       1\n\n[33341 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>start date     hourahead timee  cardinall  hou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>service long desk  price structure deal quote ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>start date  cardinall    hourahead timee  card...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>start date     hourahead timee  cardinall  anc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cardinall deliverable revenue management marke...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33340</th>\n      <td>bio  matrix scientific group   symbo   bmxg  p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33341</th>\n      <td>cardinall step away hot naked webcam girl liv...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33342</th>\n      <td>need pill increase performance click  seroius ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33343</th>\n      <td>datee final nom       inlet hpl  eastrans  car...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33344</th>\n      <td>ordinall time  offering male enhancement perfo...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>33341 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = pd.read_csv(\"Database/dataBaseWithNER.csv\")\n",
    "\n",
    "database = database.drop(columns=[\"Unnamed: 0\"])\n",
    "database = database.dropna()\n",
    "target = database[\"target\"].values.tolist()\n",
    "database"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#wordCount = bagOfWord(emailsText)\n",
    "\n",
    "#wordFrequency = heapq.nlargest(100, wordCount, wordCount.get)\n",
    "\n",
    "#print(wordFrequency)\n",
    "emailsText = []\n",
    "for email in database[\"email\"]:\n",
    "    emailsText.append(email)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33341\n"
     ]
    }
   ],
   "source": [
    "print(len(emailsText))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Representação vetorial GLOVE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "categories = [0, 1]\n",
    "\n",
    "X_train = emailsText[:26000]\n",
    "\n",
    "Y_train = target[:26000]\n",
    "\n",
    "X_test = emailsText[26000:-1]\n",
    "Y_test = target[26000:-1]\n",
    "\n",
    "a = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab : ['', '[UNK]', 'cardinall', 'datee', 'personn', 'orgg', 'moneyy', 'gpee', 'ect', 'company']\n",
      "Vocab Size : 20000\n",
      "Output Shape : (5, 200)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "#text_ds = tf.data.Dataset.from_tensor_slices(emailsText).batch(128)\n",
    "vectorizer.adapt(np.concatenate((X_train, X_test)), batch_size=128)\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "print(\"Vocab : {}\".format(vocab[:10]))\n",
    "print(\"Vocab Size : {}\".format(vectorizer.vocabulary_size()))\n",
    "out = vectorizer(X_train[:5])\n",
    "print(\"Output Shape : {}\".format(out.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n '[UNK]',\n 'cardinall',\n 'datee',\n 'personn',\n 'orgg',\n 'moneyy',\n 'gpee',\n 'ect',\n 'company',\n 'com',\n 'timee',\n 'e',\n 'percentt',\n 'time',\n 'price',\n 'business',\n 'information',\n 'said',\n 'hou',\n 'market',\n 'new',\n 'gas',\n 'http',\n 'email',\n 'message',\n 'need',\n 'enron',\n 'energy',\n 'stock',\n 'deal',\n 'know',\n 'mail',\n 'cc',\n 'service',\n 'report',\n 'thanks',\n 'like',\n 'power',\n 'statement',\n 'norpp',\n 'number',\n 'www',\n 'security',\n 'share',\n 'c',\n 'risk',\n 'vince',\n 'product',\n 'investment',\n 'group',\n 'trading',\n 'j',\n 'ordinall',\n 'money',\n 'work',\n 'forward',\n 'let',\n 'p',\n 'contact',\n 'want',\n 'order',\n 'term',\n 'financial',\n 'free',\n 'sent',\n 'credit',\n 'offer',\n 'question',\n 'address',\n 'use',\n 'change',\n 'list',\n 'best',\n 'management',\n 'project',\n 'right',\n 'account',\n 'based',\n 'future',\n 'customer',\n 'meeting',\n 'original',\n 'site',\n 'people',\n 'r',\n 'transaction',\n 'date',\n 'investor',\n 'sale',\n 'program',\n 'contract',\n 'office',\n 'click',\n 'data',\n 'news',\n 'help',\n 'net',\n 'dynegy',\n 'kaminski',\n 'state',\n 'result',\n 'th',\n 'l',\n 'issue',\n 'send',\n 'cost',\n 'look',\n 'plan',\n 'looking',\n 'attached',\n 'quantityy',\n 'day',\n 'b',\n 'way',\n 'rate',\n 'good',\n 'line',\n 'following',\n 'regard',\n 'mr',\n 'x',\n 'available',\n 'software',\n 'process',\n 'fund',\n 'forwarded',\n 'online',\n 'u',\n 'position',\n 'schedule',\n 'note',\n 'operation',\n 'home',\n 'review',\n 'development',\n 'provide',\n 'asset',\n 'high',\n 'think',\n 'phone',\n 'bank',\n 'team',\n 'research',\n 'thank',\n 'cash',\n 'long',\n 'file',\n 'value',\n 'current',\n 'event',\n 'internet',\n 'come',\n 'agreement',\n 'request',\n 'world',\n 'option',\n 'website',\n 'act',\n 'start',\n 'total',\n 'receive',\n 'employee',\n 'going',\n 'industry',\n 'fax',\n 'buy',\n 'database',\n 'problem',\n 'analyst',\n 'point',\n 'technology',\n 'adobe',\n 'natural',\n 'trade',\n 'opportunity',\n 'set',\n 'fact',\n 'oil',\n 'volume',\n 'support',\n 'including',\n 'director',\n 'visit',\n 'communication',\n 'locc',\n 'received',\n 'professional',\n 'performance',\n 'president',\n 'web',\n 'copyright',\n 'pay',\n 'form',\n 'international',\n 'sell',\n 'save',\n 'debt',\n 'possible',\n 'party',\n 'rating',\n 'action',\n 'marketing',\n 'real',\n 'include',\n 'link',\n 'g',\n 'great',\n 'executive',\n 'place',\n 'ee',\n 'n',\n 'thing',\n 'country',\n 'working',\n 'access',\n 'partnership',\n 'final',\n 'firm',\n 'productt',\n 'claim',\n 'member',\n 'v',\n 'life',\n 'limited',\n 'additional',\n 'trader',\n 'special',\n 'mark',\n 'believe',\n 'manager',\n 'chief',\n 'officer',\n 'copy',\n 'detail',\n 'book',\n 'source',\n 'conference',\n 'currently',\n 'update',\n 'user',\n 'interested',\n 'continue',\n 'provided',\n 'model',\n 'global',\n 'loss',\n 'purchase',\n 'check',\n 'level',\n 'advice',\n 'able',\n 'wish',\n 'comment',\n 'reply',\n 'payment',\n 'short',\n 'unit',\n 'material',\n 'type',\n 'effort',\n 'feel',\n 'increase',\n 'stop',\n 'pm',\n 'area',\n 'soon',\n 'meter',\n 'lon',\n 'hope',\n 'ena',\n 'finance',\n 'government',\n 'case',\n 'plant',\n 'pill',\n 'sure',\n 'end',\n 'production',\n 'mmbtu',\n 'error',\n 'dear',\n 'notice',\n 'center',\n 'corp',\n 'charge',\n 'concern',\n 'pipeline',\n 'release',\n 'delivery',\n 'control',\n 'meet',\n 'dbcaps',\n 'revenue',\n 'low',\n 'potential',\n 'shall',\n 'application',\n 'growth',\n 'window',\n 'related',\n 'resource',\n 'hpl',\n 'commercial',\n 'discussion',\n 'f',\n 'legal',\n 'expected',\n 'partner',\n 'complete',\n 'equity',\n 'read',\n 'et',\n 'major',\n 'talk',\n 'required',\n 'given',\n 'chairman',\n 'utility',\n 'person',\n 'hi',\n 'capacity',\n 'content',\n 'view',\n 'reserved',\n 'electricity',\n 'supply',\n 'estimate',\n 'private',\n 'letter',\n 'watch',\n 'w',\n 'profit',\n 'info',\n 'paid',\n 'na',\n 'ceo',\n 'version',\n 'run',\n 'individual',\n 'better',\n 'system',\n 'oo',\n 'earnings',\n 'discus',\n 'size',\n 'close',\n 'lot',\n 'cd',\n 'public',\n 'daren',\n 'board',\n 'newsletter',\n 'edu',\n 'general',\n 'corporate',\n 'remove',\n 'demand',\n 'kitchen',\n 'quality',\n 'certain',\n 'john',\n 'document',\n 'mailing',\n 'department',\n 'big',\n 'transfer',\n 'shareholder',\n 'jones',\n 'effective',\n 'page',\n 'filing',\n 'got',\n 'paper',\n 'word',\n 'solution',\n 'unknown',\n 'capital',\n 'expectation',\n 'family',\n 'desk',\n 'activity',\n 'try',\n 'decision',\n 'bankruptcy',\n 'ticket',\n 'fee',\n 'flow',\n 'network',\n 'iso',\n 'interview',\n 'say',\n 'open',\n 'immediately',\n 'response',\n 'hello',\n 'tax',\n 'press',\n 'k',\n 'completed',\n 'return',\n 'dollar',\n 'bond',\n 'accounting',\n 'reason',\n 'experience',\n 'pro',\n 'presentation',\n 'needed',\n 'little',\n 'lay',\n 'job',\n 'thought',\n 'necessary',\n 'follow',\n 'laww',\n 'approval',\n 'standard',\n 'operating',\n 'approved',\n 'prior',\n 'alias',\n 'easy',\n 'target',\n 'important',\n 'factor',\n 'sheet',\n 'benefit',\n 'course',\n 'according',\n 'making',\n 'official',\n 'large',\n 'h',\n 'investing',\n 'cut',\n 'corporation',\n 'viagra',\n 'kind',\n 'recent',\n 'exchange',\n 'getting',\n 'direct',\n 'client',\n 'agent',\n 'st',\n 'card',\n 'dow',\n 'street',\n 'cause',\n 'matter',\n 'louise',\n 'period',\n 'add',\n 'key',\n 'status',\n 'm',\n 'announced',\n 'acquisition',\n 'basis',\n 'registered',\n 'success',\n 'yahoo',\n 'item',\n 'face',\n 'balance',\n 'remember',\n 'different',\n 'ask',\n 'expect',\n 'strong',\n 'held',\n 'record',\n 'asked',\n 'font',\n 'uncertainty',\n 'staff',\n 'david',\n 'requirement',\n 'workofartt',\n 'name',\n 'ca',\n 'non',\n 'past',\n 'hard',\n 'small',\n 'closed',\n 'belief',\n 'search',\n 'enronxgate',\n 'create',\n 'mean',\n 'lottery',\n 'average',\n 'loan',\n 'personal',\n 'gain',\n 'committee',\n 'section',\n 'promotion',\n 'participant',\n 'addition',\n 'farmer',\n 'year',\n 'policy',\n 'step',\n 'purpose',\n 'write',\n 'example',\n 'wanted',\n 'download',\n 'away',\n 'largest',\n 'analysis',\n 'confidential',\n 'told',\n 'retail',\n 'commodity',\n 'title',\n 'hand',\n 'bring',\n 'ready',\n 'organization',\n 'left',\n 'lead',\n 'ability',\n 'medium',\n 'wholesale',\n 'reference',\n 'index',\n 'property',\n 'senior',\n 'nd',\n 'friend',\n 'code',\n 'man',\n 'late',\n 'idea',\n 'associate',\n 'fastow',\n 'expense',\n 'unsubscribe',\n 'includes',\n 'assistance',\n 'br',\n 'merger',\n 'called',\n 'soft',\n 'en',\n 'reported',\n 'location',\n 'projection',\n 'sold',\n 'sincerely',\n 'law',\n 'head',\n 'agency',\n 'fast',\n 'prescription',\n 'likely',\n 'eb',\n 'worldwide',\n 'join',\n 'xl',\n 'taking',\n 'removed',\n 'recently',\n 'far',\n 'latest',\n 'resume',\n 'profile',\n 'transmission',\n 'included',\n 'la',\n 'box',\n 'meaning',\n 'class',\n 'strategy',\n 'brand',\n 'higher',\n 'intended',\n 'role',\n 'effect',\n 'begin',\n 'package',\n 'actual',\n 'lower',\n 'logo',\n 'receiving',\n 'financing',\n 'differ',\n 'clear',\n 'q',\n 'field',\n 'category',\n 'facility',\n 'added',\n 'school',\n 'opinion',\n 'xp',\n 'understand',\n 'scheduling',\n 'feedback',\n 'simply',\n 'reserve',\n 'pricing',\n 'health',\n 'sign',\n 'org',\n 'commission',\n 'storage',\n 'seek',\n 'foreign',\n 'condition',\n 'answer',\n 'specific',\n 'vice',\n 'server',\n 'suite',\n 'mx',\n 'mobile',\n 'contains',\n 'confidence',\n 'dr',\n 'grant',\n 'winning',\n 'representative',\n 'income',\n 'cover',\n 'building',\n 'agreed',\n 'sum',\n 'hold',\n 'happy',\n 'federal',\n 'bid',\n 'portland',\n 'city',\n 'prize',\n 'situation',\n 'national',\n 'microsoft',\n 'lose',\n 'goal',\n 'tel',\n 'offering',\n 'focus',\n 'portfolio',\n 'mentioned',\n 'drive',\n 'distribution',\n 'room',\n 'guarantee',\n 'aware',\n 'store',\n 'woman',\n 'computron',\n 'mw',\n 'normal',\n 'quick',\n 'love',\n 'longer',\n 'significant',\n 'consumer',\n 'subscriber',\n 'reporting',\n 'worth',\n 'telephone',\n 'winner',\n 'huge',\n 'allow',\n 'fuel',\n 'log',\n 'west',\n 'reader',\n 'range',\n 'video',\n 'present',\n 'cera',\n 'scheduled',\n 'broadband',\n 'live',\n 'draw',\n 'holding',\n 'managing',\n 'curve',\n 'student',\n 'mind',\n 'lost',\n 'drug',\n 'tell',\n 'avoid',\n 'respect',\n 'directly',\n 'php',\n 'voip',\n 'selected',\n 'draft',\n 'shipping',\n 'america',\n 'involved',\n 'discount',\n 'wall',\n 'house',\n 'featured',\n 'fall',\n 'ensure',\n 'involve',\n 'impact',\n 'chance',\n 'responsibility',\n 'probably',\n 'derivative',\n 'fyi',\n 'design',\n 'jeff',\n 'wide',\n 'fell',\n 'secure',\n 'selling',\n 'learn',\n 'later',\n 'hot',\n 'guy',\n 'attention',\n 'positive',\n 'td',\n 'created',\n 'proposal',\n 'plus',\n 'confirm',\n 'listed',\n 'proposed',\n 'hourahead',\n 'safe',\n 'objective',\n 'publisher',\n 'weather',\n 'require',\n 'care',\n 'assumption',\n 'trying',\n 'decided',\n 'leading',\n 'considered',\n 'seen',\n 'image',\n 'travel',\n 'publication',\n 'near',\n 'turn',\n 'sector',\n 'known',\n 'existing',\n 'choose',\n 'successful',\n 'perform',\n 'fw',\n 'usa',\n 'generation',\n 'region',\n 'expects',\n 'se',\n 'base',\n 'took',\n 'test',\n 'provider',\n 'membership',\n 'requested',\n 'identified',\n 'color',\n 'tool',\n 'pc',\n 'entity',\n 'affiliate',\n 'enrononline',\n 'trust',\n 'structure',\n 'shirley',\n 'deposit',\n 'came',\n 'load',\n 'med',\n 'increased',\n 'conflict',\n 'sally',\n 'oi',\n 'inform',\n 'owner',\n 'outside',\n 'floor',\n 'water',\n 'wi',\n 'industrial',\n 'stand',\n 'enter',\n 'assist',\n 'investigation',\n 'take',\n 'session',\n 'cell',\n 'taken',\n 'exposure',\n 'express',\n 'highly',\n 'child',\n 'play',\n 'associated',\n 'advertisement',\n 'text',\n 'physical',\n 'men',\n 'body',\n 'month',\n 'greg',\n 'university',\n 'feature',\n 'ce',\n 'submit',\n 'reach',\n 'build',\n 'award',\n 'outstanding',\n 'sending',\n 'appreciate',\n 'occur',\n 'advantage',\n 'providing',\n 'discussed',\n 'yes',\n 'north',\n 'edition',\n 'story',\n 'choice',\n 'sorry',\n 'studio',\n 'similar',\n 'make',\n 'california',\n 'saving',\n 'medication',\n 'andrew',\n 'history',\n 'quickly',\n 'broker',\n 'simple',\n 'insurance',\n 'coming',\n 'training',\n 'skilling',\n 'receipt',\n 'bad',\n 'table',\n 'immediate',\n 'cap',\n 'local',\n 'attend',\n 'obligation',\n 'fixed',\n 'medical',\n 'congratulation',\n 'summary',\n 'raise',\n 'disclosure',\n 'provides',\n 'game',\n 'eol',\n 'spot',\n 'post',\n 'pg',\n 'mailto',\n 'preferred',\n 'ooking',\n 'compliance',\n 'variance',\n 'guaranteed',\n 'entire',\n 'awarded',\n 'dvd',\n 'arrangement',\n 'format',\n 'advisor',\n 'relationship',\n 'electric',\n 'super',\n 'respond',\n 'al',\n 'responsible',\n 'entered',\n 'core',\n 'instruction',\n 'early',\n 'wait',\n 'announcement',\n 'old',\n 'track',\n 'que',\n 'candidate',\n 'biz',\n 'appropriate',\n 'independent',\n 'delay',\n '·',\n 'limit',\n 'biggest',\n 'anticipated',\n 'planning',\n 'pre',\n 'pec',\n 'stay',\n 'solicitation',\n 'macromedia',\n 'leader',\n 'voice',\n 'western',\n 'agree',\n 'welcome',\n 'march',\n 'dealer',\n 'failed',\n 'venture',\n 'var',\n 'remain',\n 'hr',\n 'technical',\n 'changed',\n 'ahead',\n 'issued',\n 'confirmation',\n 'recipient',\n 'acquire',\n 'starting',\n 'approach',\n 'rice',\n 'shop',\n 'processing',\n 'represent',\n 'tx',\n 'producer',\n 'consider',\n 'air',\n 'east',\n 'internal',\n 'fully',\n 'stated',\n 'leave',\n 'started',\n 'drop',\n 'sex',\n 'transport',\n 'contained',\n 'pleased',\n 'paul',\n 'bit',\n 'tw',\n 'rose',\n 'follows',\n 'subsidiary',\n 'manage',\n 'graphic',\n 'wysak',\n 'revised',\n 'acceptance',\n 'listing',\n 'hear',\n 'court',\n 'photoshop',\n 'lender',\n 'force',\n 'economic',\n 'wiil',\n 'tab',\n 'growing',\n 'buyer',\n 'study',\n 'instead',\n 'notification',\n 'understanding',\n 'spam',\n 'moving',\n 'password',\n 'kin',\n 'stake',\n 'creative',\n 'talking',\n 'sitara',\n 'filed',\n 'ken',\n 'txt',\n 'function',\n 'common',\n 'buying',\n 'facc',\n 'equipment',\n 'popular',\n 'single',\n 'running',\n 'invest',\n 'initial',\n 'sp',\n ...]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return Sequential([\n",
    "        layers.Input(shape=(1,), dtype=\"string\"),\n",
    "        vectorizer,\n",
    "        #layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(len(categories), activation=\"softmax\"),\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               25728     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 34,114\n",
      "Trainable params: 34,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "102/102 [==============================] - 4s 26ms/step - loss: 131.0792 - accuracy: 0.5271 - val_loss: 30.5798 - val_accuracy: 0.5286\n",
      "Epoch 2/8\n",
      "102/102 [==============================] - 1s 14ms/step - loss: 10.4005 - accuracy: 0.5424 - val_loss: 2.5667 - val_accuracy: 0.5486\n",
      "Epoch 3/8\n",
      "102/102 [==============================] - 1s 13ms/step - loss: 1.4121 - accuracy: 0.5498 - val_loss: 1.4258 - val_accuracy: 0.5403\n",
      "Epoch 4/8\n",
      "102/102 [==============================] - 1s 12ms/step - loss: 0.9584 - accuracy: 0.5574 - val_loss: 1.1114 - val_accuracy: 0.5565\n",
      "Epoch 5/8\n",
      "102/102 [==============================] - 1s 12ms/step - loss: 0.8210 - accuracy: 0.5622 - val_loss: 1.0459 - val_accuracy: 0.5658\n",
      "Epoch 6/8\n",
      "102/102 [==============================] - 1s 12ms/step - loss: 0.7596 - accuracy: 0.5667 - val_loss: 0.9868 - val_accuracy: 0.5650\n",
      "Epoch 7/8\n",
      "102/102 [==============================] - 1s 12ms/step - loss: 0.7351 - accuracy: 0.5700 - val_loss: 1.0002 - val_accuracy: 0.5651\n",
      "Epoch 8/8\n",
      "102/102 [==============================] - 1s 12ms/step - loss: 0.7445 - accuracy: 0.5681 - val_loss: 1.0427 - val_accuracy: 0.5187\n"
     ]
    },
    {
     "data": {
      "text/plain": "6674"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=256, epochs=8, validation_data=(X_test, Y_test))\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.5299615384615385\n",
      "Test  Accuracy : 0.5186648501362398\n",
      "\n",
      "Confusion Matrix : \n",
      "[[3173  459]\n",
      " [3074  634]]\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "print(\"Train Accuracy : {}\".format(accuracy_score(Y_train, np.argmax(train_preds, axis=1))))\n",
    "print(\"Test  Accuracy : {}\".format(accuracy_score(Y_test, np.argmax(test_preds, axis=1))))\n",
    "#print(\"\\nClassification Report : \")\n",
    "#print(classification_report(Y_test, np.argmax(test_preds, axis=1), target_names=categories))\n",
    "print(\"\\nConfusion Matrix : \")\n",
    "print(confusion_matrix(Y_test, np.argmax(test_preds, axis=1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikitplot'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscikitplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mskplt\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      4\u001B[0m skplt\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mplot_confusion_matrix([categories[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m Y_test], [categories[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39margmax(test_preds, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)],\n\u001B[0;32m      5\u001B[0m                                     normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m      6\u001B[0m                                     title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConfusion Matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m                                     figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m     10\u001B[0m                                     );\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'scikitplot'"
     ]
    }
   ],
   "source": [
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix([categories[i] for i in Y_test], [categories[i] for i in np.argmax(test_preds, axis=1)],\n",
    "                                    normalize=True,\n",
    "                                    title=\"Confusion Matrix\",\n",
    "                                    cmap=\"Purples\",\n",
    "                                    hide_zeros=True,\n",
    "                                    figsize=(5,5)\n",
    "                                    );\n",
    "plt.xticks(rotation=90);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))\n",
    "word_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = [\"cardinall\", \"datee\", \"personn\", \"orgg\", \"moneyy\", \"gpee\"]\n",
    "[word_index[w] for w in test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2, random_state=0)\n",
    "#model = PCA(n_components=50, svd_solver='full')\n",
    "array_red = model.fit_transform(dfTfidfArray)\n",
    "\n",
    "df_tsne = pd.DataFrame(array_red)\n",
    "\n",
    "target = dfTfidfArray[\"Target\"].array\n",
    "\n",
    "df_tsne['Target'] = target\n",
    "print(df_tsne)\n",
    "df_tsne_c1 = df_tsne[df_tsne['Target'] == 0]\n",
    "\n",
    "df_tsne_c2 = df_tsne[df_tsne['Target'] == 1]\n",
    "\n",
    "plt.scatter(df_tsne_c1[0].array,df_tsne_c1[1].array,marker='o',color='blue')\n",
    "\n",
    "plt.scatter(df_tsne_c2[0].array,df_tsne_c2[1].array,marker='o',color='red')\n",
    "\n",
    "plt.title('Dados')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(df_features.values,target,test_size=0.2)\n",
    "modelo = getModel().fit(X_treino,y_treino)\n",
    "score = modelo.score(X_teste,y_teste)\n",
    "#score = modelo.score([\"alo\"],[1])\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = cross_val_score(getModel(),df_features.values,target,cv=10)\n",
    "\n",
    "scores.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicoes = cross_val_predict(getModel(), df_features.values, target, cv=10)\n",
    "\n",
    "cm = confusion_matrix(target,predicoes,labels=[0, 1])\n",
    "\n",
    "cm_df = pd.DataFrame(cm, columns=[0, 1])\n",
    "\n",
    "cm_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emailsTest2 = []\n",
    "\n",
    "for email in teste2[\"text\"]:\n",
    "    emailsTest2.append(wordsPreProcessing(email))\n",
    "    \n",
    "print(\"ok\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emailsTest3 = []\n",
    "\n",
    "for email in teste[\"text\"]:\n",
    "    emailsTest3.append(wordsPreProcessing(email))\n",
    "    \n",
    "print(\"ok\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#APAGAR DEPOIS\n",
    "\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_counts = count_vect.fit_transform(emailsTest)\n",
    "# X_train_counts.shape\n",
    "#\n",
    "# tf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ##APAGAR DEPOIS\n",
    "# clf = getModel().fit(X_train_tfidf,target)\n",
    "#\n",
    "# X_new_counts = count_vect.transform(emailsTest2)\n",
    "#\n",
    "# X_new_tfidf = tf_transformer.transform(X_new_counts)\n",
    "#\n",
    "# predict = clf.predict(X_new_tfidf)\n",
    "# print(len(emailsTest2))\n",
    "# print(predict)\n",
    "# print(targetTest2)\n",
    "# print(teste2)\n",
    "# print(clf.score(X_new_tfidf,targetTest2))\n",
    "#\n",
    "# #predicoesTest = cross_val_predict(modelo2, dfTfidfArrayFeaturesTest.values, dfTfidfArrayTargetTest, cv=10)\n",
    "#\n",
    "# cmTest = confusion_matrix(targetTest2,predict,labels=[0, 1])\n",
    "#\n",
    "# cm_dfTest = pd.DataFrame(cmTest, columns=[0, 1])\n",
    "#\n",
    "# cm_dfTest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dfTfidfArrayTest = pd.DataFrame(data=tfidfTransformTest.toarray(), columns=tfidfVectorizerTest.get_feature_names_out())\n",
    "# dfTfidfArrayTest.insert(len(dfTfidfArrayTest.columns), \"Target\", target.array, True)\n",
    "# dfTfidfArrayTest = dfTfidfArrayTest.sample(frac=1)\n",
    "# dfTfidfArrayTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# modelTest = TSNE(n_components=2, random_state=0)\n",
    "# #modelTest = PCA(n_components=50)\n",
    "# array_redTest = modelTest.fit_transform(dfTfidfArrayTest)\n",
    "#\n",
    "# df_tsneTest = pd.DataFrame(array_redTest)\n",
    "# df_tsneTest['Target'] = target.array\n",
    "#\n",
    "# df_tsne_c1Test = df_tsneTest[df_tsneTest['Target'] == 0]\n",
    "#\n",
    "# df_tsne_c2Test  = df_tsneTest[df_tsneTest['Target'] == 1]\n",
    "#\n",
    "# plt.scatter(df_tsne_c1Test[0].array,df_tsne_c1Test[1].array,marker='o',color='blue')\n",
    "#\n",
    "# plt.scatter(df_tsne_c2Test[0].array,df_tsne_c2Test[1].array,marker='o',color='red')\n",
    "#\n",
    "# plt.title('Dados')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "#\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dfTfidfArrayTarget = dfTfidfArray[\"Target\"].array\n",
    "# dfTfidfArrayFeatures = dfTfidfArray.drop(columns=['Target'])\n",
    "#\n",
    "# print(dfTfidfArrayFeatures)\n",
    "#\n",
    "# dfTfidfArrayTargetTest = dfTfidfArrayTest[\"Target\"].array\n",
    "# dfTfidfArrayFeaturesTest = dfTfidfArrayTest.drop(columns=['Target'])\n",
    "#\n",
    "#\n",
    "#\n",
    "# print(dfTfidfArrayFeaturesTest)\n",
    "# dfTfidfArrayTargetTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dfTfidfArrayTargetTest2 = dfTfidfArrayTest2[\"Target\"].array\n",
    "# dfTfidfArrayFeaturesTest2 = dfTfidfArrayTest2.drop(columns=['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #from sklearn.svm import LinearSVC\n",
    "#\n",
    "# X_treino, X_teste, y_treino, y_teste = train_test_split(dfTfidfArrayFeaturesTest2.values,dfTfidfArrayTargetTest2,test_size=0.2)\n",
    "# X_treinoTest, X_testeTest, y_treinoTest, y_testeTest = train_test_split(dfTfidfArrayFeaturesTest.values,dfTfidfArrayTargetTest,test_size=0.01)\n",
    "# modelo = getModel().fit(X_treino,y_treino)\n",
    "# modelo2 = getModel().fit(X_treinoTest,y_treinoTest)\n",
    "# predict = modelo.predict(X_teste)\n",
    "# #score = modelo.score(X_treinoTest,y_treinoTest)\n",
    "# #score2 = modelo2.score(X_treino,y_treino)\n",
    "#\n",
    "# cmTest = confusion_matrix(y_teste,predict)\n",
    "# cm_dfTest = pd.DataFrame(cmTest, columns=[0, 1])\n",
    "#\n",
    "# cm_dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#predicoesTest = cross_val_predict(modelo2, dfTfidfArrayFeaturesTest.values, dfTfidfArrayTargetTest, cv=10)\n",
    "\n",
    "#cmTest = confusion_matrix(dfTfidfArrayTargetTest,predicoesTest,labels=[0, 1])\n",
    "\n",
    "#cm_dfTest = pd.DataFrame(cmTest, columns=[0, 1])\n",
    "\n",
    "#cm_dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}