{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "import math\n",
    "#from langdetect import detect,detect_langs\n",
    "import validators\n",
    "import spacy\n",
    "spacy.require_gpu()\n",
    "from spacy import displacy\n",
    "#import en_core_web_sm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import email\n",
    "import email.policy\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer,word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import re\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CARREGANDO BASE DE DADOS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "'''teste = pd.read_csv(\"spam_ham_dataset.csv\").sample(frac=1)\n",
    "teste2 =pd.read_csv(\"emails.csv\").sample(frac=1)\n",
    "targetTest2 = teste2[\"spam\"]\n",
    "teste = teste.drop(columns=[\"Unnamed: 0\",\"label_num\"])\n",
    "teste = teste.replace({\"ham\":0,\"spam\":1})\n",
    "targetTest = teste[\"label\"]'''\n",
    "\n",
    "database = pd.read_csv(\"Database/enron_spam_data.csv\")\n",
    "database = database.drop(columns=[\"Message ID\",\"Date\"])\n",
    "database = database.replace({\"ham\":0,\"spam\":1})\n",
    "database = database.drop(columns=[\"Subject\"])\n",
    "database = database.dropna()\n",
    "database = database.sample(frac=1)\n",
    "target = database[\"Spam/Ham\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def removePunctuation(text):\n",
    "    ponctuation = list(punctuation)\n",
    "\n",
    "    for i in ponctuation:\n",
    "        text = text.replace(i, \"\")\n",
    "\n",
    "    return text\n",
    "\n",
    "stopWords = set(stopwords.words('english')  + list(punctuation) + list(STOPWORDS))\n",
    "stopWords.add(\"subject\")\n",
    "stem = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "regex = re.compile(r'[\\w\\.-]+@[\\w\\.-]+(\\.[\\w]+)+')\n",
    "\n",
    "def wordsPreProcessing(email):\n",
    "    if email is None:\n",
    "        return 'empty'\n",
    "\n",
    "    newText = \"\"\n",
    "\n",
    "    e = email.split()\n",
    "\n",
    "    for i in range(0,len(e)):\n",
    "        if validators.url(e[i]):\n",
    "            e[i] = \"URLLL\"\n",
    "\n",
    "        if re.fullmatch(regex,e[i]):\n",
    "            e[i] = \"EMAILLL\"\n",
    "\n",
    "    for text in word_tokenize(email.lower()):\n",
    "        text = removePunctuation(text)\n",
    "        if text not in stopWords and not text.isdigit():\n",
    "            newText += lemmatizer.lemmatize(text) + \" \"\n",
    "\n",
    "    return newText\n",
    "\n",
    "def NERProcessing(emails):\n",
    "    emailsPreProcessedLocal = []\n",
    "\n",
    "    NER = spacy.load(\"en_core_web_sm\")\n",
    "    NER.disable_pipe(\"parser\")\n",
    "    NER.add_pipe(\"sentencizer\")\n",
    "    NER.add_pipe(\"merge_entities\")\n",
    "\n",
    "    for doc in NER.pipe(emails, n_process=4):\n",
    "        emailsPreProcessedAux = []\n",
    "\n",
    "        for t in doc:\n",
    "            if not t.ent_type_:\n",
    "                emailsPreProcessedAux.append(t.text)\n",
    "            else:\n",
    "                emailsPreProcessedAux.append((t.ent_type_ + t.ent_type_[-1]).upper())\n",
    "\n",
    "        emailsPreProcessedAux = \" \".join(emailsPreProcessedAux)\n",
    "        emailsPreProcessedLocal.append(wordsPreProcessing(emailsPreProcessedAux))\n",
    "\n",
    "    return emailsPreProcessedLocal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def bagOfWord(emails):\n",
    "    wordCount = {}\n",
    "\n",
    "    for email in emails:\n",
    "        for i in email.split():\n",
    "            if i not in wordCount.keys():\n",
    "                wordCount[i] = 1\n",
    "            else:\n",
    "                wordCount[i] += 1\n",
    "\n",
    "    return wordCount"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# # emailsTest = []\n",
    "# #\n",
    "# # for email in np.array(database[\"Message\"]):\n",
    "# #     emailsTest.append(NERProcessing(email))\n",
    "# #\n",
    "# # NERDataframe = pd.DataFrame(emailsTest, columns=[\"email\"])\n",
    "# # NERDataframe.to_csv('Database/dataBaseWithNER.csv')\n",
    "# # NERDataframe\n",
    "# a = wordsPreProcessing(database[\"Message\"].array[0])\n",
    "# a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DevPack\\Anaconda3\\envs\\data_science\\lib\\site-packages\\spacy\\language.py:1567: UserWarning: [W114] Using multiprocessing with GPU models is not recommended and may lead to errors.\n",
      "  warnings.warn(Warnings.W114)\n"
     ]
    }
   ],
   "source": [
    "textos = []\n",
    "ini = datetime.now()\n",
    "\n",
    "emailsPreProcessed = NERProcessing(database[\"Message\"])\n",
    "\n",
    "#print(emailsPreProcessed)\n",
    "#print()\n",
    "print(datetime.now() - ini)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NERDataframe = pd.DataFrame(emailsPreProcessed, columns=[\"email\"])\n",
    "NERDataframe[\"target\"] = target.values\n",
    "\n",
    "NERDataframe.to_csv('Database/dataBaseWithNER.csv')\n",
    "NERDataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #nlp = en_core_web_sm.load()\n",
    "# #nlp = spacy.load(\"en_core_web_sm\")\n",
    "# spacy.prefer_gpu()\n",
    "# NER = spacy.load(\"E:\\Anaconda3\\Lib\\site-packages\\en_core_web_sm\\en_core_web_sm-3.2.0\")\n",
    "#\n",
    "# print(emailsTest[45])\n",
    "# print()\n",
    "# print(NERProcessing(emailsTest[45]))\n",
    "#\n",
    "# #displacy.render(text1,style=\"ent\",jupyter=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import cupy\n",
    "# a = cupy.zeros((5, 5))\n",
    "# a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# spacy.prefer_gpu()\n",
    "# spacy.require_gpu()\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "#\n",
    "# text = nlp(\"Ruan\")\n",
    "# text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#wordCount = bagOfWord(emailsText)\n",
    "\n",
    "#wordFrequency = heapq.nlargest(100, wordCount, wordCount.get)\n",
    "\n",
    "#print(wordFrequency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidfVectorizer = TfidfVectorizer(analyzer=\"word\",max_features=2100)\n",
    "#tfidfVectorizer = TfidfVectorizer(analyzer=\"word\")\n",
    "\n",
    "tfidfTransform = tfidfVectorizer.fit_transform(emailsText)\n",
    "\n",
    "print(tfidfTransform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidfLabels = tfidfVectorizer.get_feature_names()\n",
    "tfidfLabels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfTfidfArray = pd.DataFrame(data=tfidfTransform.toarray(), index=emailsNome, columns=tfidfLabels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfTfidfArray"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfTfidfArray.insert(len(dfTfidfArray.columns), \"Target\", targetsArray, True)\n",
    "dfTfidfArray = dfTfidfArray.sample(frac=1)\n",
    "dfTfidfArray\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dfTfidfArray.to_csv(\"dataset.csv\", sep='\\t', encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2, random_state=0)\n",
    "#model = PCA(n_components=50, svd_solver='full')\n",
    "array_red = model.fit_transform(dfTfidfArray)\n",
    "\n",
    "df_tsne = pd.DataFrame(array_red)\n",
    "\n",
    "target = dfTfidfArray[\"Target\"].array\n",
    "\n",
    "df_tsne['Target'] = target\n",
    "print(df_tsne)\n",
    "df_tsne_c1 = df_tsne[df_tsne['Target'] == 0]\n",
    "\n",
    "df_tsne_c2 = df_tsne[df_tsne['Target'] == 1]\n",
    "\n",
    "plt.scatter(df_tsne_c1[0].array,df_tsne_c1[1].array,marker='o',color='blue')\n",
    "\n",
    "plt.scatter(df_tsne_c2[0].array,df_tsne_c2[1].array,marker='o',color='red')\n",
    "\n",
    "plt.title('Dados')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_features = dfTfidfArray.drop(columns=['Target'])\n",
    "#df_tsneTarget = df_tsne[\"Target\"].array\n",
    "#df_tsneFeatures = df_tsne.drop(columns=['Target'])\n",
    "\n",
    "\n",
    "df_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def getModel():\n",
    "      return LogisticRegression(max_iter=200)\n",
    "#     return DecisionTreeClassifier()\n",
    "#     return RandomForestClassifier()\n",
    "#     return LinearSVC()\n",
    "#     return MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(df_features.values,target,test_size=0.2)\n",
    "modelo = getModel().fit(X_treino,y_treino)\n",
    "score = modelo.score(X_teste,y_teste)\n",
    "#score = modelo.score([\"alo\"],[1])\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = cross_val_score(getModel(),df_features.values,target,cv=10)\n",
    "\n",
    "scores.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicoes = cross_val_predict(getModel(), df_features.values, target, cv=10)\n",
    "\n",
    "cm = confusion_matrix(target,predicoes,labels=[0, 1])\n",
    "\n",
    "cm_df = pd.DataFrame(cm, columns=[0, 1])\n",
    "\n",
    "cm_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emailsTest2 = []\n",
    "\n",
    "for email in teste2[\"text\"]:\n",
    "    emailsTest2.append(wordsPreProcessing(email))\n",
    "    \n",
    "print(\"ok\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emailsTest3 = []\n",
    "\n",
    "for email in teste[\"text\"]:\n",
    "    emailsTest3.append(wordsPreProcessing(email))\n",
    "    \n",
    "print(\"ok\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#APAGAR DEPOIS\n",
    "\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_counts = count_vect.fit_transform(emailsTest)\n",
    "# X_train_counts.shape\n",
    "#\n",
    "# tf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ##APAGAR DEPOIS\n",
    "# clf = getModel().fit(X_train_tfidf,target)\n",
    "#\n",
    "# X_new_counts = count_vect.transform(emailsTest2)\n",
    "#\n",
    "# X_new_tfidf = tf_transformer.transform(X_new_counts)\n",
    "#\n",
    "# predict = clf.predict(X_new_tfidf)\n",
    "# print(len(emailsTest2))\n",
    "# print(predict)\n",
    "# print(targetTest2)\n",
    "# print(teste2)\n",
    "# print(clf.score(X_new_tfidf,targetTest2))\n",
    "#\n",
    "# #predicoesTest = cross_val_predict(modelo2, dfTfidfArrayFeaturesTest.values, dfTfidfArrayTargetTest, cv=10)\n",
    "#\n",
    "# cmTest = confusion_matrix(targetTest2,predict,labels=[0, 1])\n",
    "#\n",
    "# cm_dfTest = pd.DataFrame(cmTest, columns=[0, 1])\n",
    "#\n",
    "# cm_dfTest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# dfTfidfArrayTest = pd.DataFrame(data=tfidfTransformTest.toarray(), columns=tfidfVectorizerTest.get_feature_names_out())\n",
    "# dfTfidfArrayTest.insert(len(dfTfidfArrayTest.columns), \"Target\", target.array, True)\n",
    "# dfTfidfArrayTest = dfTfidfArrayTest.sample(frac=1)\n",
    "# dfTfidfArrayTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# modelTest = TSNE(n_components=2, random_state=0)\n",
    "# #modelTest = PCA(n_components=50)\n",
    "# array_redTest = modelTest.fit_transform(dfTfidfArrayTest)\n",
    "#\n",
    "# df_tsneTest = pd.DataFrame(array_redTest)\n",
    "# df_tsneTest['Target'] = target.array\n",
    "#\n",
    "# df_tsne_c1Test = df_tsneTest[df_tsneTest['Target'] == 0]\n",
    "#\n",
    "# df_tsne_c2Test  = df_tsneTest[df_tsneTest['Target'] == 1]\n",
    "#\n",
    "# plt.scatter(df_tsne_c1Test[0].array,df_tsne_c1Test[1].array,marker='o',color='blue')\n",
    "#\n",
    "# plt.scatter(df_tsne_c2Test[0].array,df_tsne_c2Test[1].array,marker='o',color='red')\n",
    "#\n",
    "# plt.title('Dados')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "#\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# dfTfidfArrayTarget = dfTfidfArray[\"Target\"].array\n",
    "# dfTfidfArrayFeatures = dfTfidfArray.drop(columns=['Target'])\n",
    "#\n",
    "# print(dfTfidfArrayFeatures)\n",
    "#\n",
    "# dfTfidfArrayTargetTest = dfTfidfArrayTest[\"Target\"].array\n",
    "# dfTfidfArrayFeaturesTest = dfTfidfArrayTest.drop(columns=['Target'])\n",
    "#\n",
    "#\n",
    "#\n",
    "# print(dfTfidfArrayFeaturesTest)\n",
    "# dfTfidfArrayTargetTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# dfTfidfArrayTargetTest2 = dfTfidfArrayTest2[\"Target\"].array\n",
    "# dfTfidfArrayFeaturesTest2 = dfTfidfArrayTest2.drop(columns=['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# #from sklearn.svm import LinearSVC\n",
    "#\n",
    "# X_treino, X_teste, y_treino, y_teste = train_test_split(dfTfidfArrayFeaturesTest2.values,dfTfidfArrayTargetTest2,test_size=0.2)\n",
    "# X_treinoTest, X_testeTest, y_treinoTest, y_testeTest = train_test_split(dfTfidfArrayFeaturesTest.values,dfTfidfArrayTargetTest,test_size=0.01)\n",
    "# modelo = getModel().fit(X_treino,y_treino)\n",
    "# modelo2 = getModel().fit(X_treinoTest,y_treinoTest)\n",
    "# predict = modelo.predict(X_teste)\n",
    "# #score = modelo.score(X_treinoTest,y_treinoTest)\n",
    "# #score2 = modelo2.score(X_treino,y_treino)\n",
    "#\n",
    "# cmTest = confusion_matrix(y_teste,predict)\n",
    "# cm_dfTest = pd.DataFrame(cmTest, columns=[0, 1])\n",
    "#\n",
    "# cm_dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#predicoesTest = cross_val_predict(modelo2, dfTfidfArrayFeaturesTest.values, dfTfidfArrayTargetTest, cv=10)\n",
    "\n",
    "#cmTest = confusion_matrix(dfTfidfArrayTargetTest,predicoesTest,labels=[0, 1])\n",
    "\n",
    "#cm_dfTest = pd.DataFrame(cmTest, columns=[0, 1])\n",
    "\n",
    "#cm_dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}